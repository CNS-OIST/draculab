{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tutorial2.ipynb\n",
    "\n",
    "Synaptic plasticity and spatially arranged connections in draculab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FOREWORD**  \n",
    "Plasticity rules for firing rate neurons usually assume that you have a set of input vectors $\\{ {\\bf x}^{(1)}, {\\bf x}^{(2)}, \\dots, {\\bf x}^{(n)} \\}$, \n",
    "where ${\\bf x}^{(j)} = (x_1^{(j)}, \\dots, x_k^{(j)})^T$.   \n",
    "These input vectors are applied to the network in discrete presentations, each causing a change $\\Delta \\boldsymbol{\\omega}^{(j)}$ on the vector of \n",
    "synaptic weights $\\boldsymbol{\\omega} = (\\omega_1, \\omega_2, \\dots, \\omega_k)^T$.\n",
    "\n",
    "For example, the  [Oja learning rule](http://www.scholarpedia.org/article/Oja_learning_rule) states that presenting ${\\bf x} = (x_1, \\dots, x_k)$ will \n",
    "produce a change $\\Delta \\omega_i$ in $\\omega_i$, characterized by the equation:  \n",
    "$ \\Delta \\omega_i = \\alpha \\left(x_i y - y^2 \\omega_i \\right), \\ \\ i=1, \\dots, k. $,  \n",
    "where $\\alpha$ is a learning rate, and $y$ is the response of the neuron to the input ${\\bf x}$.\n",
    "\n",
    "When we work with networks that operate in continuous time we no longer have discrete input vectors, and the learning rule must be adapted.\n",
    "The most straightforward way to do this is by assuming that the learning rule describes the derivative of $\\omega_i$, so we end up with something like:   \n",
    "$ \\frac{d \\omega_i}{dt} = \\alpha \\left(x_i(t) y(t) - y^2(t) \\omega_i \\right), \\ \\ i=1, \\dots, k. $,  \n",
    "where $x_i(t), y(t)$ are functions of time. We use a function ${\\bf x}(t)$ that gradually transitions through the patterns \n",
    "$\\{ {\\bf x}^{(1)}, {\\bf x}^{(2)}, \\dots, {\\bf x}^{(n)} \\}$ in continuous time. In the first part of the tutorial we create a unit with plastic connections and observe whether it behaves like its discrete counterpart. \n",
    "\n",
    "The next step would be to program a network whose units have plastic synapses. This implies specifying how the units are connected to each other, \n",
    "which can be a complicated endeavour. Before attempting this, the second part of the tutorial presents draculab's `topology` module, which allows to create spatially structured connections. In the next tutorial a network with plastic synapses is presented.\n",
    "\n",
    "The networks in this tutorial are is an open-loop systems (because the outputs of the network don't affect its inputs). Tutorial 4 provides a simple closed-loop simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "Creating a unit with adaptive connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  [Oja learning rule](http://www.scholarpedia.org/article/Oja_learning_rule) is supposed to extract the first principal component of the input correlation\n",
    "matrix. If we create a matrix with our input vectors, say $M = [ {\\bf x}^{(1)} \\ {\\bf x}^{(2)} \\dots \\ {\\bf x}^{(n)} ]$, the input correlation matrix is\n",
    "$C = M M^T$. Notice that $C_{i,j}$ shows how the $x_i$ component of the input vectors correlates with the $x_j$ component. When using linear units, it can be shown that using the Oja learning rule can (approximately) produce a weight vector $\\boldsymbol{\\omega}$ such that \n",
    "$C \\boldsymbol{\\omega} = \\lambda \\boldsymbol{\\omega}$, where $\\lambda$ (the principal eigenvalue) is the scalar $\\boldsymbol{\\omega}^T C \\boldsymbol{\\omega}$.\n",
    "\n",
    "This tutorial is not concerned with the meaning of all this. We want to see if a continous version of the rule can still produce this result in a toy problem.\n",
    "\n",
    "The programming part is similar to the first tutorial, but we now have to produce a slighltly more complex input, and change the synapse specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing...\n",
    "%cd .. \n",
    "from draculab import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid \n",
    "# mpl_toolkits should be included with matplotlib. If it is not present (as happened with some \n",
    "# Ubuntu releases) please reinstall matplolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the network as before, using a single linear unit\n",
    "net_params = {\n",
    "    'min_delay' : 0.005, # minimum delay in all the network's connections (in seconds)\n",
    "    'min_buff_size' : 10 } # minimum buffer size. How many values are stored per simulation step. \n",
    "net = network(net_params)\n",
    "\n",
    "n_lins = 1 # how many linear units to create\n",
    "lin_params = {\n",
    "    'type' : unit_types.linear,\n",
    "    'init_val' : 0.5, # initial value\n",
    "    'tau_fast' : 0.05, # see explanation below\n",
    "    'coordinates' : np.array([0., 0.]), # not required. Just a preview of what's to come\n",
    "    'tau' : 0.02 } # time constant for the dynamics of all linear units\n",
    "lin_ids = net.create(n_lins, lin_params)\n",
    "\n",
    "n_sources = 9 # how many input units to create\n",
    "input_params = {\n",
    "    'type' : unit_types.source,\n",
    "    'init_val' : 0.5,\n",
    "    'tau_fast' : 0.05, # see explanation below\n",
    "    'function' : lambda t: None } \n",
    "inp_ids = net.create(n_sources, input_params)\n",
    "\n",
    "conn_spec = {\n",
    "    'rule' : 'all_to_all', \n",
    "    'delay' : .1 } \n",
    "syn_pars = {\n",
    "    'type' : synapse_types.oja, # Oja synapses. The oja_synapse class in synapses.py\n",
    "    'init_w' : {'distribution':'uniform', 'low':.1, 'high':.5}, \n",
    "    'lrate' : 0.2 } # learning rate\n",
    "net.connect(inp_ids, lin_ids, conn_spec, syn_pars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signals in continuous time can experience fast fluctuations. In draculab, learning rules that depend on presynaptic and postsynaptic activities (such\n",
    "as the Oja rule) depend on continous signals. To reduce the effect of fluctuations and enhance stability, instead of directly using the presynaptic\n",
    "and postsynaptic activities, draculab uses low-pass filtered versions of them. A first-order low-pass filtered basically provides an average of the\n",
    "recent values for the filtered signal. The parameter `tau_fast` is the time constant of the first-order filter used.\n",
    "\n",
    "When a synapse that uses low-pass filters (such as `oja`) is connected, it automatically requests the postsynaptic and/or postsynaptic units(s) to keep\n",
    "low-pass filtered versions of their activity (the LPF'd activity). Quantities other than LPF'd activities can be requested by the synapse to the unit,\n",
    "such as the sum of all weights, or the average of the inputs. In this way the same computation doesn't have to repeat in all synapse objects,\n",
    "but is instead done once in the unit object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create the input functions.\n",
    "\n",
    "### We are going to present 4 input patterns that randomly switch over time.\n",
    "### Imagine the 9 inputs arranged in a grid, like a tic-tac-toe board, numbered\n",
    "### from left to right and from top to bottom:\n",
    "### 1 2 3\n",
    "### 4 5 6\n",
    "### 7 8 9\n",
    "### You'll have input patterns\n",
    "### 0 X 0   0 0 0   X 0 X   0 X 0\n",
    "### 0 X 0   X X X   0 0 0   X 0 X\n",
    "### 0 X 0   0 0 0   X 0 X   0 X 0\n",
    "### Each pattern will appear for t_pat time units, and then the input will adopt\n",
    "### a different pattern by changing its values linearly through time for t_trans time units.\n",
    "### Thus, the input is always a normalized linear combination of one or two of the patterns.\n",
    "### Pattern pat1 is presented alone for t_pat time units, and then there is a transition period\n",
    "### during which pat1 becomes pat2 by presenting at time t an input \n",
    "### c*(t_pat+t_trans - t)*pat1 + c*(t - tpat)*pat2\n",
    "### where c = 1/t_trans, and t_trans is the duration of the transition period. \n",
    "### At time t_pat+t_trans, pat2 is presented by itself for t_pat time units.\n",
    "### \n",
    "# here are the patterns as arrays\n",
    "patterns = [np.zeros(n_sources) for i in range(4)]\n",
    "patterns[0] = np.array([0., 1., 0., 0., 1., 0., 0., 1., 0.])/3.\n",
    "patterns[1] = np.array([0., 0., 0., 1., 1., 1., 0., 0., 0.])/3.\n",
    "patterns[2] = np.array([1., 0., 1., 0., 0., 0., 1., 0., 1.])/4.\n",
    "patterns[3] = np.array([0., 1., 0., 1., 0., 1., 0., 1., 0.])/4.\n",
    "\n",
    "def make_pat_fun(idx):\n",
    "    # This creates a constant function with value: patterns[cur_pat][idx],\n",
    "    # used to initialize the source units as in tutorial 1\n",
    "    fun = lambda t : patterns[cur_pat][idx]\n",
    "    return fun\n",
    "\n",
    "def make_trans_fun(idx, last_t):\n",
    "    # Creates a function for the pattern transition\n",
    "    fun = lambda t : c * ( (t_trans - (t-last_t))*patterns[cur_pat][idx] +\n",
    "                           (t-last_t)*patterns[next_pat][idx] )\n",
    "    return fun\n",
    "\n",
    "t_pat = 2. # as described above\n",
    "t_trans = .3 # as described above\n",
    "c = 1/t_trans # auxiliary variable\n",
    "cur_pat = np.random.choice(4)  # pattern currently presented\n",
    "next_pat = np.random.choice(4) # next pattern to be presented\n",
    "last_t = 0. # time when the last pattern ended\n",
    "#weights = np.array(net.units[lin_ids[0]].get_weights(net.sim_time)) # initial weights of the linear unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run the simulation.\n",
    "\n",
    "# In order for the unit to learn properly, the input patterns need to be presented\n",
    "# many times. Instead of creating input functions capable of presenting all the\n",
    "# patterns, we simulate one pattern presentation at a time. After each presentation\n",
    "# we change the input function used by the source units.\n",
    "\n",
    "n_pres = 100 # number of times some pattern will be presented\n",
    "start_time = time.time() # used to time the simulation\n",
    "times = np.array([]) # used to store the times array from all simulations\n",
    "activs = np.tile([], (len(net.units),1)) # used to store the activities array from all simulations\n",
    "run_activs = [] # auxiliary list used to concatenate activities\n",
    "\n",
    "for pres in range(n_pres):\n",
    "# For each cycle you'll set the input functions and simulate, once with a single pattern,\n",
    "# once with a mix of patterns, as described above   \n",
    "    # first, we present a single pattern\n",
    "    for u in range(n_sources):\n",
    "        net.units[inp_ids[u]].set_function( make_pat_fun(u) )\n",
    "        \n",
    "    sim_dat = net.run(t_pat)  # simulating\n",
    "    last_t = net.sim_time # simulation time after last pattern presentation\n",
    "    times = np.append(times, sim_dat[0])\n",
    "    run_activs.append(sim_dat[1])\n",
    "    \n",
    "    # now one pattern turns into the next\n",
    "    for u in range(n_sources):\n",
    "        net.units[inp_ids[u]].set_function(make_trans_fun(u, last_t))\n",
    "    \n",
    "    sim_dat = net.run(t_trans) # simulating\n",
    "    times = np.append(times, sim_dat[0])\n",
    "    run_activs.append(sim_dat[1])\n",
    "    \n",
    "    # choose the pattern you'll present next\n",
    "    cur_pat = next_pat\n",
    "    next_pat = np.random.choice(4)\n",
    "    \n",
    "    if pres%10 == 0:\n",
    "        print('Finished presentation ' + str(pres))\n",
    "        \n",
    "activs = np.append(activs, np.concatenate(run_activs, axis=1), axis=1)  \n",
    "print('Execution time: %s seconds' % (time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the activities of the units using Matplotlib\n",
    "\n",
    "fig1 = plt.figure(figsize=(20,10))\n",
    "# Plot the activity of the linear unit\n",
    "plt.subplot(221)\n",
    "plt.plot(times, activs[lin_ids[0]])\n",
    "plt.title('the linear unit')\n",
    "# Plot the activity of one input unit\n",
    "plt.subplot(222)\n",
    "plt.plot(times, activs[inp_ids[2]])\n",
    "plt.title('one input')\n",
    "# Plot the activity of all inputs\n",
    "inp_acts = [ activs[u] for u in inp_ids ]\n",
    "plt.subplot(223)\n",
    "plt.plot(times, np.transpose(inp_acts))\n",
    "plt.title('all inputs')\n",
    "# Plot the activity of some inputs\n",
    "plt.subplot(224)\n",
    "inp_acts = [ activs[inp_ids[3]], activs[inp_ids[6]] ]\n",
    "plt.plot(times, np.transpose(inp_acts))\n",
    "plt.title('two inputs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now that the simulation is done, we want to compare the weight vector of the \n",
    "# linear unit with the leading eigenvector of the input correlation matrix.\n",
    "# If these two vectors are similar, then the Oja rule succeeded in extracting\n",
    "# the eigenvector in continuous time.\n",
    "\n",
    "# Obtaining the weight vector of the linear unit is straighforward\n",
    "weights = np.array(net.units[lin_ids[0]].get_weights(net.sim_time))\n",
    "\n",
    "# Next we get the eigenvectors of the correlation matrix\n",
    "pat_arr = np.array(patterns) # a numpy array composed of the input vectors\n",
    "corr = np.matmul(pat_arr.transpose(), pat_arr) # input correlation matrix\n",
    "eigs = np.linalg.eig(corr) # extracting eigenvalues and eigenvectors\n",
    "evals = eigs[0] # these are the eigenvalues\n",
    "evecs = [eigs[1][:,i] for i in range(9)] # these are the eigenvectors\n",
    "\n",
    "# extracting the leading eigenvector (the eigenvector with the largest eigenvalue)\n",
    "max_index, max_value = max(enumerate(evals), key=lambda p:p[1])\n",
    "#print('leading eigenvalue: ' + str(max_value) + ', index: ' + str(max_index))\n",
    "max_evector = evecs[max_index]  # this is the leading eigenvector\n",
    "\n",
    "# In order to compare the two vectors, we normalize them and 'flatten' them\n",
    "weights /= np.linalg.norm(weights) # normalize the weight vector\n",
    "max_evector /= np.linalg.norm(max_evector) # normalize the eigenvector\n",
    "weights1D = weights.reshape(9)\n",
    "max_ev1D = -max_evector.reshape(9) \n",
    "# also changed the sign, which doesn't change the eigenvector's identity\n",
    "\n",
    "# we obtain the angle between the two vectors\n",
    "angle = np.arccos(np.dot(weights1D, max_ev1D))\n",
    "print(\"angle between vectors: %f radians\" % (angle))\n",
    "\n",
    "# plotting leading eigenvector VS weight vector in 3x3 format\n",
    "fig2 = plt.figure(figsize=(12,5))\n",
    "sp_ev_grid = ImageGrid(fig2, 111, nrows_ncols=(1,2), axes_pad=0.2)\n",
    "for idx,vec in enumerate([-max_evector, weights]):\n",
    "    vec.shape = 3,3\n",
    "    sp_ev_grid[idx].imshow(vec)\n",
    "    # also printing the vectors in a readable format\n",
    "    print([\"%.2f\" % float(v[0]) for v in vec.reshape(9,1)])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "draculab's `topology` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1 had a single linear unit, and there was little point in having continous-time dynamics. We move into a network that has a population of interconnected sigmoidal units. Rather than following the basic connectionist paradigm leading to multilayer perceptrons, we use a more biologically-inspired architecture.\n",
    "\n",
    "Biological neural networks are sparsely connected, meaning that each neuron only sends projections to a relatively small fraction of the population. The projections usually form feedback loops, unlike the feedforward neural architectures that are ubiquitous in machine learning. Biologically plausible connectivity patterns can be better described using probabilities of connection that depend on the spatial relation between the neurons to be connected. To create these type of connections draculab has a `topology` module, largely inspired in the [topology module](http://www.nest-simulator.org/part-4-topologically-structured-networks/) of the [NEST](http://www.nest-simulator.org/) neural simulator.\n",
    "\n",
    "As a stepping stone to create a network with spatially structured adaptive connections, we learn about draculab's `topology` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing... PLEASE RESET THE KERNEL BEFORE CONTINUING WITH PART 2\n",
    "%cd .. \n",
    "from draculab import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topology module contains two important methods:\n",
    "`topology.create_group`, and `topology.topo_connect`.\n",
    "\n",
    "The idea behind the topology module is that every unit has a `coordinates` attribute, which is a numpy 1D array with 2 or 3 elements.\n",
    "Based on their relative positions we can adjust the proabability that any two units are connected, as well as the synaptic weights, and connection delays.\n",
    "\n",
    "The coordinates of the units can be set manually in their parameters dictionary, but this is usually cumbersome. The `create_group` method is here to ease the burden. \n",
    "`create_group` is basically a front end for `network.create_units`, but it receives an extra parameter dictionary to specify how to assign\n",
    "the coordinates to the units being created. At this point `create_group` only creates 2D grids of units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# more information\n",
    "help(topology.create_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have populations of units with properly assigned coordinates, we can use `topo_connect` to connect them.\n",
    "The options in `topo_connect` are reminsicent of those in PyNEST's [topology module](http://www.nest-simulator.org/part-4-topologically-structured-networks/), but there are important differences that need to be explained.\n",
    "\n",
    "The docstring of `topo_connect` is long, and not obvious at first, so let's explain some of its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(topology.topo_connect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, there are 5 arguments to `topo_connect`. These are basically the same as those used with\n",
    "`network.connect`, with the addition of `net`, which is the network instance where the connections will be made.\n",
    "\n",
    "The difference with `network.connect` is in the contents of the `conn_spec` dictionary, since we will now use a different\n",
    "way to specify which units should be connected. The way it works depends on whether we set the `connection_type` parameter to\n",
    "`convergent` or `divergent`. Let's explain the case of convergent connections.\n",
    "\n",
    "Let's say unit `b` is in `to_list`, and you're considering whether it shoud receive a projection from unit `a` in `from_list`. First we see if `a` is inside `b`'s mask. The mask is a spatial region that depends on `b`'s coordinates; only units inside the mask are eligible to send connections to `b`. If `a` is inside `b`'s mask, then it has a probability of connecting to `b` given by the kernel function. The kernel function expresses the probability of `a` connecting to `b` as a function of their distance. Thus, we generate the connection between `a` and `b` with this probability.\n",
    "\n",
    "In the case of divergent connections, the difference is that the mask is applied to the units of the `to_list`. So to decide if `a` connects to `b`, we first check whether `b` is inside of `a`'s mask.\n",
    "\n",
    "The next example illustrates these and other settings of the `conn_spec` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" In this cell we use the create_group method with the 'sheet' shape and 'grid' arrangement \"\"\"\n",
    "topo = topology()  # creating an instance of the topology class\n",
    "\n",
    "# Create network\n",
    "net_params = {'min_delay' : 0.2, \n",
    "              'min_buff_size' : 4 } # parameter dictionary for the network\n",
    "net = network(net_params)\n",
    "\n",
    "# Create group of units\n",
    "unit_pars = { \n",
    "    'init_val' : 0.5, \n",
    "    'tau' : .1, \n",
    "    'type' : unit_types.linear } \n",
    "geom = { 'shape':'sheet', \n",
    "         'extent':[1.,1.], \n",
    "         'center':[1.,0.], \n",
    "         'arrangement':'grid', \n",
    "         'rows':18, \n",
    "         'columns':16, \n",
    "         'jitter' : 0.01 } \n",
    "ids = topo.create_group(net, geom, unit_pars)  # creating the units\n",
    "\n",
    "# Plot the unit locations\n",
    "xvals = [ u.coordinates[0] for u in net.units ]\n",
    "yvals = [ u.coordinates[1] for u in net.units ]\n",
    "figg = plt.figure(figsize=(6,6))\n",
    "plt.scatter(xvals, yvals, s=2.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This cell uses the topo_connect method with the network in the previous cell. \"\"\"\n",
    "\n",
    "# create the spec dictionaries\n",
    "conn_spec = {'connection_type' : 'divergent',\n",
    "             'mask' : {\"annular\" : {\"inner_radius\": .2, 'outer_radius':.5}},\n",
    "             'kernel' : .8, \n",
    "             #'kernel' : {'gaussian':{'p_center':.2, 'sigma':3.}},\n",
    "             #'kernel' : {'linear' : {'c' : 1., 'a' : .3}},\n",
    "             'delays' : {'linear' : {'c':0.1, 'a':0.1}},\n",
    "             'weights' : {'linear' : {'c':5., 'a':1.}},\n",
    "             'edge_wrap' : True,\n",
    "             'boundary' : {'center' : geom['center'], 'extent' : geom['extent']},\n",
    "            }\n",
    "syn_spec = {'type' : synapse_types.static, 'init_w' : 0.2 }\n",
    "\n",
    "# Connect. This might take some time.\n",
    "topo.topo_connect(net, ids, ids, conn_spec, syn_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The draculab core programs do not offer a method to visualize connections. This is not hard using\n",
    "Matplolib. Below is one simple script to check that the connections look as they should. \n",
    "\n",
    "A faster, but slightly more complex version of the code below is at the bottom of this notebook. This faster version  is a\n",
    "reduced adaptation of the `conn_anim` function of the `ei_net` and `ei_network` classes, to be described later. \n",
    "You can suubstitute the cell below for the cell at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the connections \n",
    "%matplotlib widget\n",
    "#%matplotlib notebook\n",
    "# The 'notebook' backend is compatible with FuncAnimation. Another option is 'qt5'.\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# flattening net.syns\n",
    "all_syns = []\n",
    "for syn_list in net.syns:\n",
    "    all_syns += syn_list\n",
    "    \n",
    "# getting a list with the coordinates of all units\n",
    "all_coords = [u.coordinates for u in net.units]\n",
    "n_units = len(all_coords)\n",
    "\n",
    "fig = plt.figure(figsize=(9,5))\n",
    "ax1 = fig.add_axes([0.0, 0.01, .49, 0.95], frameon=True, aspect=1)\n",
    "ax2 = fig.add_axes([0.51, 0.01, .49, 0.95], frameon=True, aspect=1)\n",
    "ax1.plot(xvals, yvals, 'c.')\n",
    "ax2.plot(xvals, yvals, 'c.')\n",
    "ax1.set_title('sender=black, receiver=red')\n",
    "ax2.set_title('sender=green, receiver=black')\n",
    "\n",
    "# At each frame we'll visualize the connections arising from a single unit\n",
    "def update(frame): \n",
    "    u = frame%n_units # unit we'll visualize \n",
    "    # getting targets of projections from the unit 'u'\n",
    "    targets = [syn.postID for syn in all_syns if syn.preID == u]\n",
    "    tar_coords = [ all_coords[t] for t in targets ]\n",
    "    tar_xcoords = [c[0] for c in tar_coords]\n",
    "    tar_ycoords = [c[1] for c in tar_coords]\n",
    "    ax1.clear()\n",
    "    ax1.scatter(xvals, yvals, s=2)\n",
    "    ax1.scatter(net.units[u].coordinates[0], net.units[u].coordinates[1], s=30, c='black')\n",
    "    ax1.scatter(tar_xcoords, tar_ycoords, s=12, c=\"red\")\n",
    "    ax1.set_title('sender=black, receiver=red')\n",
    "    # getting units that project to unit 'u'\n",
    "    sources = [ syn.preID for syn in net.syns[u] ]\n",
    "    sour_coords = [ all_coords[s] for s in sources ]\n",
    "    sour_xcoords = [ c[0] for c in sour_coords ]\n",
    "    sour_ycoords = [ c[1] for c in sour_coords ]\n",
    "    ax2.clear()\n",
    "    ax2.scatter(xvals, yvals, s=2)\n",
    "    ax2.scatter(net.units[u].coordinates[0], net.units[u].coordinates[1], s=30, c='black')\n",
    "    ax2.scatter(sour_xcoords, sour_ycoords, s=12, c=\"green\")\n",
    "    ax2.set_title('sender=green, receiver=black')\n",
    "    \n",
    "    return ax1,ax2,\n",
    "\n",
    "animation = FuncAnimation(fig, update, interval=15, blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Alter the simulation loop of part 1 so that the learning rate is decreased 10% in all synapses every 10 input presentations.\n",
    "\n",
    "To do this it is helpful to look at the code of the oja_synapse class in the synapses.py file. In particular, the __init__\n",
    "methods has the lines\n",
    "\n",
    "```\n",
    "self.lrate = params['lrate'] # learning rate for the synaptic weight\n",
    "self.alpha = self.lrate * self.net.min_delay # factor that scales the update rule\n",
    "```\n",
    "which shows that in addition to the `lrate` attribute, you should also modify the `alpha` attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "What will happen if you replace the Oja synapses for BCM synapses (synapse_types.bcm)?  \n",
    "BCM synapses require an extra parameter 'tau_slow' for the postsynaptic unit. The BCM learning rule uses\n",
    "the temporal average of the squared postsynaptic activity, and this is obtained by low-pass filtering with a\n",
    "'tau_slow' time constant. Set 'tau_slow' = 4 initially. \n",
    "The `syn_spec` parameter of `topology.topo_connect` is basically the same as the `syn_pars` paramter of `network.connect`,\n",
    "which means that additional parameters required by synapses can be included here.\n",
    "\n",
    "In other words, we set `tau_slow` by including it in the synapse parameter dictionary:\n",
    "\n",
    "    syn_spec = { ..., 'tau_slow' : 4. }\n",
    "\n",
    "Also try Hebbian learning with substractive normalization (synapse_types.hebbsnorm).\n",
    "An important trait of Hebbian learning with substractive normalization is that the sum of the weights remains fixed.\n",
    "Does changing the average magnitude of the initial weights change the results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-project (for those who would enjoy it)\n",
    "You could try to extract more than one eigenvector using an algorithm based on:  \n",
    "Foldiak (1989) \"Adaptive network for optimal linear feature extraction\"\n",
    "Proc IEEE/INNS IJCNN 1:401-405"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "EXERCISE SOLUTIONS BELOW\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                ,_-=(!7(7/zs_.\n",
    "                             .='  ' .`/,/!(=)Zm.\n",
    "               .._,,._..  ,-`- `,\\ ` -` -`\\\\7//WW.\n",
    "          ,v=~/.-,-\\- -!|V-s.)iT-|s|\\-.'   `///mK%.\n",
    "        v!`i!-.e]-g`bT/i(/[=.Z/m)K(YNYi..   /-]i44M.\n",
    "      v`/,`|v]-DvLcfZ/eV/iDLN\\D/ZK@%8W[Z..   `/d!Z8m\n",
    "     //,c\\(2(X/NYNY8]ZZ/bZd\\()/\\7WY%WKKW)   -'|(][%4.\n",
    "   ,\\\\i\\c(e)WX@WKKZKDKWMZ8(b5/ZK8]Z7%ffVM,   -.Y!bNMi\n",
    "   /-iit5N)KWG%%8%%%%W8%ZWM(8YZvD)XN(@.  [   \\]!/GXW[\n",
    "  / ))G8\\NMN%W%%%%%%%%%%8KK@WZKYK*ZG5KMi,-   vi[NZGM[\n",
    " i\\!(44Y8K%8%%%**~YZYZ@%%%%%4KWZ/PKN)ZDZ7   c=//WZK%!\n",
    ",\\v\\YtMZW8W%%f`,`.t/bNZZK%%W%%ZXb*K(K5DZ   -c\\\\/KM48\n",
    "-|c5PbM4DDW%f  v./c\\[tMY8W%PMW%D@KW)Gbf   -/(=ZZKM8[\n",
    "2(N8YXWK85@K   -'c|K4/KKK%@  V%@@WD8e~  .//ct)8ZK%8`\n",
    "=)b%]Nd)@KM[  !'\\cG!iWYK%%|   !M@KZf    -c\\))ZDKW%`\n",
    "YYKWZGNM4/Pb  '-VscP4]b@W%     'Mf`   -L\\///KM(%W!\n",
    "!KKW4ZK/W7)Z. '/cttbY)DKW%     -`  .',\\v)K(5KW%%f\n",
    "'W)KWKZZg)Z2/,!/L(-DYYb54%  ,,`, -\\-/v(((KK5WW%f\n",
    " \\M4NDDKZZ(e!/\\7vNTtZd)8\\Mi!\\-,-/i-v((tKNGN%W%%\n",
    " 'M8M88(Zd))///((|D\\tDY\\\\KK-`/-i(=)KtNNN@W%%%@%[\n",
    "  !8%@KW5KKN4///s(\\Pd!ROBY8/=2(/4ZdzKD%K%%%M8@%%\n",
    "   '%%%W%dGNtPK(c\\/2\\[Z(ttNYZ2NZW8W8K%%%%YKM%M%%.\n",
    "     *%%W%GW5@/%!e]_tZdY()v)ZXMZW%W%%%*5Y]K%ZK%8[\n",
    "      '*%%%%8%8WK\\)[/ZmZ/Zi]!/M%%%%@f\\ \\Y/NNMK%%!\n",
    "        'VM%%%%W%WN5Z/Gt5/b)((cV@f`  - |cZbMKW%%|\n",
    "           'V*M%%%WZ/ZG\\t5((+)L'-,,/  -)X(NWW%%\n",
    "                `~`MZ/DZGNZG5(((\\,    ,t\\\\Z)KW%@\n",
    "                   'M8K%8GN8\\5(5///]i!v\\K)85W%%f\n",
    "                     YWWKKKKWZ8G54X/GGMeK@WM8%@\n",
    "                      !M8%8%48WG@KWYbW%WWW%%%@\n",
    "                        VM%WKWK%8K%%8WWWW%%%@`\n",
    "                          ~*%%%%%%W%%%%%%%@~\n",
    "                             ~*MM%%%%%%@f`\n",
    "                                 '''''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".'';;;,....';;,',;,',,,,,,,'''''',;;,'.......''',;;;;;::::::::::cccccccccccccccccccccccccccccccc:::::::;;;;;;;;::;;::;;,,;,,',,,''''',,,''''',,;;;::::\n",
    "..',;;,.....,;,',;,'',,,,,,'''''',,;,'.........',;;;;;::::::::::::::cc::;;,,,,,,,;:ccccccccccccc:::::::;,,,;;;;;:;;;;;;,,,'',,,'''''''',,,,;;;;;::::::\n",
    "..',;;;'....,;,,;;;,'',,,,,,''''',,,,'.........',;;;;;:::::::::::cccc:;;,,,,,,'...'';:cccccccccc:::::::;;;;;;;;;;;;;;;;;;,,''''''',,,;;;;:::::::::::::\n",
    "...';;;'....','';;,'.',,,,'''..''',,''.........',;;,;;;::::::;;;:c:,''......''.......',:cccccccc::::;;;,,,'''',;;;;;,'''''''',,;;;;;;;;;;;;;;;;;;;;;;;\n",
    "....,;;,.....'.',,................'''...........',,,,;;;;;::,'',,'.......',,,;;;;:;;,'.':ccccccc:::;;,''.......',,;,,'',,,;;;;;;;;;;;;;;;;;,,,,,,,,,,,\n",
    "....',,,........'................................',',,;;;;;,....,;:;:ccccoxkkO0KKKX0kl;'';ccccc::;;;;;,''..''''',,;;,,,,,,,;;;,,,,,,,,,,''''''..'''',,\n",
    ".....'''.........................................'''',;;;;,...,ldxkkOKXXXXNWWWMMMMMMNkc,',:c::::;;;;;;;;,,,,,,,,,,,,,,,,,,,,,'''''''''.....'''',,,,,,,\n",
    "......,,'......'.................................'''',,,,,'...:dxxxxOXNNWWWWWMMMMMMMWOl;'';:::::;;;;;;;;;,,,,,,,,'''''''...........''''''''''''''.....\n",
    "......',,'.......................................''.'',,,,'..'coddddk0XNWNNWWMMMMMMMMNkc'';::::;;;;;;;;,,,,,,''''............'''''''''''..............\n",
    "'......','...........................................'',,,...:looooddxOKNNXXNWWNK00KNWW0c,cl:;:;;;;,,,,,,,,'''........''''..........................''\n",
    "........''.....................';;;;,,,,,,,,''',,,,,,,;;;:;.'colc:;;:clxKXK00kdlldxOXWMXod0d:;;;,,,,,,,,,,'',,'....................................',;\n",
    ".........'.....................':::::::::::::::::::::::::cl;,clc:;;,,,,;o0NNXkdooxOKWWMXk00lccc:::::::;;;;;;;:;;'...................................,;\n",
    "....... ...................   .'::::::::::::::::::::::::::cc:cllccc::ccclONWNNK00KNWWWWNK0dccccccccccccccccc:cc::;;,''',,,,'..................'......,\n",
    "........ ......................':::::::;;;;;;;;;;;;;;::::::clllllllllllcoONWWWWWWWWMWWWWXxlcccccccccccccccccccc:::cc;:clcll:...................''.....\n",
    "...............................'::::::;;:;,,,,,',,,,,,,,,;;;clllllloollldKWWWWNNWWWMWWWXxlcc::;;:::ccc::ccccccc::clc:clllll:...................',''''.\n",
    "  ......   ...   ..   ....    .';::;;;;;::;,,,,,,,,,,,,,,;;;;:cllllodolclOXNXXNXXNWWWWXd'.........,:;,,;:cccccc:::cc:clllll;.             ......','...\n",
    "      ..         .     .       ';;;;;;,;::;,;;;;;;;;;;;;;,....,cllloolccokKXXNNNXXNWNN0;       ..;::;'.,:ccccc::;:c::clllll,.                 ...',...\n",
    ".     ....      .... ....     .';:::::;;c:;;;;,,;;:::::::;.   .;lloolc:;cdxxk0KXXNNWNXo........;cccc:,';:cccccc:;cl::clllol;.                ....',,'.\n",
    "....  .....      ... .....    .,::::::;:c:::;'..'::;,;;;;;'.   .,coolc::lodxOKXNNNNNWNd.......,ccccc:,';ccccccc::cl::llllol,. ......    ....  ....';;,\n",
    "............. .  .........  ...,::::::;:c:::;'..,cc:;;;;;;;.    .,colllodk0KXNNNNNNNWWXl......'clccc;,,;cccccccccll::lllool,................ ......,;;\n",
    "..........'....................;::::::;:cc::;'..,clc::::::c,......cdoolok00KXNNNXXNWMMMXd,.....,clcc;,,:cccccccclol:clooool'.......................',;\n",
    "......':oxkkdl;'...............;::::::;:cc::;'..,clc::cccc:,....,cxK0kdoxxooxkO0KNWMMMNKOo:'....,ccc;',:ccc:::cclol:clooooc'.............''.........',\n",
    "....';coddxxxkkxoc'......    ..;::::::;:lc::;'..,clcccc:;,'....'kNNWWNNKOxddxOKXNNNWWXK0Oxd:......,,,'':c::::::clol:clooooc.......      .',....   ...'\n",
    "....;:cccllclxOO00xc,..... ....;c::::::clc::;'..;ll::;,'......'oKNNWWMWN00KXXXXXNNNXXNNKOxd;.........',;:::::::cllc:cooooo:.......... ...,,...........\n",
    "....';:lxo;':dOkddxkko,........:ccc:c::clc::;'.',;,'.........;d0XXXNNNNK0KNNNNNNNNXXWWX0Oxl'.............,;:cc::clc;cooooo:..............,;...........\n",
    "....';:okx;',lko'';:oOd,......':ccccc::clc::,...............;d0XNXKXNNWWWWWMMMMMWNWMWNX0Oxc........ ...  ...,:ccll:;cooooo;...     ......;;...  ..  ..\n",
    "'''.',:cxx,..;dd,...'lkx;.....':ccccc::cc,'................:xKNNNNXXNWWWWMWWMMWNNWMMWNK0Od,....................,:lc:looooo;...... ......';;...   .....\n",
    " .  .';:dd' ..:c'....'okc.....':ccccc::;..................ckKNNNNWNXXWWWMWWMWWNNMMMWWNK0Oo'......................':clooool,.............';;'..........\n",
    " .  ..;lxOo.. ... ....,ol.....':ccc::,'.. ...............:kKNNNNNWWNXWWWWWWWNXWMMMMWNNK0kc.........................':coool,.............,:;'..........\n",
    "     .'ck0Ol.     ......'. ...':,,'...     ..     ......:k0XWWWWWWWWNXWNNNNXNWMMMMWNNNK0x,...............  ...    ...':lol'.............,:;'.... .....\n",
    "      .'lkkx;.     .. ... .......                  ....'d0XNWWWWWWWWWXNWNXNWWWMMWWWNNWX0d'...........  ...           ..;ll'. . ..  .. ..;:;'..........\n",
    "       .;dddo'     ..  ..                        ......cOKNWWWWWWWWWMNNNXNWMMMWWMWNNWWX0l..........     .......       ..;l:'..  ....  ..;:;'..........\n",
    "...     .',,;. . ..   ..                ..... ........,d0XNWWWWWWWMMMWXKNWMWMMWWWWNNWWXOc................................;lc'...........;;;'..........\n",
    "....            ..                      ...... .......lOKXNWWWWWWWMMMWKKWMMWWMWWWNNWWWXk;...............'co:.........  ...,cc,.........';;,'..........\n",
    ".....           .                ..     .............,x0KXNWWWWWWWMMMWKKWMMMMMMWWNWWMWXk,...........'cdxO0Ol...  ....     .,cc,........';;,...........\n",
    "........     ...                 .     .. ...........ck0KXNWWWWMMMMMMWKXMMMMMMMWWWWMMNKx,...........;kXKl.......     ..    .':c,. .....';;,...........\n",
    "................       .        ....  ..............,oO0KXNWWWMMMMMMMNXNMMMMMMWWWWMMWXKd'.............:;......................,:,.....;coooc;'........\n",
    "........ ........      .        ...      ...........:x00KKNWMMMMMMMMWXKNMMMMMWWWWMMWNXKd'.......................................,,,:oxk00KXX0dc,......\n",
    ".....                                           ...'ok00KKXWMMMMMMMMWNNWMMWWWWWWMMMWXXKo......                                 .;dk0000KKXNNNXKk:.....\n",
    "..  ..                                           ..,xO00KKKNWMMMWWMWNNNWMWWNNNWWMMWNXXKl...                                  .;dO00KKKXXXNNNNNNXd,....\n",
    "..........      .....        ....   ...      ......,dO0KKKKXWMMMMMMWNWMMWWWWWWWMMWWXXX0l....... ...                        .'ck000XNNNNNNNNWWWXo:,....\n",
    ".............................':,...........  ......;dk0KKKKKNWMMWMWNNWWWWWWWWMMMMWNNX0Oc........  .      ..            ....'ldxO0KNNXKXNWNNWWNx'::....\n",
    ".............................':.  .  .. .    ......:dk000KKKKNWMMMWXNWWWNNWWWMMMMNXKK0Oc....                             .,ooccxO0X0kOKNNNWWWKc.co'...\n",
    ".......  ......   .  ..     .';.                 .,cdO00O000KKNWWWWXXXNNNNWWWWWNXKKXX0k:.                               .,odc,'lk0XklxOKXKKNXx;,lOl...\n",
    ".............................,,.  ................;lokOOO0000KXNWWWX0KNNWWWWWWNXXXXXKOd:...........            ...     .'ldc'..o0X0c,oOXNx:ol'.,:c;...\n",
    "...........'.................,,...................;clxkOO00KKKKXNNNKOKWWWWWWMWNXXXXX0kx:................................:oc,..;kKKo.'l0NN0o,..........\n",
    "..........''.................,'...................;ccoxOO00KKKXXXXXXXNWWWWWWWWWNXXKK0Od:................................,,....c0Kd'.'dXWWWO,..........\n",
    "..........'..................,'...................:llldkO00KKKXXXXXWWWWWWWWWWWWWXXKK0kdc......................................,ol...:ONWNNd...........\n",
    "..........'..................,'...................cooddxkO00KKXXXXXNNXNWWWMMMWMWWXK0kxxd;..........................................:kNNXNK:...........\n",
    "..........'..................,....................codkkkkOO0KKXKK0KNNNNNWWWWMMMWWNKOO0Oxl'.................. .....................,ONXO0Nk'...........\n",
    "................... .........,.  .......         'lodkOO00OO00000KKXNNWWWWWWWWWWWWNK00Okdl..............      ....................:kOooKXl............\n",
    ".........'......... .........,.  .........     ..'okkOOOOO00KKKKKKkxXMMMMMMMMMMMMMMNK00Oxdc.....'cl,........ .............''..',;::clloxd:............\n",
    ".........'......... .........,. ...........    ..'dOOOOO0000KKKKKx,'xWMMMMMMMMMMMMMMNK0Okdo;.....,,........  .......,,...,::..,:cccccllc::;...........\n",
    ".........'..................',.  ..  ......     ..':okO0KKKKKKKKx,..;0WMMMMMMMMMWWMWWXOdl:;,.............    ......':;...,c:..,:cccccllc;::,..........\n",
    ".........''.................',. ... ...             ..;lx0KKKKXk,....lNMMMMMMMWNX0xol:,............................':;..';c:..,:cccccll:,,,'..........\n",
    "............................',.....  ..                ..;d0XX0:.....;0WWMMWWXOo;......................  ..........':;...;c:..,:ccccccl:..............\n",
    "\n",
    "                               \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                 ______\n",
    "                /     /\\\n",
    "               /     /##\\\n",
    "              /     /####\\\n",
    "             /     /######\\\n",
    "            /     /########\\\n",
    "           /     /##########\\\n",
    "          /     /#####/\\#####\\\n",
    "         /     /#####/++\\#####\\\n",
    "        /     /#####/++++\\#####\\\n",
    "       /     /#####/\\+++++\\#####\\\n",
    "      /     /#####/  \\+++++\\#####\\\n",
    "     /     /#####/    \\+++++\\#####\\\n",
    "    /     /#####/      \\+++++\\#####\\\n",
    "   /     /#####/        \\+++++\\#####\\\n",
    "  /     /#####/__________\\+++++\\#####\\\n",
    " /                        \\+++++\\#####\\\n",
    "/__________________________\\+++++\\####/\n",
    "\\+++++++++++++++++++++++++++++++++\\##/\n",
    " \\+++++++++++++++++++++++++++++++++\\/\n",
    "  ``````````````````````````````````\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE 1\n",
    "\n",
    "# The cell that performs the simulation can be modified as follows:\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# We run the simulation.\n",
    "\n",
    "# In order for the unit to learn properly, the input patterns need to be presented\n",
    "# many times. Instead of creating input functions capable of presenting all the\n",
    "# patterns, we simulate one pattern presentation at a time. After each presentation\n",
    "# we change the input function used by the source units.\n",
    "\n",
    "n_pres = 100 # number of times some pattern will be presented\n",
    "start_time = time.time() # used to time the simulation\n",
    "times = np.array([]) # used to store the times array from all simulations\n",
    "activs = np.tile([], (len(net.units),1)) # used to store the activities array from all simulations\n",
    "run_activs = [] # auxiliary list used to concatenate activities\n",
    "# <><><><> THE NEXT LINE IS NEW! <><><><><>\n",
    "curr_lrate = syn_pars['lrate'] # current learning rate. Used to gradually decrease the learning rate\n",
    "\n",
    "for pres in range(n_pres):\n",
    "# For each cycle you'll set the input functions and simulate, once with a single pattern,\n",
    "# once with a mix of patterns, as described above   \n",
    "    # first, we present a single pattern\n",
    "    for u in range(n_sources):\n",
    "        net.units[inp_ids[u]].set_function( make_pat_fun(u) )\n",
    "        \n",
    "    sim_dat = net.run(t_pat)  # simulating\n",
    "    last_t = net.sim_time # simulation time after last pattern presentation\n",
    "    times = np.append(times, sim_dat[0])\n",
    "    run_activs.append(sim_dat[1])\n",
    "    \n",
    "    # now one pattern turns into the next\n",
    "    for u in range(n_sources):\n",
    "        net.units[inp_ids[u]].set_function(make_trans_fun(u, last_t))\n",
    "    \n",
    "    sim_dat = net.run(t_trans) # simulating\n",
    "    times = np.append(times, sim_dat[0])\n",
    "    run_activs.append(sim_dat[1])\n",
    "    \n",
    "    # choose the pattern you'll present next\n",
    "    cur_pat = next_pat\n",
    "    next_pat = np.random.choice(4)\n",
    "    \n",
    "    if pres%10 == 0:\n",
    "        print('Finished presentation ' + str(pres))\n",
    "        # <><><><> THIS IS ALSO NEW! <><><><><>\n",
    "        curr_lrate = .9 * curr_lrate\n",
    "        for syn in net.syns[lin_ids[0]]:\n",
    "            syn.lrate = curr_lrate\n",
    "            syn.alpha = curr_lrate * net.min_delay\n",
    "        \n",
    "activs = np.append(activs, np.concatenate(run_activs, axis=1), axis=1)  \n",
    "print('Execution time: %s seconds' % (time.time() - start_time)) \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE 3\n",
    "#--------------- copy-paste ---------------\n",
    "%cd .. \n",
    "from draculab import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "net_params = {\n",
    "    'min_delay' : 0.005, # minimum delay in all the network's connections (in seconds)\n",
    "    'min_buff_size' : 10 } # minimum buffer size. How many values are stored per simulation step. \n",
    "net = network(net_params)\n",
    "\n",
    "n_sigs = 10 # how many sigmoidal units to create\n",
    "sig_params = {\n",
    "    'type' : unit_types.sigmoidal,  # unit_types is an Enum in draculab.py\n",
    "    'init_val' : 0.5, # initial value\n",
    "    'thresh' : .1, # all sigmoidal units will have threshold 1\n",
    "    'slope' : np.random.uniform(0.5, 2., n_sigs), # the slopes come from a random distribution\n",
    "    'tau' : 0.02 } # time constant for the dynamics of all sigmoidal units\n",
    "sig_ids = net.create(n_sigs, sig_params)\n",
    "\n",
    "n_sources = 10 # how many input units to create\n",
    "input_params = {\n",
    "    'type' : unit_types.source,\n",
    "    'init_val' : 0.5,\n",
    "    'function' : lambda t: None } \n",
    "inp_ids = net.create(n_sources, input_params)\n",
    "\n",
    "def create_cosine(ang_freq, phase):\n",
    "    return lambda t: np.cos(ang_freq*(t - phase))\n",
    "\n",
    "for idx, uid in enumerate(inp_ids):\n",
    "    net.units[uid].set_function(create_cosine(2.*np.pi, 0.1*idx))\n",
    "    \n",
    "conn_spec = {\n",
    "    'rule' : 'one_to_one',  # all sources connect to all targets\n",
    "    'delay' : {'distribution': 'uniform', 'low': 0.01, 'high':0.1} }# connection delays will be uniformly distributed\n",
    "syn_spec = {\n",
    "    'type': synapse_types.static, # synapse_types is an Enum in draculab.py\n",
    "    'init_w' : [0.1*n for n in range(n_sigs)] } # the initial weights range from 0. to 0.9\n",
    "net.connect(inp_ids, sig_ids, conn_spec, syn_spec)\n",
    "#--------------------------------------\n",
    "\n",
    "# THE ACTUAL SOLUTION\n",
    "s2s_conn_spec = {\n",
    "    'rule' : 'one_to_one',  \n",
    "    'delay' : 0.01 }\n",
    "s2s_syn_spec = {\n",
    "    'type': synapse_types.static, \n",
    "    'init_w' : 0.5 }\n",
    "target_ids = [(i+1)%n_sigs for i in sig_ids] # assuming sig_ids range from 0 to n_sigs...\n",
    "net.connect(sig_ids, target_ids, s2s_conn_spec, s2s_syn_spec)\n",
    "\n",
    "#-------- more copy-paste ----------\n",
    "sim_time = 10. # simulation time\n",
    "times, unit_acts, _ = net.run(sim_time)\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "# Plot the activity of a single sigmoidal unit\n",
    "plt.subplot(221)\n",
    "plt.plot(times, unit_acts[sig_ids[2]])\n",
    "plt.title('one sigmoidal')\n",
    "# Plot the activity of one input unit\n",
    "plt.subplot(222)\n",
    "plt.plot(times, unit_acts[inp_ids[5]])\n",
    "plt.title('one input')\n",
    "# Plot the activity of all inputs\n",
    "inp_acts = [ unit_acts[u] for u in inp_ids ]\n",
    "plt.subplot(223)\n",
    "plt.plot(times, np.transpose(inp_acts))\n",
    "plt.title('all inputs')\n",
    "# Plot the activity of all sigmoidal units\n",
    "plt.subplot(224)\n",
    "sig_acts = [ unit_acts[u] for u in sig_ids ]\n",
    "plt.plot(times, np.transpose(sig_acts))\n",
    "plt.title('all sigmoidal units')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Using the solution to exercise 1 to visualize the connections made in exercise 3\n",
    "N = len(net.units) # number of units\n",
    "weights = np.zeros((N,N)) \n",
    "for syn_list in net.syns:\n",
    "    for syn in syn_list:\n",
    "        weights[syn.postID, syn.preID] = syn.w\n",
    "\n",
    "fig_ex1 = plt.figure(figsize=(10,10))\n",
    "ax = fig_ex1.add_axes([0., 0., 1., 1.], aspect=1)\n",
    "ax.set_xticks(list(range(N)))\n",
    "ax.set_yticks(list(range(N)))\n",
    "ax.imshow(weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS SCRIPT!!!\n",
    "# Faster visualization for connections\n",
    "\n",
    "# visualizing the connections \n",
    "%matplotlib notebook\n",
    "# The 'notebook' backend is compatible with FuncAnimation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "    \n",
    "# the update function below will use these variables\n",
    "all_coords = [u.coordinates for u in net.units]\n",
    "source = [u.ID for u in net.units]\n",
    "sink = [u.ID for u in net.units]\n",
    "len_source = len(source)\n",
    "len_sink = len(sink)\n",
    "source_0 = source[0]\n",
    "sink_0 = sink[0]\n",
    "\n",
    "# flattening net.syns\n",
    "all_syns = []\n",
    "for syn_list in [net.syns[i] for i in sink]:\n",
    "    all_syns.extend([s for s in syn_list if s.preID in source])\n",
    "\n",
    "# getting lists with the coordinates of all source, sink units\n",
    "source_coords = [u.coordinates for u in [net.units[i] for i in source]]\n",
    "sink_coords = [u.coordinates for u in [net.units[i] for i in sink]]\n",
    "source_x = [c[0] for c in source_coords]\n",
    "source_y = [c[1] for c in source_coords]\n",
    "sink_x = [c[0] for c in sink_coords]\n",
    "sink_y = [c[1] for c in sink_coords]\n",
    "\n",
    "# id2src[n] maps the unit with network id 'n' to its index in the 'source' list\n",
    "id2src = np.array([1e8 for _ in range(len(net.units))], dtype=int) # 1e8 if not in source\n",
    "for src_idx, net_idx in enumerate(source):\n",
    "    id2src[net_idx] = src_idx\n",
    "# id2snk[n] maps the unit with network id 'n' to its index in the 'sink' list\n",
    "id2snk = np.array([1e8 for _ in range(len(net.units))], dtype=int) # 1e8 if not in sink\n",
    "for snk_idx, net_idx in enumerate(sink):\n",
    "    id2snk[net_idx] = snk_idx\n",
    "\n",
    "# setting colors\n",
    "std_src = [0., 0.5, 0., 0.5]\n",
    "std_snk = [0.5, 0., 0., 0.5]\n",
    "big_src = [0., 0., 1., 1.]\n",
    "big_snk = [0., 0., 1., 1.]\n",
    "\n",
    "# constructing figure, axes, path collections\n",
    "conn_fig = plt.figure(figsize=(10,6))\n",
    "ax1 = conn_fig.add_axes([0.02, 0.01, .47, 0.95], frameon=True, aspect=1)\n",
    "ax2 = conn_fig.add_axes([0.51, 0.01, .47, 0.95], frameon=True, aspect=1)\n",
    "src_col1 = ax1.scatter(source_x, source_y, s=2, c=std_src)\n",
    "snk_col1 = ax1.scatter(sink_x, sink_y, s=2, c=std_snk)\n",
    "src_col2 = ax2.scatter(source_x, source_y, s=2, c=std_src)\n",
    "snk_col2 = ax2.scatter(sink_x, sink_y, s=2, c=std_snk)\n",
    "ax1.set_title('sent connections')\n",
    "ax2.set_title('received connections')\n",
    "ax2.set_yticks([])\n",
    "\n",
    "\n",
    "# At each frame we'll visualize the connections arising from a single unit\n",
    "def update(frame): \n",
    "    sou_u = frame%len_source # source unit whose receivers we'll visualize\n",
    "    snk_u = frame%len_sink # sink unit whose senders we'll visualize\n",
    "\n",
    "    # PLOTTING THE RECEIVERS OF sou_u ON THE LEFT AXIS\n",
    "    source_sizes = np.tile(2, len_source)\n",
    "    sink_sizes = np.tile(2, len_sink)\n",
    "    source_colors = np.tile(std_src,(len_source,1))\n",
    "    sink_colors = np.tile(std_snk, (len_sink,1))\n",
    "    source_sizes[sou_u] = 50\n",
    "    source_colors[sou_u] = big_src\n",
    "    # getting targets of projections from the unit 'sou_u'\n",
    "    targets = id2snk[ [syn.postID for syn in all_syns if id2src[syn.preID] == sou_u ] ]\n",
    "    # setting the colors and sizes\n",
    "    sink_colors[targets] = big_snk\n",
    "    sink_sizes[targets] = 15\n",
    "    src_col1.set_sizes(source_sizes)\n",
    "    #ax1.get_children()[0].set_sizes(source_sizes)   # sizes for the source units\n",
    "    snk_col1.set_sizes(sink_sizes)\n",
    "    src_col1.set_color(source_colors)\n",
    "    snk_col1.set_color(sink_colors)\n",
    "\n",
    "    # PLOTTING THE SENDERS TO snk_u ON THE RIGHT AXIS\n",
    "    source_sizes = np.tile(2, len_source)\n",
    "    sink_sizes = np.tile(2, len_sink)\n",
    "    source_colors = np.tile(std_src, (len_source,1))\n",
    "    sink_colors = np.tile(std_snk, (len_sink,1))\n",
    "    sink_sizes[snk_u] = 50\n",
    "    sink_colors[snk_u] = big_snk\n",
    "    # getting senders of projections to the unit 'snk_u\n",
    "    senders = id2src[ [syn.preID for syn in all_syns if id2snk[syn.postID] == snk_u] ]\n",
    "    # setting the colors and sizes\n",
    "    source_colors[senders] = std_src\n",
    "    source_sizes[senders] = 15\n",
    "    src_col2.set_sizes(source_sizes)\n",
    "    snk_col2.set_sizes(sink_sizes)\n",
    "    src_col2.set_color(source_colors)\n",
    "    snk_col2.set_color(sink_colors)\n",
    "\n",
    "    return ax1, ax2,\n",
    "\n",
    "animation = FuncAnimation(conn_fig, update, interval=30, blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
