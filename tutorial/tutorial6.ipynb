{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6\n",
    "Creating complex models:\n",
    "* Creating units with multiport inputs.\n",
    "* Creating new requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "### Units with multiport inputs\n",
    "For some unit models, there may be several types of qualitatively different inputs. An example can be found in the `delta_linear` class of `custom_units.py`. This class, together with the `delta_synapse` class in in `synapses.py` implements a continuous-time version of the _delta_ learning rule.\n",
    "\n",
    "The _delta_ learning rule is one of the most widespread forms of supervised learning in neural networks. Given a _training set_ consisting of  input vectors \n",
    "$(\\bf{x_1}, \\dots, \\bf{x_n})$ and their corresponding desired outptus $(y_1, \\dots, y_n)$, the purpose of the delta rule is to adjust the input weights of a unit so\n",
    "the response to $\\bf{x_i}$ is $y_i$. Without going into details, this can sometimes be achieved by presenting the inputs one by one, each time adjusting the weights using:\n",
    "\n",
    "$\\Delta \\omega_{j} = \\alpha (y - u)x_j$,\n",
    "\n",
    "where $y$ is the desired response to the input, $u$ is the actual response, $x_j$ is the $j$-th component of the input vector, $\\omega_j$ is the corresponding weight, and $\\alpha$ is a learning rate.  \n",
    "To implement this, we require to know not only the input to the unit, but also the desired output. Since the error $e \\equiv y - u$ is used by every synapse,\n",
    "it is computationally efficient to calculate it once in the unit class and make it available to all synapses. Thus, the error is a synaptic _requirement_ that must be updated at every simulation step.\n",
    "\n",
    "This tutorial is a guide to the source code in the `delta_linear`, and `delta_synapse` classes, which illustrate the tools used\n",
    "to create units with multiple input ports, and synapses that use custom requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class delta_linear in module custom_units:\n",
      "\n",
      "class delta_linear(units.unit)\n",
      " |  A linear unit that modifies its weights using a continuous version of the delta rule.\n",
      " |  \n",
      " |  This unit scales its input vector so it has a unit L2 norm. Moreover, there is an implicit bias\n",
      " |  input that is always 1, and whose weight starts at 0 and changes with rate 'bias_lrate'.\n",
      " |  \n",
      " |  Units in this class have 3 input ports. \n",
      " |  Port 0 is for the plastic synapses, which are of the delta_synapse class.\n",
      " |  Port 1 is for the desired value signal, which is used to produce the error.\n",
      " |  Port 2 is for the signal that indicates when to update the synaptic weights.\n",
      " |  \n",
      " |  The weight of the bias input is updated by the unit, whereas the weights of all inputs\n",
      " |  at port 0 are updated by their respective synapses, which must be of the 'delta' type.\n",
      " |  These synapses update their weight using: w' = alpha * error * pre, where alpha controls\n",
      " |  the learning rate, error is the scaled input sum at port 0 (the desired output) minus the \n",
      " |  (fast low-pass filtered) postsynaptic activity (the output), and pre is the\n",
      " |  presynaptic activity.\n",
      " |  \n",
      " |  The delta_linear units have a variable named 'learning', which decays to zero exponentially\n",
      " |  with a time constant given as a paramter. If 'e' stands for learning, e' = -tau_e * e .\n",
      " |  \n",
      " |  When learning > 0.5: \n",
      " |      * The signal at port 2 is ignored. \n",
      " |      * The error transmitted to the synapses is the the desired output (e.g. the signal at\n",
      " |        port 1) minus the current activity. \n",
      " |      * e decays to 0 exponentially.\n",
      " |  When learning <= 0.5:\n",
      " |      * The error is 0 (which cancels plasticity at the synapses).\n",
      " |      * If the scaled sum of inputs at port 2 is smaller than 0.5, learning decays exponentially, \n",
      " |        but if the input is larger than 0.5 then learning is set to the value 1.\n",
      " |  \n",
      " |  The error is a synaptic requirement updated by the method upd_error below.\n",
      " |  After being set to 1, learning will take T = log(2)/tau_e time units to decay back to 0.5.\n",
      " |  During this time any non-zero error signal will cause plasticity at the synapses.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      delta_linear\n",
      " |      units.unit\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, ID, params, network)\n",
      " |      The unit constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          ID, params, network: same as in the parent's constructor.\n",
      " |          n_ports and tau_fast are no longer optional.\n",
      " |              n_ports: number of inputs ports. IT MUST BE SET TO 3.\n",
      " |              tau_fast: Time constant for the fast low-pass filter.\n",
      " |          In addition, params should have the following entries.\n",
      " |              REQUIRED PARAMETERS \n",
      " |              gain: slope of the linear unit.\n",
      " |              tau: time constant of the update dynamics.\n",
      " |              tau_e: time constant for the decay of learning.\n",
      " |              bias_lrate: learning rate of the bias. Requires small values.\n",
      " |      Raises:\n",
      " |          ValueError\n",
      " |  \n",
      " |  derivatives(self, y, t)\n",
      " |      This function returns the derivatives of the state variables at a given point in time.\n",
      " |  \n",
      " |  dt_fun(self, y, s)\n",
      " |      Returns the derivative when state is y, at time substep s.\n",
      " |  \n",
      " |  get_mp_input_sum(self, time)\n",
      " |      The input function of the delta_linear unit.\n",
      " |  \n",
      " |  upd_error(self, time)\n",
      " |      update the error used by delta units.\n",
      " |  \n",
      " |  upd_inp_l2(self, time)\n",
      " |      Update the L2 norm of the inputs at port 0.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from units.unit:\n",
      " |  \n",
      " |  euler_maru_update(self, time)\n",
      " |      Advance the dynamics from time to time+min_delay with the Euler-Maruyama method.\n",
      " |      \n",
      " |      The Euler-Maruyama implementation is basically the same as forward Euler.\n",
      " |      The atol and rtol values are meaningless in this case.\n",
      " |      \n",
      " |      This solver does the buuffer's \"rolling\" by itself.\n",
      " |      The unit needs to have 'mu' and 'sigma' attributes.\n",
      " |      self.mu = 0. # Mean of the white noise\n",
      " |      self.sigma = 0.0 # standard deviation of Wiener process.\n",
      " |  \n",
      " |  euler_update(self, time)\n",
      " |      Advance the dynamics from time to time+min_delay using the forward Euler method. \n",
      " |      \n",
      " |      This implementation uses forward Euler integration. Although this may be\n",
      " |      imprecise and unstable in some cases, it is a first step to implement the\n",
      " |      Euler-Maruyama method. And it's also faster than odeint.\n",
      " |      Notice the atol and rtol network parameters are not used in this case.\n",
      " |      Precision is controlled by the step size, which is min_delay/min_buff_size.\n",
      " |  \n",
      " |  exp_euler_update(self, time)\n",
      " |      Advance the dynamics from time to time+min_delay with the exponential Euler method.\n",
      " |      \n",
      " |      This method can only be used when the unit model has noisy dynamics where the \n",
      " |      activity follows an instaneous input function with a particular decay rate. \n",
      " |      This includes the noisy_linear and noisy_sigmoidal models.\n",
      " |      \n",
      " |      The current version is rectifying ouputs by default.\n",
      " |  \n",
      " |  flat_euler_maru_update(self, time)\n",
      " |      The Euler-Maruyama integration used with network.flat_update3.\n",
      " |  \n",
      " |  flat_euler_update(self, time)\n",
      " |      The forward Euler integration method used with network.flat_update3.\n",
      " |  \n",
      " |  flat_exp_euler_update(self, time)\n",
      " |      The exponential Euler integration used with network.flat_update3.\n",
      " |  \n",
      " |  get_act(self, time)\n",
      " |      Gives you the activity at a previous time 't' (within buffer range).\n",
      " |      \n",
      " |      This version works for units that store their previous activity values in a buffer.\n",
      " |      Units without buffers (e.g. source units) have their own get_act function.\n",
      " |      \n",
      " |      This was the most time-consuming method in draculab (thus the various optimizations).\n",
      " |  \n",
      " |  get_exp_sc_input_sum(self, time)\n",
      " |      Returns the sum of inputs, each scaled by its weight and by a scale factor.\n",
      " |      \n",
      " |      The sum accounts for transmission delays. Input ports are ignored.\n",
      " |      The time argument should be within the range of values stored in the unit's buffer.\n",
      " |      \n",
      " |      The scale factor is applied only to excitatory synapses, and it is the scale_facs value\n",
      " |      set by the upd_exp_scale function. This is the way that exp_dist_sigmoidal units get\n",
      " |      their total input.\n",
      " |  \n",
      " |  get_input_sum(self, time)\n",
      " |      Returns the sum of all inputs at the given time, each scaled by its synaptic weight.\n",
      " |      \n",
      " |      The time argument should be within the range of values stored in the unit's buffer.\n",
      " |      The sum accounts for transmission delays. Input ports are ignored.\n",
      " |  \n",
      " |  get_inputs(self, time)\n",
      " |      Returns a list with the inputs received by the unit from all other units at time 'time'.\n",
      " |      \n",
      " |      The time argument should be within the range of values stored in the unit's buffer.\n",
      " |      \n",
      " |      The returned inputs already account for the transmission delays.\n",
      " |      To do this: in the network's act list the entry corresponding to the unit's ID\n",
      " |      (e.g. self.net.act[self.ID]) is a list; for each i-th entry (a function) retrieve\n",
      " |      the value at time \"time - delays[ID][i]\".\n",
      " |      \n",
      " |      \n",
      " |      This function ignores input ports.\n",
      " |  \n",
      " |  get_lpf_fast(self, steps)\n",
      " |      Get the fast low-pass filtered activity, as it was 'steps' simulation steps before.\n",
      " |  \n",
      " |  get_lpf_mid(self, steps)\n",
      " |      Get the mid-speed low-pass filtered activity, as it was 'steps' simulation steps before.\n",
      " |  \n",
      " |  get_lpf_mid_inp_sum(self)\n",
      " |      Get the latest value of the mid-speed low-pass filtered sum of inputs.\n",
      " |  \n",
      " |  get_lpf_slow(self, steps)\n",
      " |      Get the slow low-pass filtered activity, as it was 'steps' simulation steps before.\n",
      " |  \n",
      " |  get_mp_inputs(self, time)\n",
      " |      Returns a list with all the inputs, arranged by input port.\n",
      " |      \n",
      " |      This method is for units where multiport = True, and that have a port_idx attribute.\n",
      " |      \n",
      " |      The i-th element of the returned list is a numpy array containing the raw (not multiplied\n",
      " |      by the synaptic weight) inputs at port i. The inputs include transmision delays.\n",
      " |      \n",
      " |      The time argument should be within the range of values stored in the unit's buffer.\n",
      " |  \n",
      " |  get_mp_weights(self, time)\n",
      " |      Returns a list with the weights corresponding to the list obtained with get_mp_inputs.\n",
      " |      \n",
      " |      This method is for units where multiport = True, and that have a port_idx attribute.\n",
      " |      \n",
      " |      The i-th element of the returned list is a numpy array with the weights of the\n",
      " |      synapses where port = i.\n",
      " |  \n",
      " |  get_sc_input_sum(self, time)\n",
      " |      Returns the sum of inputs, each scaled by its synaptic weight and by a gain constant.\n",
      " |      \n",
      " |      The sum accounts for transmission delays. Input ports are ignored.\n",
      " |      The time argument should be within the range of values stored in the unit's buffer.\n",
      " |      \n",
      " |      The extra scaling factor is the 'gain' attribute of the synapses. This is useful when\n",
      " |      different types of inputs have different gains applied to them. You then need a unit\n",
      " |      model that calls get_sc_input_sum instead of get_input_sum.\n",
      " |  \n",
      " |  get_weights(self, time)\n",
      " |      Returns a list with the weights corresponding to the input list obtained with get_inputs.\n",
      " |  \n",
      " |  init_buffers(self)\n",
      " |      This method (re)initializes the buffer variables according to the current parameters.\n",
      " |      \n",
      " |      It is useful because new connections may increase self.delay, and thus the size of the buffers.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AssertionError.\n",
      " |  \n",
      " |  init_pre_syn_update(self)\n",
      " |      Configure the pre_syn_update function according to current synaptic requirements.\n",
      " |      \n",
      " |      Correlational learning rules require the pre- and post-synaptic activity, in this\n",
      " |      case low-pass filtered in order to implement a running average. Moreover, for\n",
      " |      heterosynaptic plasticity individual synapses need information about all the\n",
      " |      other synapses on the unit. It is inefficient for each synapse to maintain\n",
      " |      low-pass filtered versions of pre- and post-synaptic activity, as well as to\n",
      " |      obtain by itself all the values required for its update.\n",
      " |      The function pre_syn_update(), initialized by init_pre_syn_update(), \n",
      " |      is tasked with updating all the 'slow' unit variables, which can be either used by\n",
      " |      the synapses, or by the unit itself.\n",
      " |      pre_syn_update() is called once per simulation step (i.e. every min_delay period).\n",
      " |      \n",
      " |      In addition, for each one of the unit's synapses, init_pre_syn_update will initialize \n",
      " |      its delay value.\n",
      " |      \n",
      " |      An extra task done here is to prepare the 'port_idx' list used by units with multiple \n",
      " |      input ports.\n",
      " |      \n",
      " |      init_pre_syn_update is called for a unit everytime network.connect() connects the unit, \n",
      " |      which may be more than once.\n",
      " |      \n",
      " |      Raises:\n",
      " |          NameError, NotImplementedError, ValueError.\n",
      " |  \n",
      " |  odeint_update(self, time)\n",
      " |      Advance the dynamics from time to time+min_delay.\n",
      " |      \n",
      " |      This update function will replace the values in the activation buffer\n",
      " |      corresponding to the latest \"min_delay\" time units, introducing \"min_buff_size\" new values.\n",
      " |      In addition, all the synapses of the unit are updated.\n",
      " |      source and kwta units override this with shorter update functions.\n",
      " |  \n",
      " |  pre_syn_update(self, time)\n",
      " |      Call the update functions for the requirements added in init_pre_syn_update.\n",
      " |  \n",
      " |  solve_ivp_diff(self, t, y)\n",
      " |      The derivatives function used by solve_ivp_update. \n",
      " |      \n",
      " |      solve_ivp requires that the derivatives function has its parameters in the\n",
      " |      opposite of the order used by odeint. Thus, to make it work you need to change\n",
      " |      the order of the arguments in all the derivatives functions, from \n",
      " |      derivatives(self, y, t) to derivatives(self, t, y).\n",
      " |      Also, make sure that the import command at the top is uncommented for solve_ivp.\n",
      " |      One more thing: to use the stiff solvers the derivatives must return a list or \n",
      " |      array, so the returned value must be enclosed in square brackets.\n",
      " |  \n",
      " |  solve_ivp_update(self, time)\n",
      " |      Advance the dynamics from time to time+min_delay.\n",
      " |      \n",
      " |      This update function will replace the values in the activation buffer\n",
      " |      corresponding to the latest \"min_delay\" time units, introducing \"min_buff_size\" new \n",
      " |      values. In addition, all the synapses of the unit are updated.\n",
      " |      source and kwta units override this with shorter update functions.\n",
      " |  \n",
      " |  upd_balance(self, time)\n",
      " |      Updates two numbers called  below, and above.\n",
      " |      \n",
      " |      below = fraction of inputs with rate lower than this unit.\n",
      " |      above = fraction of inputs with rate higher than this unit.\n",
      " |      \n",
      " |      Those numbers are useful to produce a given firing rate distribtuion.\n",
      " |      \n",
      " |      NOTICE: this version does not restrict inputs to exp_rate_dist synapses.\n",
      " |  \n",
      " |  upd_balance_mp(self, time)\n",
      " |      Updates two numbers called  below, and above. Used in units with multiple input ports.\n",
      " |      \n",
      " |      below = fraction of inputs with rate lower than this unit.\n",
      " |      above = fraction of inputs with rate higher than this unit.\n",
      " |      \n",
      " |      Those numbers are useful to produce a given firing rate distribtuion among\n",
      " |      the population of units that connect to the 'rdc_port'.\n",
      " |      \n",
      " |      This is the same as upd_balance, but ports other than the rdc_port are ignored.\n",
      " |  \n",
      " |  upd_diff_avg(self, time)\n",
      " |      Update the average of derivatives from inputs with diff_hebbsnorm synapses.\n",
      " |      \n",
      " |      The values being averaged are not the actual derivatives, but approximations\n",
      " |      which are roughly proportional to them, coming from the difference \n",
      " |      lpf_fast - lpf_mid .\n",
      " |  \n",
      " |  upd_err_diff(self, time)\n",
      " |      Update an approximate derivative of the error inputs used for input correlation learning. \n",
      " |      \n",
      " |      A very simple approach is taken, where the derivative is approximated as the difference\n",
      " |      between the fast and medium low-pass filtered inputs. Each input arrives with its\n",
      " |      corresponding transmission delay.\n",
      " |  \n",
      " |  upd_exp_scale(self, time)\n",
      " |      Updates the synaptic scaling factor used in exp_dist_sigmoidal units.\n",
      " |      \n",
      " |      The algorithm is a multiplicative version of the  one used in exp_rate_dist synapses.\n",
      " |      It scales all excitatory inputs.\n",
      " |  \n",
      " |  upd_exp_scale_mp(self, time)\n",
      " |      Updates the synaptic scaling factors used in multiport ssrdc units.\n",
      " |      \n",
      " |      The algorithm is the same as upd_exp_scale, but only the inputs at the rdc_port\n",
      " |      are considered.\n",
      " |  \n",
      " |  upd_flat_inp_sum(self, time)\n",
      " |      Updates the vector with input sums for each substep of the current step.\n",
      " |  \n",
      " |  upd_flat_mp_inp_sum(self, time)\n",
      " |      The multiport version of upd_flat_inp_sum.\n",
      " |  \n",
      " |  upd_inp_avg_hsn(self, time)\n",
      " |      Update the inp_avg_hsn variable.\n",
      " |  \n",
      " |  upd_inp_vector(self, time)\n",
      " |      Update the inp_vector variable.\n",
      " |  \n",
      " |  upd_lpf_fast(self, time)\n",
      " |      Update the lpf_fast variable.\n",
      " |  \n",
      " |  upd_lpf_mid(self, time)\n",
      " |      Update the lpf_mid variable.\n",
      " |  \n",
      " |  upd_lpf_mid_inp_sum(self, time)\n",
      " |      Update the lpf_mid_inp_sum variable.\n",
      " |  \n",
      " |  upd_lpf_slow(self, time)\n",
      " |      Update the lpf_slow variable.\n",
      " |  \n",
      " |  upd_lpf_slow_mp_inp_sum(self, time)\n",
      " |      Update the slow LPF'd scaled sum of inputs at individual ports, returning them in a list.\n",
      " |  \n",
      " |  upd_mp_inputs(self, time)\n",
      " |      Update the mp_inputs variable.\n",
      " |  \n",
      " |  upd_pos_inp_avg_hsn(self, time)\n",
      " |      Update the pos_inp_avg_hsn variable.\n",
      " |  \n",
      " |  upd_reqs_n_syns(self, time)\n",
      " |      Update the unit's requirements and those of its synapses.\n",
      " |      \n",
      " |      This should be called at every min_delay integration step, after the unit's\n",
      " |      buffers have been updated.\n",
      " |  \n",
      " |  upd_sc_inp_sum_sqhsn(self, time)\n",
      " |      Update the sum of the inputs multiplied by their synaptic weights.\n",
      " |      \n",
      " |      The actual value being summed is lpf_fast of the presynaptic units.\n",
      " |  \n",
      " |  upd_slide_thresh(self, time)\n",
      " |      Updates the threshold of exp_dist_sig_thr units and some other 'trdc' units.\n",
      " |      \n",
      " |      The algorithm is an adapted version of the  one used in exp_rate_dist synapses.\n",
      " |  \n",
      " |  upd_slide_thresh_shrp(self, time)\n",
      " |      Updates the threshold of trdc units when input at 'sharpen' port is larger than 0.5 .\n",
      " |      \n",
      " |      The algorithm is based on upd_slide_thresh.\n",
      " |  \n",
      " |  upd_sq_lpf_slow(self, time)\n",
      " |      Update the sq_lpf_slow variable.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from units.unit:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can begin by looking at the docstring of the two classes\n",
    "from draculab import *\n",
    "help(delta_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class delta_synapse in module synapses:\n",
      "\n",
      "class delta_synapse(synapse)\n",
      " |  A synapse that implements a continuous version of the delta rule.\n",
      " |  \n",
      " |  The discrete delta rule produces a weight update given by:\n",
      " |  Delta_w = alpha * (des - post) * pre, \n",
      " |  where alpha is a learning rate, des is a desired output for the postsynaptic unit,\n",
      " |  post is the output of the postsynaptic unit, and pre is the input from the\n",
      " |  presynaptic unit.\n",
      " |  \n",
      " |  The version implemented here assumes that the error (des-post) is provided by the \n",
      " |  postsynaptic unit, and has weight dynamics given by:\n",
      " |  w' = alpha * error * pre.\n",
      " |  \n",
      " |  An alternative version (commented-out code) is:\n",
      " |  w' = alpha * error * (pre -pre_lpf_slow) \n",
      " |  \n",
      " |  Weight clipping is used to ensure that the weights of excitatory synapses don't\n",
      " |  become negative, and the weights of inhibitory synapses don't become positive. To\n",
      " |  decide whether a synapse is excitatory or inhibitory, the value of 'init_w' is used.\n",
      " |  When init_w = 0, the synapse is assumed to be excitatory.\n",
      " |  \n",
      " |  This synapse is meant to be used with one of the delta_* unit models.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      delta_synapse\n",
      " |      synapse\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, params, network)\n",
      " |      The class constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          params: same as the parent class, with an addition\n",
      " |          REQUIRED PARAMETERS\n",
      " |          lrate: Learning rate. A scalar value that will multiply the derivative of the weight.\n",
      " |      \n",
      " |      Warnings:\n",
      " |          UserWarning when connecting to a non-delta unit.\n",
      " |  \n",
      " |  update(self, time)\n",
      " |      Update the weight using the delta rule.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from synapse:\n",
      " |  \n",
      " |  get_w(self, time)\n",
      " |      Returns the current synaptic weight. \n",
      " |      \n",
      " |      The 'time' argument is currently not used.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from synapse:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(delta_synapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0,  1,  2,  3],\n",
       "        [ 8,  9, 10, 11]]), array([[4, 5, 6, 7]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "### ei_net\n",
    "Now we will create a delta unit and test it using random input vectors with unit norm.\n",
    "The desired output will be the norm of the projection of the input vector with a given vector $\\bf{v}$.\n",
    "If the learning algorithm works, the weight vector of the delta unit must approach $\\bf{v}$.\n",
    "\n",
    "To create this simulation we use the `ei_net` class from `ei_net.py`.  \n",
    "This class is used to run simulations involving three different populations, called **e**, **i**, and **x**.  \n",
    "These three populations are meant to contain excitatory, inhibitory, and source units respectively. An instance of the `ei_net` class contains default parameter dictionaries for the three populations, and for their connections. In theory we could just create an instance of `ei_net`, run `ei_net.build`, and then start running simulations with `ei_net.run`. Of course, those simulations would not use the network we want to simulate, so we need to adapt the parameters of `ei_net` for this end.\n",
    "\n",
    "We want the **e** population to contain a single `delta_linear` unit, the **i** population to be empty, and the **x** population to contain __inp_dim__ source units, where __inp_dim__ stands for the dimensionality of the input vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Create the input vectors\n",
    "inp_dim = 10  # dimensionality of the input vectors\n",
    "n_inp = 100  # number of input vectors\n",
    "inps = np.zeros((inp_dim, n_inp))\n",
    "for col in range(n_inp):\n",
    "    vec = np.random.uniform(0., 1., inp_dim)\n",
    "    inps[:, col] = vec / np.linalg.norm(vec)\n",
    "    \n",
    "# Create the desired outputs\n",
    "v = np.zeros(inp_dim)\n",
    "v[0::2] = 1. # about half of the entries are non-zero\n",
    "v = v / np.linalg.norm(v)\n",
    "des_out = np.zeros(n_inp)\n",
    "for idx in range(n_inp):\n",
    "    des_out[idx] = np.dot(v, inps[:, idx])\n",
    "\n",
    "# Specify how long you will present each input\n",
    "pres_time = 1.\n",
    "\n",
    "# These methods return functions providing the inputs as continuous time functions\n",
    "def cont_input(entry, pres_time):\n",
    "    return lambda t : ( inps[entry,int(t//pres_time)] + ((t%pres_time)/pres_time) *\n",
    "                      (inps[entry,max(int(t//pres_time)+1, n_inp-1)] - inps[entry,int(t//pres_time)]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14970888 0.13771542 0.17286141 0.21396512 0.46388254 0.31884652\n",
      " 0.36345077 0.2509728  0.23359477 0.17816396]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf2w1SLO/FY/GAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "inp2 = cont_input(2, pres_time)\n",
    "print(inps[2,0:10])\n",
    "ts = np.linspace(0,10,100)\n",
    "plt.plot(ts, [inp2(t) for t in ts], '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
