{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tutorial3.ipynb\n",
    "\n",
    "A network of excitatory and inhibitory units with plastic synapses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous tutorials have already provided all the tools required to create more complex simulations. In this tutorial a network with the following properties will be created:\n",
    "* It will have 3 populations of units, called `exc`, `inh`, and `inp`. Those populations will have excitatory, inhibitory, and source units respectively.\n",
    "* Each population will be arranged in a NxN grid where each unit is 1 length unit away from its neighbours. The grids have periodic boundaries, so units at the very top of the grid are nearby units at the bottom, and units at the far left are close to units on the right.\n",
    " * Excitatory units send projections to nearby excitatory units (using a 'disk' mask), and to inhibitory units at intermediate distances (using an 'annular' mask). E-E projections use Hebbian learning with substractive normalization, whereas E-I connections are static. \n",
    " * Inhibitory units send projections to nearby excitatory units. These connections use a \"homeostatic\" learning rule that maintains a desired level of activity in excitatory units, as described [here](http://www.pnas.org/content/103/44/16526.short?related-urls=yes&legid=pnas;103/44/16526).\n",
    " * Input units send projections to nearby units.\n",
    "\n",
    "What is expected is that the units in the network will self-organize into groups that respond to particular inputs.\n",
    "\n",
    "It will become obvious that writing this simulation involves typing a lot of parameters, and writing code to visualize things. For these reason we create classes that help with these tasks. The main aim of the tutorial is to show users one particular approach to write a more complex simulation. It is not necessary to follow every line of code, just execute the cells, get the general idea, and read the methods that seem interesting. A more mature approach will be shown with the `ei_net` and `ei_network` modules.\n",
    "\n",
    "Although the properties of the network may be interesting, numerical analysis of simulation results is beyond the scope of this tutorial. On the other hand, many visualization procedures are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "A network where units respond selectively to inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cortical neurons in primary sensory regions tend to respond to particular stimuli. A prominent example is macaque primary visual cortex, where neurons respond to particular colors, orientations, and directions of movement (see the introduction [here](https://www.sciencedirect.com/science/article/pii/S096098221731521X)).\n",
    "\n",
    "A large number of models exist to explain how neurons develop this *selectivity*. In here we take some basic features of those models to create a layer with plastic connections, and provide a variety of inputs. We can then ask whether the units in our layer resemble real neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "from draculab import *\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a lot of parameters. It is convenient to keep them all in one place. In this case a class is created for this puprpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1,
     7
    ]
   },
   "outputs": [],
   "source": [
    "class parameters():\n",
    "    \"\"\"\n",
    "        Instances of this class contain all the parameters used by the 'selection' class.\n",
    "        \n",
    "        All parameters derived from other parameters will be recalculated in \n",
    "        selection.__init__ . They're here too for readability.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        ########################## Here be all parameters\n",
    "        # NETWORK PARAMETERS \n",
    "        self.md = 0.1 # minimum delay in the network\n",
    "        self.min_buff_size = 5 # minimum buffer size\n",
    "        self.rtol = 1e-4 # relative tolerance of the ODE solver\n",
    "        self.atol = 1e-4 # absolute tolerance of the ODE solver\n",
    "        self.N = 5 # The network's layers will have size NxN\n",
    "        N = self.N # for brevity\n",
    "        self.L = N/2. + 2./N # side length of rectangle with the square grids.\n",
    "        L = self.L\n",
    "        \n",
    "        # EXCITATORY UNIT PARAMETERS\n",
    "        self.exc_tau = np.random.uniform(2., 3.5, N*N)   # time constants\n",
    "        self.exc_init_val = np.random.uniform(0.1, 0.6, N*N)  # initial activations (around IE_des_act)\n",
    "        self.exc_tau_fast = 0.2  # time constant of the fast low-pass filter\n",
    "        self.exc_tau_slow = 20.  # time constant of the slow low-pass filter (for BCM)\n",
    "        self.fe_thr = 0.3 # threshold of the f-I curve\n",
    "        self.fe_eps = 0.2 # epsilon parameter of the f-I curve\n",
    "        # geometrical arrangement of the excitatory units\n",
    "        self.exc_shape = 'sheet'\n",
    "        self.exc_extent = [L, L]\n",
    "        self.exc_arrangement = 'grid'\n",
    "        self.exc_rows = N\n",
    "        self.exc_columns = N\n",
    "        self.exc_center = [0., 0.]\n",
    "        \n",
    "        # INHIBITORY UNIT PARAMETERS\n",
    "        self.inh_tau = np.random.uniform(2.5, 4., N*N)   # time constants\n",
    "        self.inh_init_val = np.random.uniform(0.1, 0.6, N*N)  # initial activations\n",
    "        self.inh_tau_fast = 0.2  # time constant of the fast low-pass filter\n",
    "        self.inh_tau_slow = 20.  # time constant of the slow low-pass filter (for BCM)\n",
    "        self.fi_thr = 0.4 # threshold of the f-I curve\n",
    "        self.fi_eps = 0.2 # epsilon parameter of the f-I curve\n",
    "        # geometrical arrangement of the inhibitory units\n",
    "        self.inh_shape = 'sheet'\n",
    "        self.inh_extent = [L, L]\n",
    "        self.inh_arrangement = 'grid'\n",
    "        self.inh_rows = N\n",
    "        self.inh_columns = N\n",
    "        self.inh_center = [0., 0.]\n",
    "        \n",
    "        # INPUT UNIT PARAMETERS\n",
    "        self.inp_init_val = 0.2 # initial activation\n",
    "        self.inp_tau_fast = 0.2 # time constant of the fast low-pass filter\n",
    "        # geometrical arrangement of the input units\n",
    "        self.inp_shape = 'sheet'\n",
    "        self.inp_extent = [L, L]\n",
    "        self.inp_arrangement = 'grid'\n",
    "        self.inp_rows = N\n",
    "        self.inp_columns = N\n",
    "        self.inp_center = [0., 0.]\n",
    "        \n",
    "        # E-I CONNECTIONS\n",
    "        self.EI_connection_type = 'convergent'\n",
    "        self.EI_mask = {'annular':{'inner_radius' : 1.1, 'outer_radius':4.1}}\n",
    "        self.EI_kernel = {'linear' : {'c' : 1., 'a' : 0.2}}\n",
    "        self.EI_delays = {'linear' : {'c' : self.md, 'a' : 0.3}}\n",
    "        self.EI_weights = {'uniform' : {'low' : 0.5, 'high' : 0.8}}\n",
    "        self.EI_edge_wrap = True\n",
    "        self.EI_boundary = {'center' : [0.,0.], 'extent' : [L, L]}\n",
    "        self.EI_type = synapse_types.static\n",
    "        \n",
    "        # E-E CONNECTIONS\n",
    "        self.EE_connection_type = 'divergent'\n",
    "        self.EE_mask = {'circular':{'radius':2.}}\n",
    "        self.EE_kernel = {'gaussian' : {'p_center' : 1., 'sigma' : 1.}}\n",
    "        self.EE_delays = {'linear' : {'c' : self.md, 'a' : 0.3}}\n",
    "        self.EE_weights =  {'uniform' : {'low' : 0.1, 'high' : 0.6}}\n",
    "        self.EE_edge_wrap = True\n",
    "        self.EE_boundary = {'center' : [0.,0.], 'extent' : [L, L]}\n",
    "        self.EE_type = synapse_types.sq_hebbsnorm \n",
    "        self.EE_lrate = 1./200. # learning rate\n",
    "        self.EE_omega = 2.5  # sum of squared EE weights \n",
    "        \n",
    "        # I-E CONNECTIONS\n",
    "        self.IE_connection_type = 'divergent'\n",
    "        self.IE_mask = {'circular':{'radius':2.}}\n",
    "        self.IE_kernel = {'gaussian' : {'p_center' : 1.4, 'sigma' : 1.}}\n",
    "        self.IE_delays = {'linear' : {'c' : self.md, 'a' : 0.3}}\n",
    "        self.IE_weights =  {'uniform' : {'low' : -0.6, 'high' : -0.1}}\n",
    "        self.IE_edge_wrap = True\n",
    "        self.IE_boundary = {'center' : [0.,0.], 'extent' : [L, L]}\n",
    "        self.IE_type = synapse_types.homeo_inh\n",
    "        self.IE_lrate = 1./100. \n",
    "        self.IE_des_act = 0.3\n",
    "        \n",
    "        # INP_EXC CONNECTIONS\n",
    "        self.PE_connection_type = 'divergent'\n",
    "        self.PE_mask = {'circular':{'radius':3.5}}\n",
    "        self.PE_kernel = 0.6\n",
    "        self.PE_delays = {'linear' : {'c' : self.md, 'a' : 0.3}}\n",
    "        self.PE_weights = {'uniform' : {'low' : 0.3, 'high' : 0.5}}\n",
    "        self.PE_edge_wrap = True\n",
    "        self.PE_boundary = {'center' : [0.,0.], 'extent' : [L, L]}\n",
    "        self.PE_type = synapse_types.bcm\n",
    "        self.PE_lrate = 1./200.\n",
    "        \n",
    "        # INP_INH CONNECTIONS\n",
    "        self.PI_connection_type = 'divergent'\n",
    "        self.PI_mask = {'circular':{'radius':3.5}}\n",
    "        self.PI_kernel = 0.6\n",
    "        self.PI_delays = {'linear' : {'c' : self.md, 'a' : 0.3}}\n",
    "        self.PI_weights = {'uniform' : {'low' : 0.3, 'high' : 0.5}}\n",
    "        self.PI_edge_wrap = True\n",
    "        self.PI_boundary = {'center' : [0.,0.], 'extent' : [L, L]}\n",
    "        self.PI_type = synapse_types.bcm\n",
    "        self.PI_lrate = 1./200.\n",
    "        \n",
    "        # PATTERN PRESENTATION\n",
    "        self.t_pat = 20. # time each pattern will be presented\n",
    "        self.t_trans = 5. # length of transition period between patterns\n",
    "        self.c = 1./self.t_trans # auxiliary variable for make_fun2\n",
    "        self.pat_type = 'lines' # see selection.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also useful to create a class that contains all the procedures that will be repeatedly used during simulations. That is the role of the `selection` class.\n",
    "\n",
    "The `selection` class is initialized with a parameter object, and then its `build` procedure is invoked to create a draculab network as specified in the parameter object. Additionaly, `build` also creates input patterns, which can be one of three types: \"random\", \"snake\", or \"lines\". The type of input is specified in the `pat_type` attribute of the parameters object.\n",
    "\n",
    "Once the network has been built, simulations can be run with the `run` procedure.\n",
    "\n",
    "Other methods in the `selection` class will be shown later. These include:\n",
    "* `animate_responses` -- creates an animation of how much each unit activated in response to each input pattern.\n",
    "* `display_inputs` -- creates a grid image with all the input patterns.\n",
    "* `view_weight_grid` -- visualize the synaptic weigths in a grid of images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     125,
     196,
     199,
     202,
     205,
     226,
     233,
     239,
     341,
     373,
     385,
     403
    ]
   },
   "outputs": [],
   "source": [
    "class selection():\n",
    "    def __init__(self, p):\n",
    "        \"\"\" Initialize parameter dictionaries using the parameter object p. \"\"\"\n",
    "        # optionally, seed the random number generator\n",
    "        #np.random.seed(54321)\n",
    "        \n",
    "        ########################## Initialize derived parameters\n",
    "        N = p.N; # N is used often. Might as well make a local copy.\n",
    "        p.L = N/2. + 2./N # side length of the square unit grids   \n",
    "        L = p.L\n",
    "        p.exc_tau = np.random.uniform(2., 3.5, N*N)   # time constants\n",
    "        p.exc_init_val = np.random.uniform(0., 0.6, N*N)  # initial activations\n",
    "        p.exc_extent = [L, L]\n",
    "        p.exc_rows = N\n",
    "        p.exc_columns = N\n",
    "        p.inh_tau = np.random.uniform(2.5, 4., N*N)   # time constants\n",
    "        p.inh_init_val = np.random.uniform(0., 0.6, N*N)  # initial activations\n",
    "        p.inh_extent = [L, L]\n",
    "        p.inh_rows = N\n",
    "        p.inh_columns = N\n",
    "        p.inp_extent = [L, L]\n",
    "        p.inp_rows = N\n",
    "        p.inp_columns = N\n",
    "        p.EI_boundary = {'center' : [0.,0.], 'extent' : [L, L]}\n",
    "        p.EI_delays['linear']['c'] = p.md\n",
    "        p.EE_boundary = {'center' : [0.,0.], 'extent' : [L, L]}\n",
    "        p.EE_delays['linear']['c'] = p.md\n",
    "        p.IE_boundary = {'center' : [0.,0.], 'extent' : [L, L]}\n",
    "        p.IE_delays['linear']['c'] = p.md\n",
    "        p.PE_boundary = {'center' : [0.,0.], 'extent' : [L, L]}\n",
    "        p.PE_delays['linear']['c'] = p.md\n",
    "        p.PI_boundary = {'center' : [0.,0.], 'extent' : [L, L]}\n",
    "        p.PI_delays['linear']['c'] = p.md\n",
    "        # stuff used to create input functions\n",
    "        self.t_trans = p.t_trans\n",
    "        self.c = 1./self.t_trans # auxiliary variable for make_fun2\n",
    "        self.t_pat = p.t_pat\n",
    "        self.params = p\n",
    "        \n",
    "        ########################## Initialize all the parameter dictionaries \n",
    "        self.net_params = {'min_delay' : p.md, \n",
    "                           'min_buff_size' : p.min_buff_size, \n",
    "                           'rtol':p.rtol, \n",
    "                           'atol':p.atol } \n",
    "        self.exc_params = {'tau' : p.exc_tau,\n",
    "                           'function' : self.make_fe(p.fe_thr, p.fe_eps), \n",
    "                           'type' : unit_types.custom_fi, \n",
    "                           'init_val' : p.exc_init_val, \n",
    "                           'tau_fast' : p.exc_tau_fast, \n",
    "                           'tau_slow' : p.exc_tau_slow } # tau_slow vs lrate controls stability of BCM\n",
    "        self.exc_geom = {'shape' : p.exc_shape, \n",
    "                         'extent' : p.exc_extent, \n",
    "                         'arrangement' : p.exc_arrangement, \n",
    "                         'rows' : p.exc_rows, \n",
    "                         'columns' : p.exc_columns, \n",
    "                         'center' : p.exc_center }\n",
    "        self.inh_params = {'tau' :p.inh_tau, \n",
    "                           'function' : self.make_fi(p.fi_thr, p.fi_eps), \n",
    "                           'type' : unit_types.custom_fi, \n",
    "                           'init_val' : p.inh_init_val, \n",
    "                           'tau_fast' : p.inh_tau_fast, \n",
    "                           'tau_slow' : p.inh_tau_slow }\n",
    "        self.inh_geom = {'shape' : p.inh_shape, \n",
    "                         'extent' : p.inh_extent, \n",
    "                         'arrangement' : p.inh_arrangement, \n",
    "                         'rows' : p.inh_rows, \n",
    "                         'columns' : p.inh_columns, \n",
    "                         'center' : p.inh_center }\n",
    "        self.inp_params = {'type' : unit_types.source, \n",
    "                           'init_val' : p.inp_init_val, \n",
    "                           'tau_fast' : p.inp_tau_fast, \n",
    "                           'function' : lambda x: None }\n",
    "        self.inp_geom = {'shape' : p.inp_shape, \n",
    "                         'extent' : p.inp_extent, \n",
    "                         'arrangement' : p.inp_arrangement, \n",
    "                         'rows' : p.inp_rows, \n",
    "                         'columns' : p.inp_columns, \n",
    "                         'center' : p.inp_center }\n",
    "        self.EI_conn = {'connection_type' : p.EI_connection_type,\n",
    "                        'mask' : p.EI_mask,\n",
    "                        'kernel' : p.EI_kernel,\n",
    "                        'delays' : p.EI_delays,\n",
    "                        'weights' : p.EI_weights,\n",
    "                        'edge_wrap' : p.EI_edge_wrap,\n",
    "                        'boundary' : p.EI_boundary }\n",
    "        self.EI_syn = {'type' : p.EI_type }\n",
    "        self.EE_conn = {'connection_type' : p.EE_connection_type,\n",
    "                        'mask' : p.EE_mask,\n",
    "                        'kernel' : p.EE_kernel,\n",
    "                        'delays' : p.EE_delays,\n",
    "                        'weights' : p.EE_weights,\n",
    "                        'edge_wrap' : p.EE_edge_wrap,\n",
    "                        'boundary' : p.EE_boundary }\n",
    "        self.EE_syn = {'type' : p.EE_type, \n",
    "                       'lrate' : p.EE_lrate, \n",
    "                       'omega' : p.EE_omega } \n",
    "        self.IE_conn = {'connection_type' : p.IE_connection_type,\n",
    "                        'mask' : p.IE_mask,\n",
    "                        'kernel' : p.IE_kernel,\n",
    "                        'delays' : p.IE_delays,\n",
    "                        'weights' : p.IE_weights,\n",
    "                        'edge_wrap' : p.IE_edge_wrap,\n",
    "                        'boundary' : p.IE_boundary }\n",
    "        self.IE_syn = {'type' : p.IE_type, \n",
    "                       'lrate' : p.IE_lrate, \n",
    "                       'des_act' : p.IE_des_act }\n",
    "        self.PE_conn = {'connection_type' : p.PE_connection_type,\n",
    "                        'mask' : p.PE_mask,\n",
    "                        'kernel' : p.PE_kernel,\n",
    "                        'delays' : p.PE_delays,\n",
    "                        'weights' : p.PE_weights,\n",
    "                        'edge_wrap' : p.PE_edge_wrap,\n",
    "                        'boundary' : p.PE_boundary }\n",
    "        self.PE_syn = {'lrate' : p.PE_lrate, \n",
    "                       'type' : p.PE_type }\n",
    "        self.PI_conn = {'connection_type' : p.PI_connection_type,\n",
    "                        'mask' : p.PI_mask,\n",
    "                        'kernel' : p.PI_kernel,\n",
    "                        'delays' : p.PI_delays,\n",
    "                        'weights' : p.PI_weights,\n",
    "                        'edge_wrap' : p.PI_edge_wrap,\n",
    "                        'boundary' : p.PI_boundary }\n",
    "        self.PI_syn = {'lrate' : p.PI_lrate, \n",
    "                       'type' : p.PI_type }\n",
    "        \n",
    "    def build(self):            \n",
    "        topo = topology() # the topology class. Used to create spatially patterned connections\n",
    "        #build network\n",
    "        self.net = network(self.net_params)\n",
    "        # build units\n",
    "        self.exc = topo.create_group(self.net, self.exc_geom, self.exc_params)\n",
    "        self.inh = topo.create_group(self.net, self.inh_geom, self.inh_params)\n",
    "        self.inp = topo.create_group(self.net, self.inp_geom, self.inp_params)\n",
    "        # build connections\n",
    "        topo.topo_connect(self.net, self.exc, self.inh, self.EI_conn, self.EI_syn)\n",
    "        topo.topo_connect(self.net, self.exc, self.exc, self.EE_conn, self.EE_syn)\n",
    "        topo.topo_connect(self.net, self.inh, self.exc, self.IE_conn, self.IE_syn)\n",
    "        topo.topo_connect(self.net, self.inp, self.exc, self.PE_conn, self.PE_syn)\n",
    "        topo.topo_connect(self.net, self.inp, self.inh, self.PI_conn, self.PI_syn)\n",
    "        \n",
    "        # create the input patterns\n",
    "        N = self.inp_geom['rows'] # number of patterns based on input layer size\n",
    "        if self.params.pat_type == 'random':\n",
    "            n_pat = int(round(1.5*N))  # number of different patterns\n",
    "            n_ones = int(round(N*N)/3) # number of ones in the input patterns\n",
    "            basic_pat = np.array( [1.]*n_ones + [0.]*(N*N - n_ones) )\n",
    "            basic_pat = basic_pat/np.sqrt(sum(basic_pat)) # normalizing\n",
    "            self.patterns = [basic_pat.copy() for i in range(n_pat)]\n",
    "            for pat in self.patterns:\n",
    "                np.random.shuffle(pat)\n",
    "        elif self.params.pat_type == 'snake': # intersecting lines\n",
    "            n_pat = int(round(1.5*N))  # number of different patterns\n",
    "            length = int(round(N*N/3.))\n",
    "            advance = int(round(N*N/n_pat))\n",
    "            base = np.zeros(N*N)\n",
    "            base[0:length] = np.ones(length)/np.sqrt(length)\n",
    "            self.patterns = [np.zeros(N*N) for _ in range(n_pat)]\n",
    "            for pat in range(n_pat):\n",
    "                self.patterns[pat] = np.roll(base, pat*advance)\n",
    "        elif self.params.pat_type == 'lines': # separate lines\n",
    "            n_pat = N  # number of different patterns\n",
    "            self.patterns = [np.zeros((N,N)) for _ in range(n_pat)]\n",
    "            for num,pat in enumerate(self.patterns):\n",
    "                if num < N:\n",
    "                    pat[:,num] = np.ones(N)\n",
    "                    self.patterns[num] = pat.reshape(N*N, order='F') \n",
    "                    # the conversion from shape N*N to shape (N,N) must follow the index-location\n",
    "                    # relation created by create_group using grid arrangement\n",
    "        \n",
    "        # print average number of connections of each type\n",
    "        sum_ee = 0 # number of e-e connections\n",
    "        sum_ei = 0\n",
    "        sum_ie = 0\n",
    "        sum_pe = 0 # number of input to exc connections\n",
    "        sum_pi = 0\n",
    "        for syn_list in self.net.syns:\n",
    "            for syn in syn_list:\n",
    "                if syn.postID in self.exc:\n",
    "                    if syn.preID in self.exc:\n",
    "                        sum_ee += 1\n",
    "                    elif syn.preID in self.inh:\n",
    "                        sum_ie += 1\n",
    "                    else:\n",
    "                        sum_pe += 1\n",
    "                elif syn.postID in self.inh:\n",
    "                    if syn.preID in self.exc:\n",
    "                        sum_ei += 1\n",
    "                    else:\n",
    "                        sum_pi += 1\n",
    "        Nsq = self.params.N * self.params.N\n",
    "        print(\"Average number of incoming EE connections: %f\" % (sum_ee/Nsq))\n",
    "        print(\"Average number of incoming EI connections: %f\" % (sum_ei/Nsq))\n",
    "        print(\"Average number of incoming IE connections: %f\" % (sum_ie/Nsq))\n",
    "        print(\"Average number of incoming PE connections: %f\" % (sum_pe/Nsq))\n",
    "        print(\"Average number of incoming PI connections: %f\" % (sum_pi/Nsq))\n",
    "        \n",
    "    def make_fe(self, th, eps): # returns the activation function of excitatory units\n",
    "        return lambda x : np.sqrt( eps * np.log( 1. + np.exp( (x - th)/eps ) ) )\n",
    "    \n",
    "    def make_fi(self, th, eps): # returns the activation function of inhibitory units\n",
    "        return lambda x: eps * np.log( 1. + np.exp( (x - th)/eps ) ) \n",
    "    \n",
    "    def make_pulse(self, t_init, t_end): # returns f(t) = 1 if t_init < t < t_end, 0 otherwise\n",
    "        return lambda t : 1. if (t_init < t and t < t_end) else 0.\n",
    "    \n",
    "    def make_sin_pulse(self, t_init, t_end, per): # A stimulus function\n",
    "        return lambda t : 1. + np.sin( np.pi*( 2.*(t - t_init)/per - 0.5 ) ) if (t_init < t and t < t_end) else 0.\n",
    "    \n",
    "    def plot_stuff(self, data): \n",
    "        N = self.params.N\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        upper = 1.1*max([max(data[1][u]) for u in self.exc+self.inp+self.inh])\n",
    "        for r in range(N):\n",
    "            for c in range(1,N):\n",
    "                i = N*r + c\n",
    "                ax = fig.add_subplot(N,N,i+1)\n",
    "                ax.clear()\n",
    "                plt.ylim(-0.02, upper)\n",
    "                ax.plot(data[0], data[1][self.exc[i]], 'b', data[0], data[1][self.inh[i]], 'r',\n",
    "                        data[0], data[1][self.inp[i]], 'k', figure=fig)\n",
    "                if c>1:\n",
    "                    ax.get_yaxis().set_ticks([])\n",
    "                if r<N-1:\n",
    "                    ax.get_xaxis().set_ticks([])              \n",
    "        plt.show()\n",
    "        \n",
    "    def make_fun1(self, cur_pat, idx):  \n",
    "        # This creates a constant function with value: patterns[cur_pat][idx]\n",
    "        # thus avoiding a scoping problem that is sometimes hard to see:\n",
    "        # https://eev.ee/blog/2011/04/24/gotcha-python-scoping-closures/\n",
    "        fun = lambda t : self.patterns[cur_pat][idx]\n",
    "        return fun\n",
    "\n",
    "    def make_fun2(self, cur_pat, next_pat, idx, last_t):\n",
    "        # Creates a function for the pattern transition\n",
    "        fun = lambda t : self.c * ( (self.t_trans - (t-last_t))*self.patterns[cur_pat][idx] +\n",
    "                                    (t-last_t)*self.patterns[next_pat][idx] )\n",
    "        return fun\n",
    "\n",
    "    def run(self, n_pres, n_disp, flat=False):\n",
    "        \"\"\" Run a simulation.\n",
    "            \n",
    "            Args:\n",
    "                n_pres: (int) number of times an input pattern will be presented. \n",
    "                n_disp: (int) number of times outputs will be displayed during the simulation.\n",
    "        \"\"\"\n",
    "        %matplotlib inline\n",
    "        N = self.params.N\n",
    "        if flat:\n",
    "            run = self.net.flat_run\n",
    "        else:\n",
    "            run = self.net.run\n",
    "        n_pat = len(self.patterns) # variable for number of distinct patterns\n",
    "        if n_disp > 0:\n",
    "            display = [int(round(n)) for n in (n_pres/n_disp)*np.array(range(n_disp+1))] # when to display info\n",
    "        else:\n",
    "            display = [0]\n",
    "        idx_d = 0 # index for display data\n",
    "        self.exc_w = [[] for _ in range(n_disp+1)]  # to show the evolution of excitatory connections\n",
    "        self.inh_w = [[] for _ in range(n_disp+1)]  # to show the evolution of inhibitory connections\n",
    "        self.inp_w = [[] for _ in range(n_disp+1)]  # to show the evolution of input connections\n",
    "        \n",
    "        cur_pat = np.random.randint(n_pat)  # current pattern\n",
    "        next_pat = np.random.randint(n_pat) # next pattern\n",
    "        # Explanation of all_avg_res is below\n",
    "        self.all_avg_res = [[np.zeros(N*N) for _ in range(n_pat)] for _ in range(n_pres)]\n",
    "        \n",
    "        for pres in range(n_pres):\n",
    "            # For each cycle you'll set the input functions and simulate, \n",
    "            # once with a single pattern, once with a mix of patterns\n",
    "            # first, we present a single pattern\n",
    "            for u in range(len(self.inp)):\n",
    "                self.net.units[self.inp[u]].set_function( self.make_fun1(cur_pat, u) )\n",
    "    \n",
    "            start_time = time.time()\n",
    "            times, units, plants = run(self.t_pat)  # simulating\n",
    "            last_t = self.net.sim_time # simulation time after last pattern presentation\n",
    "    \n",
    "            #self.plot_stuff((times,units))\n",
    "            #print('Fixed pattern presented: ' + str(cur_pat))\n",
    "            \n",
    "            # store the average activation level for each excitatory unit\n",
    "            if pres > 0:\n",
    "                for pats in range(n_pat):\n",
    "                    if pats != cur_pat:\n",
    "                        self.all_avg_res[pres][pats] = self.all_avg_res[pres-1][pats].copy()\n",
    "            for u in range(N*N):\n",
    "                self.all_avg_res[pres][cur_pat][u] = sum(units[self.exc[u]]) / len(units[self.exc[u]])\n",
    "            \n",
    "            # now one pattern turns into the next\n",
    "            for u in range(len(self.inp)):\n",
    "                self.net.units[self.inp[u]].set_function(self.make_fun2(cur_pat, next_pat, u, last_t))\n",
    "    \n",
    "            times2, units2, plants2 = run(self.t_trans) # simulating\n",
    "    \n",
    "            print('Execution time for iteration %d is %s seconds' % (pres, (time.time() - start_time)) )\n",
    "            #self.plot_stuff((times2,units2))\n",
    "            #print('Transitioned to pattern: ' + str(next_pat))\n",
    "\n",
    "            # plot a grid with the average responses\n",
    "            #avg_fig, avg_ax = plt.subplots()\n",
    "            #self.all_avg_res[pres][cur_pat].shape = N,N \n",
    "            #avg_ax.imshow(self.all_avg_res[pres][cur_pat])\n",
    "            #self.all_avg_res[pres][cur_pat].shape = N*N,1\n",
    "            #plt.show()\n",
    "            \n",
    "            # choose the pattern you'll present next\n",
    "            cur_pat = next_pat\n",
    "            next_pat = np.random.randint(n_pat)\n",
    "            \n",
    "            if pres == 0 or (pres+1) in display:\n",
    "                self.plot_stuff((times,units))\n",
    "                #self.plot_stuff((times2,units2))\n",
    "                avg_fig = plt.figure(figsize=(9,9))\n",
    "                largest = max([max([max(self.all_avg_res[a][b]) for b in range(n_pat)]) for a in range(n_pres)])\n",
    "                for res in self.all_avg_res[pres]:\n",
    "                    res.shape = N*N\n",
    "                for u in range(N*N):\n",
    "                    ax = avg_fig.add_subplot(N,N,u+1)\n",
    "                    ax.plot(range(n_pat), [self.all_avg_res[pres][i][u] for i in range(n_pat)], 'bo-')\n",
    "                    plt.ylim([-0.02, largest])\n",
    "                plt.show()\n",
    "                # store the synaptic weights\n",
    "                self.exc_w[idx_d] = [np.zeros(N*N) for _ in range(N*N)]\n",
    "                self.inh_w[idx_d] = [np.zeros(N*N) for _ in range(N*N)]\n",
    "                self.inp_w[idx_d] = [np.zeros(N*N) for _ in range(N*N)]\n",
    "        \n",
    "                for u in self.exc: # for each excitatory unit, record its incoming weights\n",
    "                    for syn_list in [self.net.syns[u]]: # recording weights for excitatory units\n",
    "                        for syn in syn_list:\n",
    "                            if syn.preID in self.exc: # lateral excitatory connection\n",
    "                                self.exc_w[idx_d][u][syn.preID-self.exc[0]] = syn.w\n",
    "                            elif syn.preID in self.inh: # lateral inhibitory connection\n",
    "                                self.inh_w[idx_d][u][syn.preID-self.inh[0]] = syn.w\n",
    "                            elif syn.preID in self.inp: # descending connection\n",
    "                                self.inp_w[idx_d][u][syn.preID-self.inp[0]] = syn.w\n",
    "                            else:\n",
    "                                print(\"What???\")\n",
    "                print('Presentation ' + str(pres+1))\n",
    "                idx_d += 1\n",
    "            \n",
    "    def animate_responses(self, interv=20, slider=False):\n",
    "        \"\"\"For each unit, plot its avg. response for each pattern and for each presentation, as a movie.\n",
    "        \n",
    "        To use this:\n",
    "        1) Run the simulation\n",
    "        2) animate_responses(interv)\n",
    "        where interv is the refresh interval for the simulation\n",
    "        \"\"\"\n",
    "        %matplotlib qt5  \n",
    "        #%matplotlib notebook\n",
    "        from matplotlib.animation import FuncAnimation\n",
    "        self.all_avg_fig = plt.figure(figsize=(8,8))\n",
    "        N = self.params.N\n",
    "        n_pats = len(self.patterns)\n",
    "        n_pres = len(self.all_avg_res)\n",
    "        \n",
    "        for pres in self.all_avg_res:\n",
    "            for res in pres:\n",
    "                res.shape = N*N\n",
    "        self.axes = self.all_avg_fig.subplots(nrows=N, ncols=N, sharex=True, sharey=True)\n",
    "        self.max_avg = max([max([max(self.all_avg_res[a][b]) for b in range(n_pats)]) for a in range(n_pres)])\n",
    "        plt.ylim([-0.02, self.max_avg])\n",
    "        self.pat_ids = list(range(n_pats))\n",
    "        \n",
    "        if not slider:\n",
    "            animation = FuncAnimation(self.all_avg_fig, self.update_anim, interval=interv)\n",
    "            return animation\n",
    "        else:\n",
    "            from ipywidgets import interact\n",
    "            widget = interact(self.update_anim, frame=(1,n_pats))\n",
    "            return widget\n",
    "        \n",
    "    def update_anim(self, frame):\n",
    "        n_pres = len(self.all_avg_res)\n",
    "        #n_pats = len(self.patterns)\n",
    "        pres = frame%n_pres\n",
    "        self.all_avg_fig.suptitle('Presentation: ' + str(pres))\n",
    "        \n",
    "        for r in range(self.params.N):\n",
    "            for c in range(self.params.N):\n",
    "                self.axes[r,c].clear()\n",
    "                self.axes[r,c].plot(self.pat_ids, [self.all_avg_res[pres][i][self.params.N*r+c] for i in self.pat_ids], 'bo-')\n",
    "        return self.axes,\n",
    "           \n",
    "    def display_inputs(self):\n",
    "        # visualize the input patterns in a grid\n",
    "        %matplotlib inline\n",
    "        n_pat = len(self.patterns)\n",
    "        inp_fig = plt.figure(figsize=(6,8))\n",
    "        cols = int(np.ceil(np.sqrt(n_pat)))\n",
    "        rows = int(round(np.sqrt(n_pat)))\n",
    "        inp_grid = ImageGrid(inp_fig, 111, nrows_ncols=(rows,cols), axes_pad=0.1, direction='row')\n",
    "        for idx,pat in enumerate(self.patterns):\n",
    "            copy = pat.copy() # to avoid reshaping the input vectors\n",
    "            copy.shape = self.params.N, self.params.N\n",
    "            copy = np.transpose(copy)\n",
    "            inp_grid[idx].set_xticks([])\n",
    "            inp_grid[idx].set_yticks([])\n",
    "            inp_grid[idx].imshow(copy)\n",
    "        #inp_fig.suptitle('Input patterns')\n",
    "        plt.show()\n",
    "        \n",
    "    def view_weight_grid(self):\n",
    "        # visualize the weights in a grid after the simulation\n",
    "        %matplotlib inline\n",
    "        N = self.params.N\n",
    "        # First, a solitary plot of the E-I weights\n",
    "        ei_w = [np.zeros(N*N) for _ in range(N*N)] # each entry lists all incoming weights for a unit\n",
    "        for idx, uid in enumerate(self.inh):\n",
    "            for syn in self.net.syns[uid]:\n",
    "                if syn.preID in self.exc:\n",
    "                    ei_w[idx][syn.preID - self.exc[0]] = syn.w\n",
    "        ei_fig = plt.figure(figsize=(11,7))\n",
    "        ei_grid = ImageGrid(ei_fig, 111, nrows_ncols=(N,N), share_all=True, label_mode=\"L\",\n",
    "                            axes_pad=0.05, cbar_location=\"top\", cbar_mode=\"single\", )\n",
    "        for idx, ei in enumerate(ei_w):\n",
    "            ei.shape = N,N\n",
    "            eiim = ei_grid[idx].imshow(ei)\n",
    "        ei_grid.cbar_axes[0].colorbar(eiim)\n",
    "        ei_fig.suptitle('E-I weights')\n",
    "        \n",
    "        # Now, plots of EE, IE, and PE weights for each stored presentation\n",
    "        n_disp = len(self.exc_w)\n",
    "        for vis in range(n_disp):\n",
    "            w_fig = plt.figure(figsize=(30,10))\n",
    "            exw_grid = ImageGrid(w_fig, 131, nrows_ncols=(N,N), share_all=True, label_mode=\"L\",\n",
    "                             axes_pad=0.05, cbar_location=\"top\", cbar_mode=\"single\", direction=\"column\", )\n",
    "            for idx,exw in enumerate(self.exc_w[vis]):\n",
    "                exw.shape = N,N\n",
    "                exim = exw_grid[idx].imshow(np.transpose(exw))\n",
    "            exw_grid.cbar_axes[0].colorbar(exim)  \n",
    "            inw_grid = ImageGrid(w_fig, 132, nrows_ncols=(N,N), share_all=True, label_mode=\"L\",\n",
    "                         axes_pad=0.05, cbar_location=\"top\", cbar_mode=\"single\", direction=\"column\" )\n",
    "            for idx,inw in enumerate(self.inh_w[vis]):\n",
    "                inw.shape = N,N\n",
    "                inim = inw_grid[idx].imshow(np.transpose(inw))\n",
    "            inw_grid.cbar_axes[0].colorbar(inim)           \n",
    "            ipw_grid = ImageGrid(w_fig, 133, nrows_ncols=(N,N), share_all=True, label_mode=\"L\",\n",
    "                                 axes_pad=0.05, cbar_location=\"top\", cbar_mode=\"single\", direction=\"column\")\n",
    "            for idx,ipw in enumerate(self.inp_w[vis]):\n",
    "                ipw.shape = N,N\n",
    "                ipim = ipw_grid[idx].imshow(np.transpose(ipw))\n",
    "            ipw_grid.cbar_axes[0].colorbar(ipim)           \n",
    "            if vis == 0:\n",
    "                w_fig.suptitle('E-E,  I-E,  INP-E', fontsize=30)\n",
    "            plt.show()\n",
    "    \n",
    "        # see how the sum of each type of input weights evolves for unit 0\n",
    "        exc_sums = [sum(sum(self.exc_w[ii][0]*self.exc_w[ii][0])) for ii in range(n_disp)]\n",
    "        inh_sums = [sum(sum(self.inh_w[ii][0])) for ii in range(n_disp)]\n",
    "        inp_sums = [sum(sum(self.inp_w[ii][0])) for ii in range(n_disp)]\n",
    "        print(\"Excitatory squared sums:\", end='\\t')\n",
    "        print(exc_sums)\n",
    "        print(\"Inhibitory sums:\", end='\\t')\n",
    "        print(inh_sums)\n",
    "        print(\"External input sums:\", end=' \\t')\n",
    "        print(inp_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the `selection` class it is time to use it.  \n",
    "First we create  a `parameters` object, and configure its values to create NxN grids of excitatory, inhibitory, and input units.  \n",
    "Next we create a `selection` object, build it, and display the inputs that will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Running a simulation. \"\"\"\n",
    "# create a parameters object with the default values\n",
    "p = parameters()\n",
    "\n",
    "# Set any parameter values specific to this simulation\n",
    "p.N = 8 # number of units on each row/column\n",
    "p.md = 0.2 # minimum delay in the connections\n",
    "p.t_pat = 8. # time a pattern is presented\n",
    "p.t_trans = 2. # transition time between patterns\n",
    "p.PE_lrate = 1./250. #learning rate of PE (input to excitatory) connections\n",
    "p.PI_lrate = 1./250. #learning rate of PI (input to inhibitory) connections\n",
    "p.IE_mask = {'circular':{'radius':1.9}}\n",
    "p.IE_kernel = {'gaussian' : {'p_center' : 1.2, 'sigma' : 2.}}\n",
    "p.EI_mask = {'annular':{'inner_radius' : 1.5, 'outer_radius':2.7}}\n",
    "p.EI_kernel = {'linear' : {'c' : 1.1, 'a' : 0.2}}\n",
    "p.EE_mask = {'circular':{'radius':2.1}}\n",
    "p.EE_kernel = {'gaussian' : {'p_center' : 1.2, 'sigma' : 1.5}}\n",
    "p.EI_weights = {'uniform' : {'low' : 0.06, 'high' : 0.2}}\n",
    "p.pat_type = 'lines' # type of input pattern (snake, line, or random)\n",
    "\n",
    "# Initialize a simulation object with the specific parameters\n",
    "sel = selection(p) \n",
    "\n",
    "# Create all the draculab objects and the input patterns\n",
    "# After the connections are created, this method will plot the \n",
    "# average number of connections for each type.\n",
    "sel.build()\n",
    "\n",
    "# Show the input patterns\n",
    "# Each unit may have one of two values (\"on\" or \"off\") for each input pattern. \n",
    "# For each input pattern the NxN grid of input units is displayed, with \"off\" units\n",
    "# in purple, and \"on\" units in yellow.\n",
    "sel.display_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the simulation.  \n",
    "\n",
    "`n_pres` indicates how many times a new input pattern will be presented.\n",
    "\n",
    "During the simulation there will be two type of plots presented. The first type of plots shows, for each location in the grid, the activity level of its units. The blue line corresponds to excitatory units, the red one to inhibitory units, and the black one to inputs. This type of plot is created by the `plot_stuff` method.\n",
    "\n",
    "The second type of plot shows for each excitatory unit in the grid a subplot showing what was its response for each type of input. The response level is in the vertical axis, whereas the input type is in the horizontal axis. Notice that in the beginning only a few input types will have been presented, so the plot showing the response by input type will show a zero response for input types that have not appeared. This plot is directly produded in the `run` method.\n",
    "\n",
    "Right after the first input presentation the first plots will appear. The number of times they will subsequently be shown can be controlled through the `n_disp` parameter. The number of plottings will be `n_disp`+1, uniformly distributed through the `n_pres` input presentations. `n_pres` also controls how many times the synaptic weights for the excitatory units will be stored. Those synaptic weights can later be observed with the `view_weight_grid` method (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the simulation\n",
    "# This may take a few minutes on older machines\n",
    "\n",
    "n_pres = 30 # number of input patterns to present\n",
    "n_disp = 2  # number of times outputs will be displayed\n",
    "sel.run(n_pres, n_disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a large enough number of input presentations, the final plot of the simulation will show that the excitatory units will differ regarding in how they respond to each input, and sometimes units with similar responses will cluster into 2 or more groups.\n",
    "\n",
    "The creation of groups that preferentially respond to certain inputs is a consequence of connection topologies and synaptic plasticity. Lateral competition breaks down the homogeneity in response profiles, and the weight of the input and lateral excitatory connections tends to create groups of units that activate together. This can be observed to some extent by visualizing the synaptic weights of the inputs to the excitatory cells. This can be achieved with the  `view_weight_grid` method. It is not a very efficient method, so it might take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sel.view_weight_grid()\n",
    "# First, the E-I weights (with static connections) will be displayed.\n",
    "# Next, all the inputs to all the excitatory units will be displayed, at n_disp+1 different time points.\n",
    "# Excitatory-excitatory on the left, inhibitory-excitatory in the middle, input-excitatory on the right.\n",
    "\n",
    "# At the bottom, the sum of the weights (or squared weights) can be seen at the n_disp+1 time points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is too hard to obtain any insights by looking at the synaptic weights, especially with the random connectivity.\n",
    "\n",
    "Another visualization that could be useful it to plot how the response to different patterns evolves through the each presentation. A way to create this animation is presented in the `animate_responses` method. If your computer is configured to use the qt backend, it can be used by replacing `%matplotlib qt5` for `%matplotlib notebook`. If `ipywidges` is installed, the argument `slider=True` can also be used.\n",
    "\n",
    "In some cases the cell with `animate_responses` will have to be executed several times before the animation begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ani = sel.animate_responses(slider=False)\n",
    "# If there is no animation and the cell is not executing, executing again several times might do the trick\n",
    "# If the cell gets stuck executing [*] there is probably a problem with the backend, and a kernel reset is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it can be observed that the response profiles continue to change through the presentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Want to continue? \"\"\"\n",
    "# This will run the simulation from the last point\n",
    "n_pres = 20 # number of inputpatterns to present\n",
    "n_disp = 2  # number of times outputs will be displayed\n",
    "sel.run(n_pres, n_disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Part 2\n",
    "A flat network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the selection.run method, it can be noticed that it has a boolean argument named `flat`. When this argument has a True value, the newtork is run with the `flat_run` method, instead of the usual `run`.\n",
    "\n",
    "`flat_run` changes the way that the network connectivity is represented. The previous activation values of all units are now stored in a 2D numpy array called `acts`, which is part of the network object. The units no longer retrieving past activation values of their input sources through the methods in the `act` list introduced in tutorial 1, but instead retrieve them from `acts` using a special index.\n",
    "\n",
    "No knowledge of any of this is necessary to use *flat networks*; usually it is sufficient to replace `run` by `flat_run`. What is important is that all unit models included in the network support the *flat* version of the network. A simple way to verify it is this: if the unit has a method called `dt_fun` then it supports flat networks.\n",
    "\n",
    "More information about flat networks can be found in the draculab paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if sigmoidal units have a 'dt_fun' method\n",
    "'dt_fun' in dir(sigmoidal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Flat networks are introduced with the purpose of increasing the speed of simulations when the networks are large. Let's test this.\n",
    "\n",
    "Reset the kernel, and execute the first four code cells of the notebook, up until the part where the input patterns are plotted.\n",
    "Next execute the following cell, with the `flat=False` argument. Take notice of the execution time.\n",
    "\n",
    "Now reset again, execute the first four code cells of the notebook, and the next cell with `flat=True`.\n",
    "\n",
    "Is there a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will run the simulation from the last point\n",
    "n_pres = 5 # number of inputpatterns to present\n",
    "n_disp = 0  # number of times outputs will be displayed\n",
    "start = time.time()\n",
    "sel.run(n_pres, n_disp, flat=False)\n",
    "end = time.time()\n",
    "print('Execution time: %f'% ((end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
