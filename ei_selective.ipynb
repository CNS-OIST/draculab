{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ei_selective.ipynb\n",
    "# This notebook is used to create a balanced network of excitatory and inhibitory units that become selective\n",
    "# for particular input patterns.\n",
    "\n",
    "# By Sergio Verduzco Flores        August 2017\n",
    "\n",
    "from sirasi import *\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pylab\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below:\n",
    "* Create two NxN layers, one excitatory, and one inhibitory.\n",
    "* Connect the layers with center-excitation surround-inhibition connectivity. E-E connections use\n",
    "  Hebbian learning with substractive normalization, I-E connections use homeostatic inhibition,\n",
    "  similar to Moldakarimov06 (in ei_net.ipynb).\n",
    "* Create an input layer where the activity of each unit is a function of the current input pattern.\n",
    "* Connects the input layer to E,I layers using a connection pattern based on a Gaussian kernel, and\n",
    "  using BCM synapses.\n",
    "* Runs a simulation where input patterns are randomly selected and presented sequentially, similarly\n",
    "  to the way this was done in the test3,4,5 notebooks.\n",
    "  \n",
    "The experiment consists of finding whether selectivity to patterns will arise in the units.\n",
    "- - -\n",
    "TODO:\n",
    "* Set the right connectivity patterns, and **set the delays according to distance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create some utility functions\n",
    "def make_fe(th, eps): # returns a function as in Eq. 1 of the paper\n",
    "    return lambda x : np.sqrt( eps * np.log( 1. + np.exp( (x - th)/eps ) ) )\n",
    "def make_fi(th, eps): # returns a function as in Eq. 2 of the paper\n",
    "    return lambda x: eps * np.log( 1. + np.exp( (x - th)/eps ) ) \n",
    "def make_pulse(t_init, t_end): # returns f(t) = 1 if t_init < t < t_end, 0 otherwise\n",
    "    return lambda t : 1. if (t_init < t and t < t_end) else 0.\n",
    "def r(i,j,sigma): # A Gaussian function with s.d. sigma, applied to i-j\n",
    "    return (1./(sigma*np.sqrt(2*np.pi))) * np.exp( -0.5*( ((i-j)/sigma)**2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Create and connect the E,I layers.\n",
    "    Random connections with fixed indegree as a starter. \n",
    "\"\"\"\n",
    "\n",
    "######## CREATE THE NETWORK\n",
    "md = 0.5 # minimum delay of the connections\n",
    "net_params = {'min_delay' : md, 'min_buff_size' : 3, 'rtol':1e-4, 'atol':1e-4 } \n",
    "net = network(net_params)\n",
    "\n",
    "######## CREATE THE E,I UNITS\n",
    "N = 5 # Each layer will have N*N units\n",
    "exc_params = {'tau' : 2., 'function' : make_fe(0.1, 0.2), 'type' : unit_types.custom_fi, \n",
    "              'init_val' : 0.1, 'tau_fast' : 0.2, 'tau_slow' : 20. }\n",
    "inh_params = {'tau' : 3., 'function' : make_fi(0.5, 0.2), 'type' : unit_types.custom_fi, \n",
    "              'init_val' : 0.1, 'tau_fast' : 0.2, 'tau_slow' : 20. }\n",
    "\n",
    "exc = net.create(N*N, exc_params)\n",
    "inh = net.create(N*N, inh_params)\n",
    "\n",
    "######## SET E-I CONNECTIONS\n",
    "# connection specifications\n",
    "EI_conn = {'rule' : 'fixed_indegree', 'indegree' : 5, 'delay' : md}\n",
    "# synapse specifications\n",
    "EI_syn = {'type' : synapse_types.static, 'init_w' : .2}\n",
    "# Static connections and fixed indegree suggest that the inhibitory units will not go without excitation.\n",
    "# connect\n",
    "net.connect(exc, inh, EI_conn, EI_syn)\n",
    "\n",
    "######## SET E-E CONNECTIONS\n",
    "# connection specifications\n",
    "EE_conn = {'rule' : 'fixed_indegree', 'indegree' : 10, 'delay' : md}\n",
    "# synapse specifications\n",
    "EE_syn = {'type' : synapse_types.sq_hebbsnorm, 'init_w' : {'distribution':'uniform', 'low':0., 'high':.5},\n",
    "          'lrate' : 1./100., 'omega' : 4.} \n",
    "# The large g_ee value in Moldakaraimov06 can probably be compensated with omega and the indegree.\n",
    "# connect\n",
    "net.connect(exc, exc, EE_conn, EE_syn)\n",
    "\n",
    "######## SET I-E CONNECTIONS\n",
    "# connection specifications\n",
    "IE_conn = {'rule' : 'fixed_outdegree', 'outdegree' : 10, 'delay' : md}\n",
    "# synapse specifications\n",
    "IE_syn = {'type' : synapse_types.homeo_inh, 'init_w' : {'distribution':'uniform', 'low':-.6, 'high':0.},\n",
    "           'lrate' : 1./50., 'des_act' : 0.3}\n",
    "# connect\n",
    "net.connect(inh, exc, IE_conn, IE_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# synapse specifications\\n# I don't have the theta and the omega parameters, I assumed theta = 1. \\n# For omega I used 1 . If all weights are equal and add to c, 20w=c => w=c/20 => omega=20w^2=(c^2)/20 .\\n# lrate can be interpreted as the reciprocal of the synaptic time constants.\\ng_ee=5.; g_ie=1.; g_ei=3.5 # gains for each input type\\n\\n\\next2exc_syn = {'type' : synapse_types.static, 'init_w' : 5., 'gain' : 1.}\\next2inh_syn = {'type' : synapse_types.static, 'init_w' : 5., 'gain' : 1.}\\n\\n# neuron-to-neuron connection\\nsig = 3. # standard deviation of connection multiplier\\nbase_e = exc[0] # index of first excitatory unit\\nbase_i = inh[0]\\nfor e,i in zip(exc,inh):  # connect with non-periodic boundary conditions\\n    net2.connect([i], [e], inh2exc_conn, inh2exc_syn) # inhibitory units only connect locally\\n    for target_e, target_i in zip(exc,inh):\\n        exc2exc_syn['gain'] = g_ee * r(e, target_e, 3.)\\n        net2.connect([e], [target_e], exc2exc_conn, exc2exc_syn)\\n        exc2inh_syn['gain'] = g_ie * r(e-base_e, target_i-base_i, 3.)\\n        net2.connect([e], [target_i], exc2inh_conn, exc2inh_syn)\\n        \\n# external input connections\\nnet2.connect(ext, [exc[9]], ext2exc_conn, ext2exc_syn)\\nnet2.connect(ext, [inh[9]], ext2inh_conn, ext2inh_syn)\\n\\n# running the simulation\\nn_iters = 64\\nact_fig = plt.figure(figsize=(10,8))\\ndubyas = []  # to show the evolution of excitatory connections\\nfor iter in range(1,n_iters+1):\\n    start_time = time.time()\\n    times, units, empty = net2.run(50.)\\n    if iter == 1: ole_t = times\\n    print('Execution time: at iteration %d is %s seconds' % (iter, (time.time() - start_time)) )\\n    sim_time = net2.sim_time\\n    net2.units[ext[0]].set_function(make_pulse(sim_time+10,sim_time+10.+width))\\n    if iter%8 == 0:\\n        pylab.plot(ole_t, units[exc[9]], 'b', ole_t, units[inh[9]], 'r', ole_t, units[ext[0]], 'g', figure=act_fig)\\n        dubyas.append([syn.w for syn in net2.syns[exc[9]] if syn.type == synapse_types.sq_hebbsnorm ])\\n\\n'''\\ngain_fig = plt.figure(figsize=(5,3))\\ninps = np.linspace(-5.,10.,100)\\nexc_fr = np.array([net2.units[exc[0]].f(I) for I in inps])\\ninh_fr = np.array([net2.units[inh[0]].f(I) for I in inps])\\npylab.plot(inps, exc_fr, 'k', inps, inh_fr, 'k--', figure=gain_fig)\\n'''\\nfrom mpl_toolkits.axes_grid1 import ImageGrid\\ndub_mat = np.matrix(dubyas)\\ndub_fig = plt.figure(figsize=(8,6))\\ndub_grid = ImageGrid(dub_fig, 111, nrows_ncols=(1,1))\\ndub_grid[0].imshow(dub_mat)\\nplt.show()\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Create and connect the input layer. Create some input paterns \n",
    "\"\"\"\n",
    "\n",
    "######### CREATE THE INPUT UNITS\n",
    "inp_params = {'type' : unit_types.source, 'init_val' : 0., 'tau_fast' : 0.2, 'function' : lambda x: None}\n",
    "inp = net.create(N*N, inp_params)\n",
    "\n",
    "######### CONNECT THE INPUT UNITS\n",
    "# connection specifications\n",
    "PE_conn = {'rule' : 'one_to_one', 'delay' : md}\n",
    "PI_conn = {'rule' : 'one_to_one', 'delay' : md}\n",
    "# synapse specifications\n",
    "PE_syn = {'init_w' : {'distribution':'uniform', 'low':1., 'high':4.}, 'omega' : N*N, \n",
    "          'lrate' : 1./50., 'type' : synapse_types.bcm }\n",
    "PI_syn = {'init_w' : {'distribution':'uniform', 'low':1., 'high':4.}, 'omega' : N*N, \n",
    "          'lrate' : 1./50., 'type' : synapse_types.bcm }\n",
    "# connect\n",
    "net.connect(inp, exc, PE_conn, PI_syn)\n",
    "\n",
    "######### CREATE THE INPUT PATTERNS\n",
    "# For the input patterns I use random vectors where each element is 0 or 1. \n",
    "# All patterns will contain the same number of 1 values.\n",
    "n_pat = 5 # number of input patterns\n",
    "n_ones = int(round(N*N)/3) # number of ones in the input patterns\n",
    "basic_pat = np.array( [1.]*n_ones + [0.]*(N*N - n_ones) )\n",
    "patterns = [basic_pat.copy() for i in range(n_pat)]\n",
    "for pat in patterns:\n",
    "    np.random.shuffle(pat)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# synapse specifications\n",
    "# I don't have the theta and the omega parameters, I assumed theta = 1. \n",
    "# For omega I used 1 . If all weights are equal and add to c, 20w=c => w=c/20 => omega=20w^2=(c^2)/20 .\n",
    "# lrate can be interpreted as the reciprocal of the synaptic time constants.\n",
    "g_ee=5.; g_ie=1.; g_ei=3.5 # gains for each input type\n",
    "\n",
    "\n",
    "ext2exc_syn = {'type' : synapse_types.static, 'init_w' : 5., 'gain' : 1.}\n",
    "ext2inh_syn = {'type' : synapse_types.static, 'init_w' : 5., 'gain' : 1.}\n",
    "\n",
    "# neuron-to-neuron connection\n",
    "sig = 3. # standard deviation of connection multiplier\n",
    "base_e = exc[0] # index of first excitatory unit\n",
    "base_i = inh[0]\n",
    "for e,i in zip(exc,inh):  # connect with non-periodic boundary conditions\n",
    "    net2.connect([i], [e], inh2exc_conn, inh2exc_syn) # inhibitory units only connect locally\n",
    "    for target_e, target_i in zip(exc,inh):\n",
    "        exc2exc_syn['gain'] = g_ee * r(e, target_e, 3.)\n",
    "        net2.connect([e], [target_e], exc2exc_conn, exc2exc_syn)\n",
    "        exc2inh_syn['gain'] = g_ie * r(e-base_e, target_i-base_i, 3.)\n",
    "        net2.connect([e], [target_i], exc2inh_conn, exc2inh_syn)\n",
    "        \n",
    "# external input connections\n",
    "net2.connect(ext, [exc[9]], ext2exc_conn, ext2exc_syn)\n",
    "net2.connect(ext, [inh[9]], ext2inh_conn, ext2inh_syn)\n",
    "\n",
    "# running the simulation\n",
    "n_iters = 64\n",
    "act_fig = plt.figure(figsize=(10,8))\n",
    "dubyas = []  # to show the evolution of excitatory connections\n",
    "for iter in range(1,n_iters+1):\n",
    "    start_time = time.time()\n",
    "    times, units, empty = net2.run(50.)\n",
    "    if iter == 1: ole_t = times\n",
    "    print('Execution time: at iteration %d is %s seconds' % (iter, (time.time() - start_time)) )\n",
    "    sim_time = net2.sim_time\n",
    "    net2.units[ext[0]].set_function(make_pulse(sim_time+10,sim_time+10.+width))\n",
    "    if iter%8 == 0:\n",
    "        pylab.plot(ole_t, units[exc[9]], 'b', ole_t, units[inh[9]], 'r', ole_t, units[ext[0]], 'g', figure=act_fig)\n",
    "        dubyas.append([syn.w for syn in net2.syns[exc[9]] if syn.type == synapse_types.sq_hebbsnorm ])\n",
    "\n",
    "'''\n",
    "gain_fig = plt.figure(figsize=(5,3))\n",
    "inps = np.linspace(-5.,10.,100)\n",
    "exc_fr = np.array([net2.units[exc[0]].f(I) for I in inps])\n",
    "inh_fr = np.array([net2.units[inh[0]].f(I) for I in inps])\n",
    "pylab.plot(inps, exc_fr, 'k', inps, inh_fr, 'k--', figure=gain_fig)\n",
    "'''\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "dub_mat = np.matrix(dubyas)\n",
    "dub_fig = plt.figure(figsize=(8,6))\n",
    "dub_grid = ImageGrid(dub_fig, 111, nrows_ncols=(1,1))\n",
    "dub_grid[0].imshow(dub_mat)\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "         1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.]),\n",
       " array([ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
       "         1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.]),\n",
       " array([ 1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
       "         0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.]),\n",
       " array([ 1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,\n",
       "         0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.]),\n",
       " array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,\n",
       "         0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
