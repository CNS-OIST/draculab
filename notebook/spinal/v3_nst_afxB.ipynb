{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v3_nst_afxB.ipynb\n",
    "\n",
    "A copy of `v3_nst_afx` where the parameter dictionaries that initialize the network come from `v3_nst_afx_hyper`, rather than some SMAC-based notebook (e.g. `v3_hyperparameters`).\n",
    "\n",
    "`v3_nst_afx` is a copy of v3_normal_smac_test.ipynb, where the AF population does not have variable thresholds (chwr_linear units). Another variation to have logarithmic units in the SPF population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/z/projects/draculab\n"
     ]
    }
   ],
   "source": [
    "%cd ../..\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from draculab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default configuration\n",
    "def_cfg50 = {'b_e':4.00, 'M__C_lrate':20.26, 'sig1':0.49, 'SPF_w':1.50, 'M__C_w_sum':3.00, 'AL_thresh':0.30, \n",
    "           'g_e_factor':2.00, 'integ_amp':1.87, 'integ_decay':1.33, 'dely_diff':0.45, 'adapt_amp':5.00, \n",
    "           'C_tau_slow':49.90, 'SF_slope_factor':8.00, 'sig2':0.53, 'dely_low':0.77, 'n_evals':0.00 }\n",
    "def_cfg26 = {'C_tau_slow':23.24, 'sig2':0.65, 'integ_decay':1.68, 'fitness':0.05, 'M__C_w_sum':3.03, \n",
    "             'n_evals':27.00, 'integ_amp':1.94, 'adapt_amp':5.00, 'dely_diff':0.61, 'SPF_w':1.50, 'M__C_lrate':24.82, \n",
    "             'sig1':0.07, 'g_e_factor':2.00, 'AL_thresh':0.38, 'dely_low':0.94, 'b_e':2.98, 'SF_slope_factor':8.00}\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved population\n",
    "import pickle\n",
    "#fname = 'v3_nst_afx_pop_2020-08-09__20_39_gen26'\n",
    "#fname = 'v3_nst_afx_pop_2020-09-04__09_52_cns1'\n",
    "#fname = 'v3_nst_afx_pop_2020-09-04__09_52_cns2'\n",
    "#fname = 'v3_nst_afx_pop_2020-09-04__14_49_breaker'\n",
    "#fname = 'v3_nst_afx_pop_2020-09-14__23_05'\n",
    "#fname = 'v3_nst_afx_pop_2020-09-19__16_25'\n",
    "#fname = 'v3_nst_afx_pop_2020-10-09__08_55'\n",
    "#fname = 'v3_nst_afx_pop_2020-10-13__09_49'\n",
    "fname = 'v3_nst_afx_pop_2020-10-16__17_07'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    pop = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select configuration\n",
    "#cfg = def_cfg26\n",
    "cfg = pop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes to configuration\n",
    "#cfg['M__C_lrate'] = 1.\n",
    "#cfg['M_thresh'] = 0.\n",
    "#cfg['M__C_de_rate'] = 0.05\n",
    "#cfg['AF__M_de_rate'] = 0.02\n",
    "#cfg['AF__M_lrate'] = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C_tau_slow':23.24, 'integ_decay':0.84, 'dely_diff':0.61, 'sig2':0.71, 'dely_low':0.88, 'sig1':0.07, 'M__C_lrate':3.00, 'integ_amp':1.81, 'adapt_amp':5.57, 'SF_slope_factor':19.00, 'g_e_factor':0.53, 'AL_thresh':0.06, 'M__C_w_sum':1.75, 'b_e':3.01, 'SPF_w':2.87, 'fitness':0.13, 'n_evals':30.00, 'C__C_antag':1.41, 'C__C_p_antag':0.75, 'CE__CI_w':1.30, 'CI__CE_w':-2.00, 'M_thresh':0.10, 'M_slope':3.24, 'AF__M_w_sum':10.00, 'AF__M_lrate':26.50, 'M_p1_inp':1.00, 'M_mod':0.00, 'lowpass_SP':0.00, 'noisy_syns':0.00, 'M__C_decay':0.00, 'AF__M_decay':0.00, 'AF__M_de_rate':0.01, 'AF__M_dr_amp':0.01, }\n",
      "\n",
      "{'C_tau_slow':23.24, 'integ_decay':0.84, 'dely_diff':0.61, 'sig2':0.65, 'dely_low':0.88, 'sig1':0.07, 'M__C_lrate':3.00, 'integ_amp':1.94, 'adapt_amp':5.57, 'SF_slope_factor':19.00, 'g_e_factor':0.53, 'AL_thresh':0.06, 'M__C_w_sum':1.75, 'b_e':3.01, 'SPF_w':2.87, 'fitness':0.13, 'n_evals':30.00, 'C__C_antag':1.41, 'C__C_p_antag':0.75, 'CE__CI_w':1.30, 'CI__CE_w':-2.00, 'M_thresh':0.10, 'M_slope':3.24, 'AF__M_w_sum':10.00, 'AF__M_lrate':26.50, 'M_p1_inp':1.00, 'M_mod':0.00, 'lowpass_SP':0.00, 'noisy_syns':0.00, 'M__C_decay':0.00, 'AF__M_decay':0.00, 'AF__M_de_rate':0.01, 'AF__M_dr_amp':0.01, }\n",
      "\n",
      "{'C_tau_slow':23.24, 'integ_decay':0.84, 'dely_diff':0.70, 'sig2':0.65, 'dely_low':0.88, 'sig1':0.07, 'M__C_lrate':3.00, 'integ_amp':1.94, 'adapt_amp':5.57, 'SF_slope_factor':19.00, 'g_e_factor':0.53, 'AL_thresh':0.06, 'M__C_w_sum':1.75, 'b_e':3.01, 'SPF_w':2.87, 'fitness':0.13, 'n_evals':30.00, 'C__C_antag':1.41, 'C__C_p_antag':0.75, 'CE__CI_w':1.30, 'CI__CE_w':-2.00, 'M_thresh':0.30, 'M_slope':3.24, 'AF__M_w_sum':10.00, 'AF__M_lrate':26.50, 'M_p1_inp':1.00, 'M_mod':0.00, 'lowpass_SP':0.00, 'noisy_syns':0.00, 'M__C_decay':0.00, 'AF__M_decay':0.00, 'AF__M_de_rate':0.01, 'AF__M_dr_amp':0.06, }\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C_tau_slow': 23.242490852056637,\n",
       " 'integ_decay': 0.8416765906183062,\n",
       " 'dely_diff': 0.606,\n",
       " 'sig2': 0.7077715710692531,\n",
       " 'dely_low': 0.8750447211896449,\n",
       " 'sig1': 0.067,\n",
       " 'M__C_lrate': 3.0,\n",
       " 'integ_amp': 1.8136414725723145,\n",
       " 'adapt_amp': 5.573673053045277,\n",
       " 'SF_slope_factor': 19.004254579601053,\n",
       " 'g_e_factor': 0.5270165387639062,\n",
       " 'AL_thresh': 0.05624690639116503,\n",
       " 'M__C_w_sum': 1.75,\n",
       " 'b_e': 3.0075343697733357,\n",
       " 'SPF_w': 2.8711109175315865,\n",
       " 'fitness': 0.12941013369817142,\n",
       " 'n_evals': 30,\n",
       " 'C__C_antag': 1.4143002855209728,\n",
       " 'C__C_p_antag': 0.7524176332179722,\n",
       " 'CE__CI_w': 1.2989454595001388,\n",
       " 'CI__CE_w': -2.0,\n",
       " 'M_thresh': 0.1,\n",
       " 'M_slope': 3.238538232297488,\n",
       " 'AF__M_w_sum': 10.0,\n",
       " 'AF__M_lrate': 26.497927730877652,\n",
       " 'M_p1_inp': 1.0,\n",
       " 'M_mod': False,\n",
       " 'lowpass_SP': False,\n",
       " 'noisy_syns': False,\n",
       " 'M__C_decay': False,\n",
       " 'AF__M_decay': False,\n",
       " 'AF__M_de_rate': 0.01,\n",
       " 'AF__M_dr_amp': 0.005356753087613719}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print used configuration\n",
    "for dic in pop[0:3]:\n",
    "    print('{',end='')\n",
    "    for name in dic.keys():\n",
    "        if name != 'fitness' or dic['fitness'] != None:\n",
    "            print(\"\\'%s\\':%.2f, \" % (name, dic[name]), end='')\n",
    "    print('}\\n')\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "####### Create the network #######\n",
    "##################################\n",
    "\n",
    "t_pres = 30. # number of seconds to hold each set of target lengths\n",
    "rand_w = True # whether to use random weights in M->C, AF->M\n",
    "rga_diff = True # if True use gated_normal_rga_diff, if False gated_normal_rga\n",
    "rand_targets = True # whether to train using a large number of random targets\n",
    "M_mod = cfg['M_mod'] if 'M_mod' in cfg else True # whether M units are amplitude-modulated by the SPF input\n",
    "par_heter = 0.001 # range of heterogeneity as a fraction of the original value\n",
    "lowpass_SP = cfg['lowpass_SP'] if 'lowpass_SP' in cfg else False # whether to filter SP's output with slow-responding linear units\n",
    "noisy_syns = cfg['noisy_syns'] if 'noisy_syns' in cfg else True # whether to use noisy versions of the M__C, AF__M synapses\n",
    "M__C_decay = cfg['M__C_decay'] if 'M__C_decay' in cfg else False # is using noisy_syns, replace normalization and drift with decay\n",
    "AF__M_decay = cfg['AF__M_decay'] if 'AF__M_decay' in cfg else True # is using noisy_syns, replace normalization and drift with decay\n",
    "\n",
    "net_params = {'min_delay' : 0.005,\n",
    "          'min_buff_size' : 10 }\n",
    "\n",
    "P_params = {  'type' : plant_models.bouncy_planar_arm_v3,\n",
    "          'mass1': 1.,\n",
    "          'mass2': 1.,\n",
    "          's_min' : -0.8,\n",
    "          'p1' : (-0.01, 0.04),\n",
    "          'p2' : (0.29, 0.03),\n",
    "          'p3' : (0., 0.05),\n",
    "          'p5' : (0.01, -0.05),\n",
    "          'p10': (0.29, 0.03),\n",
    "          'init_q1': 0.,\n",
    "          'init_q2': np.pi/2.,\n",
    "          'init_q1p': 0.,\n",
    "          'init_q2p': 0.,\n",
    "          'g': 0.0,\n",
    "          'mu1': 3.,\n",
    "          'mu2': 3.,\n",
    "          'l_torque' : 0.001,\n",
    "          'l_visco' : 0.01,\n",
    "          'g_e' : cfg['g_e_factor']*np.array([18., 20., 20., 18., 22., 23.]),\n",
    "          'l0_e' : [1.]*6,\n",
    "          'Ia_gain' : 2.5*np.array([3.,10.,10., 3.,10.,10.]),\n",
    "          'II_gain' : 2.*np.array([3., 8., 8., 3., 8., 8.]),\n",
    "          'Ib_gain' : 1.,\n",
    "          'T_0' : 10.,\n",
    "          'k_pe_e' : 20.,  #8\n",
    "          'k_se_e' : 20., #13\n",
    "          'b_e' : cfg['b_e'],\n",
    "          'g_s' : 0.02,\n",
    "          'k_pe_s' : 2., \n",
    "          'k_se_s' : 2.,\n",
    "          'g_d' : 0.01,\n",
    "          'k_pe_d' : .2, #.1,\n",
    "          'k_se_d' : 1., #2.,\n",
    "          'b_s' : .5,\n",
    "          'b_d' : 2.,#3.,\n",
    "          'l0_s': .7,\n",
    "          'l0_d': .8,\n",
    "          'fs' : 0.1,\n",
    "          'se_II' : 0.5,\n",
    "          'cd' : 0.5,\n",
    "          'cs' : 0.5,\n",
    "          'tau' : 0.1   # ficticious time constant used in create_freqs_steps\n",
    "           }\n",
    "net = network(net_params)\n",
    "#P = net.create(1, P_params)\n",
    "#arm = net.plants[P]\n",
    "\n",
    "# We organize the spinal connections through 4 types of symmetric relations\n",
    "# these lists are used to set intraspinal connections and test connection matrices\n",
    "antagonists = [(0,3), (1,2), (4,5)]\n",
    "part_antag = [(0,2),(0,5), (3,4), (1,3)]\n",
    "synergists = [(0,1), (0,4), (2,3), (3,5)]\n",
    "part_syne = [(1,4), (2,5)]\n",
    "self_conn = [(x,x) for x in range(6)]\n",
    "\n",
    "antagonists += [(p[1],p[0]) for p in antagonists]\n",
    "part_antag += [(p[1],p[0]) for p in part_antag]\n",
    "synergists += [(p[1],p[0]) for p in synergists]\n",
    "part_syne += [(p[1],p[0]) for p in part_syne]\n",
    "all_pairs = [(i,j) for i in range(6) for j in range(6)]\n",
    "#unrelated = set(all_pairs) - set(antagonists) - set(part_antag) - set(synergists) - set(part_syne) - set(self_conn)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# UNIT PARAMETER DICTIONARIES\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "randz6 = lambda : (1. + par_heter*(np.random.rand(6)-0.5))\n",
    "randz12 = lambda : (1. + par_heter*(np.random.rand(12)-0.5))\n",
    "randz18 = lambda : (1. + par_heter*(np.random.rand(18)-0.5))\n",
    "randz36 = lambda : (1. + par_heter*(np.random.rand(36)-0.5))\n",
    "\n",
    "ACT_params = {'type' : unit_types.act,\n",
    "              'tau_u' : 6., #8\n",
    "              'gamma' : 6., #2\n",
    "              'g' : 2.,\n",
    "              'theta' : 1.,\n",
    "              'tau_slow' : 5.,\n",
    "              'y_min' : 0.1, #0.2\n",
    "              'rst_thr' : 0.1,\n",
    "              'init_val' : 0. }\n",
    "spf_sum_min = .4 # value where no corrections are needed anymore\n",
    "y_min = 1./(1. + np.exp(-ACT_params['g']*(spf_sum_min - ACT_params['theta'])))\n",
    "ACT_params['y_min'] = y_min\n",
    "\n",
    "AF_params = {'type' : unit_types.logarithmic,\n",
    "             'init_val' : [0.1, 0.05, 0.15, 0.1, 0.1, 0.1, # avg afferent values\n",
    "                           0.2, 0.15, 0.3, 0.3, 0.2, 0.25,\n",
    "                           0.2, 0.4, 0.4, 0.2, 0.4, 0.4]*2,\n",
    "                           #0.3, 0.4, 0.5, 0.3, 0.3, 0.5]*2,\n",
    "             'tau' : 0.02 * randz36(),\n",
    "             'tau_fast': 0.1,\n",
    "             'tau_mid' : 1.,\n",
    "             'tau_slow' : 40.,\n",
    "             'delay' : 0.1,\n",
    "             'thresh' : [0.05]*18 + [-0.4]*18 } \n",
    "AL_params = {'type' : unit_types.sigmoidal,\n",
    "             'thresh' : cfg['AL_thresh'] * randz6(),\n",
    "             'slope' : 2. * randz6(),\n",
    "             'init_val' : 0.1 * randz6(),\n",
    "             'tau' : 0.02 * randz6() }\n",
    "CE_params = {'type' : unit_types.gated_rga_inpsel_adapt_sig,\n",
    "             'thresh' : 0. * randz6(),\n",
    "             'slope' : 1.5 * randz6(),\n",
    "             'init_val' : 0.2 * randz6(),\n",
    "             'tau' : 0.02,\n",
    "             'tau_fast': 0.1,\n",
    "             'tau_mid' : 1.,\n",
    "             'tau_slow' : cfg['C_tau_slow'],\n",
    "             'custom_inp_del' : 15, # placeholder values\n",
    "             'custom_inp_del2': 30,\n",
    "             'integ_amp' : cfg['integ_amp'],\n",
    "             'integ_decay' : cfg['integ_decay'],\n",
    "             'adapt_amp' : cfg['adapt_amp'],\n",
    "             'delay' : 0.2,\n",
    "             'des_out_w_abs_sum' : 1. }\n",
    "CI_params = {'type' : unit_types.gated_rga_inpsel_adapt_sig,\n",
    "             'thresh' : 0.5 * randz6(),\n",
    "             'slope' : 2. * randz6(),\n",
    "             'init_val' : 0.2 * randz6(),\n",
    "             'tau' : 0.1,\n",
    "             'tau_fast': 0.1,\n",
    "             'tau_mid' : 1.,\n",
    "             'tau_slow' : cfg['C_tau_slow'],\n",
    "             'custom_inp_del' : 15, # placeholder values\n",
    "             'custom_inp_del2': 30,\n",
    "             'integ_amp' : cfg['integ_amp'], #.5,\n",
    "             'integ_decay' : cfg['integ_decay'],\n",
    "             'adapt_amp' : cfg['adapt_amp'],\n",
    "             'delay' : 0.2,\n",
    "             'des_out_w_abs_sum' : 1. }\n",
    "LPF_SP_params = {'type' : unit_types.linear,\n",
    "                 'init_val' : 0.3 * randz12(),\n",
    "                 'tau_fast': 0.005,\n",
    "                 'tau_mid': 0.05,\n",
    "                 'tau_slow' : 5.,\n",
    "                 'tau' : .5 }\n",
    "M_type = unit_types.gated_out_norm_am_sig if M_mod else unit_types.gated_out_norm_sig\n",
    "M_params = {'type' : M_type,\n",
    "            'thresh' : (cfg['M_thresh'] if 'M_thresh' in cfg else 0.1) * randz12(),  # 0\n",
    "            'slope' : (cfg['M_slope'] if 'M_slope' in cfg else 3.) * randz12(),\n",
    "            'init_val' : 0.2 * randz12(),\n",
    "            'delay' : 0.2,\n",
    "            'tau_fast': 0.15,\n",
    "            'tau_mid': 1.5,\n",
    "            'tau_slow' : 10.,\n",
    "            'tau' : 0.01 * randz12(),\n",
    "            'p1_inp' : cfg['M_p1_inp'] if 'M_p1_inp' in cfg else 0.,\n",
    "            'des_out_w_abs_sum' : 2. }\n",
    "SF_params = {'type' : unit_types.sigmoidal,\n",
    "             #'thresh' : np.array([-0.02]*12)\n",
    "             #'thresh' : np.array([-0.02, -0.01, 0.03, -0.01, -0.03, -0.02, -0.02, -0.01, 0.03, -0.01, -0.03, -0.02]),\n",
    "             'thresh' :  np.array([-0.12, -0.13, -0.05, -0.11, -0.03, -0.05, -0.05, -0.07, 0.05, 0.06, -0.03, -0.02]),\n",
    "             #'slope' : np.array([np.log(5.)]*12), #np.array([np.log(9.)]*12),\n",
    "             'slope' : cfg['SF_slope_factor']*np.array([2.75, 1.7, 1.37, 2.75] + [1.37]*2 + [2., 1.37, 1.37]*2),\n",
    "             'init_val' : 0.2 * randz12(),\n",
    "             'tau' : 0.03 * randz12() } \n",
    "SP_params = {'type' : unit_types.source,\n",
    "             'init_val' : 0.5,\n",
    "             'tau_fast' : 0.02,\n",
    "             'tau_mid' : 0.1,\n",
    "             'function' : lambda t: None }\n",
    "SP_CHG_params = {'type' : unit_types.sigmoidal,\n",
    "              'thresh' : 0.25,\n",
    "              'slope' : 9.,\n",
    "              'init_val' : 0.1,\n",
    "              'tau' : 0.01 }\n",
    "SPF_params = {'type' : unit_types.logarithmic, #sigmoidal,\n",
    "              'thresh' : -0.1, #0.4 * randz12(),\n",
    "              'slope' : 6. * randz12(),\n",
    "              'init_val' : 0.3 * randz12(),\n",
    "              'tau_fast': 0.005,\n",
    "              'tau_mid': 0.05,\n",
    "              'tau_slow' : 5.,\n",
    "              'tau' : 0.02 * randz12() }\n",
    "track_params = {'type' : unit_types.source,\n",
    "                'init_val' : 0.02,\n",
    "                'function' : lambda t: None }\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# CONNECTION DICTIONARIES\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# ACT to CE,CI ------------------------------------------------\n",
    "ACT__CE_conn = {'rule' : \"all_to_all\",\n",
    "                'delay' : 0.02 } \n",
    "ACT__CE_syn = {'type' : synapse_types.static,\n",
    "               'inp_ports' : 4,\n",
    "               'init_w' : 1. }\n",
    "ACT__CI_conn = {'rule' : \"all_to_all\",\n",
    "                'delay' : 0.02 } \n",
    "ACT__CI_syn = {'type' : synapse_types.static,\n",
    "               'inp_ports' : 4,\n",
    "               'init_w' : 1. }\n",
    "# AF to CE, CI --------------------------------------------------\n",
    "AF__CE_conn = {'rule' : 'all_to_all',\n",
    "               'delay' : 0.02 }\n",
    "AF__CE_syn = {'type' : synapse_types.gated_inp_sel,\n",
    "              'aff_port' : 2,\n",
    "              'inp_ports' : 2,\n",
    "              'error_port' : 0,\n",
    "              'normalize' : True,\n",
    "              'w_sum' : 2.,\n",
    "              'lrate' : 0., #10.,\n",
    "              'extra_steps' : 1,\n",
    "              'init_w' : 0.005 }\n",
    "AF__CI_conn = {'rule' : 'all_to_all',\n",
    "               'delay' : 0.02 }\n",
    "AF__CI_syn = {'type' : synapse_types.gated_inp_sel,\n",
    "              'aff_port' : 2,\n",
    "              'inp_ports' : 2,\n",
    "              'error_port' : 0,\n",
    "              'normalize' : True,\n",
    "              'w_sum' : 2.,\n",
    "              'lrate' : 0., #10.,\n",
    "              'extra_steps' : 1,\n",
    "              'init_w' : 0.005 }\n",
    "# AF to M ------------------------------------------------\n",
    "## Creating a test matrix\n",
    "if not rand_w:\n",
    "    # Initializing manually\n",
    "    AF_M = np.zeros((36, 12)) # rows are source, columns target\n",
    "    for src in range(36):\n",
    "        for trg in range(12):\n",
    "            src_pop = src%6 #src's population\n",
    "            trg_pop = trg%6 #trg's population\n",
    "            if src%18 < 6: # if the afferent is tension, don't reverse signs\n",
    "                sig = 1\n",
    "            else:\n",
    "                sig = -1\n",
    "            if src > 17: sig = -sig # if 'negative' afferent reverse sign\n",
    "            for pair in antagonists:\n",
    "                if pair == (src_pop, trg_pop):\n",
    "                    AF_M[src, trg] = sig*0.2\n",
    "                    break\n",
    "            else: \n",
    "                for pair in part_antag:\n",
    "                    if pair == (src_pop, trg_pop):\n",
    "                        AF_M[src, trg] = sig*0.1\n",
    "                        break\n",
    "                else: \n",
    "                    for pair in synergists:\n",
    "                        if pair == (src_pop, trg_pop):\n",
    "                            AF_M[src, trg] = sig*-0.2\n",
    "                            break\n",
    "                    else: \n",
    "                        for pair in synergists:\n",
    "                            if pair == (src_pop, trg_pop):\n",
    "                                AF_M[src, trg] = sig*-0.2\n",
    "                                break\n",
    "                        else: \n",
    "                            for pair in part_syne:\n",
    "                                if pair == (src_pop, trg_pop):\n",
    "                                    AF_M[src, trg] = sig*-0.1\n",
    "                                    break\n",
    "                            else:\n",
    "                                if src_pop == trg_pop:\n",
    "                                    AF_M[src, trg] = sig*-0.3\n",
    "else:\n",
    "    #AF_M = 0.2*(np.random.random((12,12)) - 0.5) # random initial connections!!!!!\n",
    "    AF_M = 0.2*(np.random.random((12,36)) - 0.5) # random initial connections!!!!!\n",
    "if noisy_syns:\n",
    "    AF__M_syn_type = synapse_types.noisy_gated_diff_inp_sel\n",
    "else:\n",
    "    AF__M_syn_type = synapse_types.gated_diff_inp_sel\n",
    "AF__M_conn = {'rule' : 'all_to_all',\n",
    "             'delay' : 0.02 }\n",
    "AF__M_syn = {'type' : AF__M_syn_type,\n",
    "            'aff_port' : 0,\n",
    "            'error_port' : 1,\n",
    "            'normalize' : not AF__M_decay if noisy_syns else True,\n",
    "            'w_sum' : cfg['AF__M_w_sum'] if 'AF__M_w_sum' in cfg else 10.,\n",
    "            'inp_ports' : 0, # afferent for out_norm_am_sig\n",
    "            'input_type' : 'pred', # if using inp_corr\n",
    "            'lrate' : cfg['AF__M_lrate'] if 'AF__M_lrate' in cfg else 15., \n",
    "            'decay' : AF__M_decay, # for noisy_gated_normal_rga_diff\n",
    "            'de_rate' : cfg['AF__M_de_rate'] if 'AF__M_de_rate' in cfg else 0.01,\n",
    "            'dr_amp' : 0.01, # drift amplitude (noisy_gated_normal_rga_diff)\n",
    "            'extra_steps' : None, # placeholder value; filled below,\n",
    "            'init_w' : AF_M.flatten() }\n",
    "# AF to SF ------------------------------------------------\n",
    "AF__SF_dubya = np.array([0.57, 0.56, 0.56, 0.57, 0.55, 0.55, 0.57, 0.56, 0.56, 0.57, 0.55, 0.55])\n",
    "AFe__SF_conn = {'rule' : 'one_to_one',\n",
    "              'delay' : 0.02 }\n",
    "AFe__SF_syn = {'type' : synapse_types.static,\n",
    "             #'init_w' : .5*np.array([ 39.73, 15.03,  9.66, 116.47, 8.63,  63.68, 20.88, 9.69, 5.86, 67.98, 5.44, 57.38]) }\n",
    "               #'init_w' : np.array([15.07516819, 20.60577773,  6.32821777, 14.08991768,  5.69679834,  8.89424814,\n",
    "               #                     7.68013805, 13.46076843,  3.87962611,  7.1693345,   3.5817668,   5.8075114 ])}\n",
    "               'init_w' : AF__SF_dubya}\n",
    "AFi__SF_conn = {'rule' : 'one_to_one',\n",
    "              'delay' : 0.02 }\n",
    "AFi__SF_syn = {'type' : synapse_types.static,\n",
    "             #'init_w' : .5*np.array([-162.42, -9.56, -15.19, -50.0, -88.47, -9.73, -67.67, -5.85, -9.96, -23.55, -50.63, -5.81])}\n",
    "              #'init_w' : np.array([-15.36496074,  -5.96985989, -21.78133701, -18.88200345, -11.38248201,\n",
    "              #            -6.93261446,  -7.53984025,  -3.68499008, -14.59079011,  -9.22649886,  -7.03063956,  -4.19297924])}\n",
    "              'init_w' : -AF__SF_dubya }\n",
    "# AL to P ------------------------------------------------\n",
    "AL__P_conn = {'inp_ports' : list(range(6)),\n",
    "             'delays': 0.01 }\n",
    "AL__P_syn = {'type': synapse_types.static,\n",
    "            'init_w' : 1. }\n",
    "# CE, CI to AL ----------------------------------------------\n",
    "CE__AL_conn = {'rule' : 'one_to_one',\n",
    "               'delay' : 0.01 }\n",
    "CE__AL_syn = {'type' : synapse_types.static,\n",
    "              'init_w' : [1., 1., 1., 1., 1., 1.] }\n",
    "CI__AL_conn = {'rule' : 'one_to_one',\n",
    "               'delay' : 0.01 }\n",
    "CI__AL_syn = {'type' : synapse_types.static,\n",
    "              'init_w' : -1. }\n",
    "# CE,CI to CE,CI  ------------------------------------------------\n",
    "CE__CI_conn = {'rule' : 'one_to_one',\n",
    "               'delay' : 0.01 }\n",
    "CI__CE_conn = {'rule' : 'one_to_one',\n",
    "               'delay' : 0.01 }\n",
    "CE__CI_syn = {'type' : synapse_types.static,\n",
    "              'inp_ports' : 2, #1, # IN AFFERENT PORT!!!!!!!!!!!!!!!!!!!!!! May affect normalization of afferent inputs\n",
    "              'init_w' : cfg['CE__CI_w'] if 'CE__CI_w' in cfg else 1. }\n",
    "CI__CE_syn = {'type' : synapse_types.static, #static, #corr_inh,\n",
    "              'inp_ports' : 2, #1, # IN AFFERENT PORT!!!!!!!!!!!!!!!!!!!!!! May affect normalization of afferent inputs\n",
    "              'lrate' : .0,\n",
    "              'des_act' : 0.5,\n",
    "              'init_w' : cfg['CI__CE_w'] if 'CI__CE_w' in cfg else -2. }\n",
    "C__C_conn = {'rule': 'one_to_one',\n",
    "             'allow_autapses' : False,\n",
    "             'delay' : 0.015 }\n",
    "C__C_syn_antag = {'type' : synapse_types.static, #bcm,\n",
    "                  'inp_ports': 2, #1, # IN AFFERENT PORT!!!!!!!!!!!!!!!!!!!!!! May affect normalization of afferent inputs\n",
    "                  'init_w' : cfg['C__C_antag'] if 'C__C_antag' in cfg else 2.,\n",
    "                  'lrate' : 1.,\n",
    "                  'des_act' : .5 }\n",
    "C__C_syn_p_antag = {'type' : synapse_types.static, #bcm,\n",
    "                  'inp_ports': 2, #1, # IN AFFERENT PORT!!!!!!!!!!!!!!!!!!!!!! May affect normalization of afferent inputs\n",
    "                  'init_w' : cfg['C__C_p_antag'] if 'C__C_p_antag' in cfg else .5,\n",
    "                  'lrate' : 1.,\n",
    "                  'des_act' : 0.2 }\n",
    "C__C_syn_syne = {'type' : synapse_types.static,\n",
    "                 'inp_ports': 1,\n",
    "                 'lrate' : 1.,\n",
    "                 'init_w' : .5 }\n",
    "C__C_syn_p_syne = {'type' : synapse_types.static,\n",
    "                   'inp_ports': 1,\n",
    "                   'lrate' : 1.,\n",
    "                   'init_w' : 0.2 }\n",
    "C__C_syn_null_lat = {'type' : synapse_types.static, # connection with static weight zero\n",
    "                   'inp_ports': 1,\n",
    "                   'lrate' : 1.,\n",
    "                   'init_w' : 0. }\n",
    "C__C_syn_null_aff = {'type' : synapse_types.static, # connection with static weight zero\n",
    "                   'inp_ports': 2, #1, # IN AFFERENT PORT!!!!!!!!!!!!!!!!!!!!!! May affect normalization of afferent inputs\n",
    "                   'lrate' : 1.,\n",
    "                   'init_w' : 0. }\n",
    "\n",
    "# LPF_SP to SPF (optional) ---------------------------------\n",
    "LPF_SPe__SPF_conn = {'rule': 'one_to_one',\n",
    "                     'delay': 0.01 }\n",
    "LPF_SPe__SPF_syn = {'type' : synapse_types.static,\n",
    "                    'inp_ports' : 1,\n",
    "                    'lrate' : 0.,\n",
    "                    'input_type' : 'error', # if using inp_corr\n",
    "                    'init_w' : cfg['SPF_w'] }\n",
    "LPF_SPi__SPF_conn = {'rule': 'one_to_one',\n",
    "                     'delay': 0.02 }\n",
    "LPF_SPi__SPF_syn = {'type' : synapse_types.static,\n",
    "                    'inp_ports' : 1,\n",
    "                    'lrate' : 0.,\n",
    "                    'input_type' : 'error', # if using inp_corr\n",
    "                    'init_w' : -cfg['SPF_w'] }\n",
    "\n",
    "# M to CE,CI ----------------------------------------------\n",
    "# creating a test matrix\n",
    "if not rand_w:\n",
    "    # initializing manually\n",
    "    M_CE = np.array(\n",
    "        [[ 0.2,  0.1, -0.1, -0.2,  0.1, -0.1],\n",
    "         [ 0.1,  0.2, -0.2, -0.1,  0.1,  0.0],\n",
    "         [-0.1, -0.2,  0.2,  0.1,  0.0,  0.0],\n",
    "         [-0.2, -0.1,  0.1, -0.2, -0.1,  0.1],\n",
    "         [ 0.1,  0.0,  0.0, -0.1,  0.3, -0.2],\n",
    "         [-0.1,  0.0,  0.0,  0.1, -0.2,  0.3],\n",
    "         [ 0.2,  0.1, -0.1, -0.2,  0.1, -0.1],\n",
    "         [ 0.1,  0.2, -0.2, -0.1,  0.1,  0.0],\n",
    "         [-0.1, -0.2,  0.2,  0.1,  0.0,  0.0],\n",
    "         [-0.2, -0.1,  0.1, -0.2, -0.1,  0.1],\n",
    "         [ 0.1,  0.0,  0.0, -0.1,  0.3, -0.2],\n",
    "         [-0.1,  0.0,  0.0,  0.1, -0.2,  0.3]])\n",
    "    M_CI = -M_CE \n",
    "else:\n",
    "    M_CE = 0.4*(np.random.random((12,6)) - 0.5) # random initial connections!!!!!\n",
    "    M_CI = 0.4*(np.random.random((12,6)) - 0.5) # random initial connections!!!!!\n",
    "if rga_diff:\n",
    "    if noisy_syns:\n",
    "        M__C_type = synapse_types.noisy_gated_normal_rga_diff\n",
    "    else:\n",
    "        M__C_type = synapse_types.gated_normal_rga_diff\n",
    "else:\n",
    "    if noisy_syns:\n",
    "        raise NotImplementedError('noisy_gated_normal_rga not implemented')\n",
    "    else:\n",
    "        M__C_type = synapse_types.gated_normal_rga\n",
    "M__CE_conn = {'rule': 'all_to_all',\n",
    "             'delay': 0.02 }\n",
    "M__CE_syn = {'type' : M__C_type,\n",
    "             'inp_ports' : 0,\n",
    "             'lrate' : cfg['M__C_lrate'] if 'M__C_lrate' in cfg else 20.,\n",
    "             'w_sum' : cfg['M__C_w_sum'],\n",
    "             'sig1' : cfg['sig1'],\n",
    "             'sig2' : cfg['sig2'],\n",
    "             'w_thresh' : 0.05,\n",
    "             'w_decay': 0.005,\n",
    "             'decay' : M__C_decay, # for noisy_gated_normal_rga_diff\n",
    "             'normalize' : not M__C_decay if noisy_syns else True,\n",
    "             'de_rate' : cfg['M__C_de_rate'] if 'M__C_de_rate' in cfg else 0.01,\n",
    "             'dr_amp' : cfg['M__C_dr_amp'] if 'M__C_dr_amp' in cfg else 0.01,\n",
    "             'w_tau' : 60.,\n",
    "             'init_w' : M_CE.flatten() }\n",
    "M__CI_conn = {'rule': 'all_to_all',\n",
    "             'delay': 0.02 }\n",
    "M__CI_syn = {'type' : M__C_type,\n",
    "             'inp_ports' : 0,\n",
    "             'lrate' : cfg['M__C_lrate'] if 'M__C_lrate' in cfg else 20.,\n",
    "             'w_sum' : cfg['M__C_w_sum'],\n",
    "             'sig1' : cfg['sig1'],\n",
    "             'sig2' : cfg['sig2'],\n",
    "             'w_thresh' : 0.05,\n",
    "             'w_tau' : 60.,\n",
    "             'w_decay': 0.005,\n",
    "             'decay' : M__C_decay, # for noisy_gated_normal_rga_diff\n",
    "             'normalize' : not M__C_decay if noisy_syns else True,\n",
    "             'de_rate' : cfg['M__C_de_rate'] if 'M__C_de_rate' in cfg else 0.01,\n",
    "             'dr_amp' : cfg['M__C_dr_amp'] if 'M__C_dr_amp' in cfg else 0.01,\n",
    "             'init_w' : M_CI.flatten() }\n",
    "# P to AF  ---------------------------------------------------\n",
    "idx_aff = np.arange(22,40) # indexes for afferent output in the arm\n",
    "P__AF_conn = {'port_map' : [[(p,0)] for p in idx_aff],\n",
    "             'delays' : 0.02 }\n",
    "Pe__AF_syn = {'type' : synapse_types.static,\n",
    "              'init_w' : [1.]*18 } \n",
    "Pi__AF_syn = {'type' : synapse_types.static,\n",
    "            'init_w' :  [-1.]*18 }\n",
    "# SP to LPF_SP ----------------------------------------------\n",
    "SP__LPF_SP_conn = {'rule': 'one_to_one',\n",
    "                   'delay': 0.01 }\n",
    "SP__LPF_SP_syn = {'type' : synapse_types.static,\n",
    "                  'init_w' : 1. }\n",
    "# SF, SP to SPF ---------------------------------------------\n",
    "SFe__SPF_conn = {'rule' : \"one_to_one\",\n",
    "                 'delay' : 0.01 }\n",
    "SFi__SPF_conn = {'rule' : \"one_to_one\",\n",
    "                 'delay' : 0.02 }\n",
    "SFe__SPF_syn = {'type' : synapse_types.static,\n",
    "                'init_w' : cfg['SPF_w'] }\n",
    "SFi__SPF_syn = {'type' : synapse_types.static,\n",
    "                'init_w' : -cfg['SPF_w'] }\n",
    "SPe__SPF_conn = {'rule' : \"one_to_one\",\n",
    "                 'delay' : 0.01 }\n",
    "SPi__SPF_conn = {'rule' : \"one_to_one\",\n",
    "                 'delay' : 0.02 }\n",
    "SPe__SPF_syn = {'type' : synapse_types.static,\n",
    "                'init_w' : cfg['SPF_w'] }\n",
    "SPi__SPF_syn = {'type' : synapse_types.static,\n",
    "               'init_w' : -cfg['SPF_w'] }\n",
    "# SP to SP_CHG ------------------------------------------------\n",
    "SP__SP_CHG_conn = {'rule' : 'all_to_all',\n",
    "                    'delay' : 0.01}\n",
    "SP__SP_CHG_syn = {'type' : synapse_types.chg,\n",
    "                  'init_w' : 0.,\n",
    "                  'lrate' : 20. }\n",
    "# SP_CHG to CE, CI ------------------------------------------------\n",
    "SP_CHG__CE_conn = {'rule' : \"all_to_all\",\n",
    "                  'delay' : 0.02 }\n",
    "SP_CHG__CE_syn = {'type' : synapse_types.static,\n",
    "                  'inp_ports' : 3,\n",
    "                  'init_w' : 1. }\n",
    "SP_CHG__CI_conn = {'rule' : \"all_to_all\",\n",
    "                   'delay' : 0.02 }\n",
    "SP_CHG__CI_syn = {'type' : synapse_types.static,\n",
    "                  'inp_ports' : 3,\n",
    "                  'init_w' : 1. }\n",
    "# SP_CHG to ACT ------------------------------------------------\n",
    "SP_CHG__ACT_conn = {'rule' : \"all_to_all\",\n",
    "                   'delay' : 0.02 }\n",
    "SP_CHG__ACT_syn = {'type' : synapse_types.static,\n",
    "                  'inp_ports' : 1,\n",
    "                  'init_w' : 1. }\n",
    "# SP_CHG to M ------------------------------------------------\n",
    "SP_CHG__M_conn = {'rule' : \"all_to_all\",\n",
    "                  'delay' : 0.02 }\n",
    "SP_CHG__M_syn = {'type' : synapse_types.static,\n",
    "                  'inp_ports' : 2,\n",
    "                  'init_w' : 1. }\n",
    "# SPF to ACT ------------------------------------------------\n",
    "SPF__ACT_conn = {'rule' : \"all_to_all\",\n",
    "                 'delay' : 0.02 }\n",
    "SPF__ACT_syn = {'type' : synapse_types.static,\n",
    "                'inp_ports' : 0,\n",
    "                'init_w' : 1. }\n",
    "\n",
    "# SPF to M  ------------------------------------------------\n",
    "SPF__M_conn = {'rule': 'one_to_one',\n",
    "               'delay': 0.01 }\n",
    "SPF__M_syn = {'type' : synapse_types.static, #synapse_types.inp_corr,\n",
    "              'inp_ports' : 1,\n",
    "              'lrate' : 0.,\n",
    "              'input_type' : 'error', # if using inp_corr\n",
    "              'init_w' : 1. }\n",
    "\n",
    "#*************************************************************\n",
    "# PROSPECTIVE CHANGES TO DEFAULTS\n",
    "# to reduce the trajectory asymmetry\n",
    "#C__C_syn_antag['init_w'] = .7\n",
    "#C__C_syn_p_antag['init_w'] = .1\n",
    "# to balance the muscles\n",
    "#P_params['g_e'] = 2.3*np.array([18., 20., 20., 18., 22., 23.])\n",
    "#P_params['b_e'] = 3.5\n",
    "# to stop circular reaching in high-gain sitauations\n",
    "#CE__CI_syn['init_w'] = 0.9\n",
    "#CI__CE_syn['init_w'] = -1.5\n",
    "# To adjust dynamic ranges\n",
    "#SF_params['slope'] = 8.*np.array([2.75, 1.7, 1.37, 2.75] + [1.37]*2 + [2., 1.37, 1.37]*2)\n",
    "#SF_params['thresh'] = np.array([-0.12, -0.13, -0.05, -0.11, -0.03, -0.05, -0.05, -0.07, 0.05, 0.06, -0.03, -0.02])\n",
    "# to promote long-term stability\n",
    "#M__CE_syn['lrate'] = 10.\n",
    "#M__CI_syn['lrate'] = 10.\n",
    "#M_params['thresh'] = 0.4 * randz12()\n",
    "#AF__M_syn['w_sum'] = 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*************************************************************\n",
    "# Setting the right delay for AF-->M\n",
    "f = 1. # going to estimate the extra delay of error inputs wrt afferent inputs at M\n",
    "w = 2.*np.pi*f\n",
    "sf_del = np.arctan(np.mean(SF_params['tau'])*w)/w\n",
    "spf_del = np.arctan(np.mean(SPF_params['tau'])*w)/w\n",
    "delay = spf_del + sf_del + AFe__SF_conn['delay'] + SFe__SPF_conn['delay']\n",
    "steps = int(round(delay/net.min_delay))\n",
    "AF_params['delay'] = AF_params['delay'] + (\n",
    "                     net_params['min_delay'] * (np.ceil(delay/net_params['min_delay']) + 1))\n",
    "AF__M_syn['extra_steps'] = steps\n",
    "#*************************************************************\n",
    "# utilitiy function for the M-->C delays used in the rga rule\n",
    "def approx_del(f):\n",
    "    \"\"\" Returns an estimate fo the optimal delay for rga learning.\n",
    "\n",
    "        We assume that the important loop for the learning rule in the C units\n",
    "        is the one going through C-AL-P-AF-M-C.\n",
    "        We also assume the delays to/from CI are the same as the ones for CE.\n",
    "\n",
    "        Args:\n",
    "            f : oscillation frequency of E-I pair in C, in Hertz\n",
    "        Returns:\n",
    "            2-tuple : (time_del, del_steps)\n",
    "            time_del : A float with the time delay.\n",
    "            del_steps : time delay as integer number of min_del steps.\n",
    "    \"\"\"\n",
    "    w = 2.*np.pi*f\n",
    "    al_del = np.arctan(np.mean(AL_params['tau'])*w)/w\n",
    "    p_del = np.arctan(np.mean(P_params['tau'])*w)/w\n",
    "    af_del = np.arctan(np.mean(AF_params['tau'])*w)/w\n",
    "    m_del = np.arctan(np.mean(M_params['tau'])*w)/w\n",
    "    D = [CE__AL_conn['delay'], AL__P_conn['delays'], np.mean(P__AF_conn['delays']),\n",
    "         AF__M_conn['delay'], M__CE_conn['delay'] ]\n",
    "    time_del = al_del + p_del + af_del + m_del + sum(D)\n",
    "    del_steps = int(np.ceil(time_del/net_params['min_delay']))\n",
    "    time_del = del_steps*net_params['min_delay']\n",
    "    del_steps -= 1 # because this is an index, and indexes start at 0\n",
    "    return time_del, del_steps\n",
    "############## Approximating the delays for the rga rule #############\n",
    "######## Using the utility function (for rga synapses)\n",
    "# time_del, del_steps = approx_del(0.01) #0.65 was approximate CE/CI frequency observed in simulations\n",
    "# #time_del, del_steps = (1., 200-1)\n",
    "# CE_params['delay'] = time_del\n",
    "# CI_params['delay'] = time_del\n",
    "# M_params['delay'] = time_del\n",
    "# CE_params['custom_inp_del'] = del_steps\n",
    "# CI_params['custom_inp_del'] = del_steps\n",
    "######## Using the two custom delays (for rga_diff synapses)\n",
    "dely1 = round(cfg['dely_low']/net.min_delay)*net.min_delay\n",
    "dely2 = dely1 + round(cfg['dely_diff']/net.min_delay)*net.min_delay\n",
    "del_steps1 = int(np.ceil(dely1/net_params['min_delay'])) - 1\n",
    "del_steps2 = int(np.ceil(dely2/net_params['min_delay'])) - 1\n",
    "CE_params['delay'] = dely2 + 0.01\n",
    "CI_params['delay'] = dely2 + 0.01\n",
    "M_params['delay'] = dely2 + 0.01\n",
    "CE_params['custom_inp_del'] = del_steps1\n",
    "CI_params['custom_inp_del'] = del_steps1\n",
    "CE_params['custom_inp_del2'] = del_steps2\n",
    "CI_params['custom_inp_del2'] = del_steps2\n",
    "#*************************************************************\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# CREATING UNITS\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "P = net.create(1, P_params)\n",
    "arm = net.plants[P]\n",
    "\n",
    "ACT = net.create(1, ACT_params)\n",
    "AF = net.create(36, AF_params)\n",
    "AL = net.create(6, AL_params)\n",
    "CE = net.create(6, CE_params)\n",
    "CI = net.create(6, CI_params)\n",
    "M = net.create(12, M_params)\n",
    "SF = net.create(12, SF_params)\n",
    "SP = net.create(12, SP_params)\n",
    "SP_CHG = net.create(1, SP_CHG_params)\n",
    "SPF = net.create(12, SPF_params)\n",
    "if lowpass_SP:\n",
    "    LPF_SP = net.create(12, LPF_SP_params)\n",
    "\n",
    "# SET THE PATTERNS IN SP -----------------------------------------------------\n",
    "# list with hand coordinates [x,y] (meters)\n",
    "if rand_targets is False:\n",
    "    hand_coords = [[0.3, 0.45], \n",
    "                   [0.35, 0.4],\n",
    "                   [0.4, 0.35],\n",
    "                   [0.35, 0.3],\n",
    "                   [0.3, 0.25],\n",
    "                   [0.25, 0.3],\n",
    "                   [0.2, 0.35],\n",
    "                   [0.25, 0.4]]\n",
    "                   #[-0.1, 0.3],\n",
    "                   #[-0.1, 0.35]] # experimental extra coordinates\n",
    "else:\n",
    "    # creating a list of random coordinates to use as targets\n",
    "    min_s_ang = -0.1 # minimum shoulder angle\n",
    "    max_s_ang = 0.8  # maximum shoulder angle\n",
    "    min_e_ang = 0.2 # minimum elbow angle\n",
    "    max_e_ang = 2.3 # maximum elbow angle\n",
    "    n_coords = 1000 # number of coordinates to generate\n",
    "    l_arm = net.plants[P].l_arm # upper arm length\n",
    "    l_farm = net.plants[P].l_farm # forearm length\n",
    "    hand_coords = [[0.,0.] for _ in range(n_coords)]\n",
    "    s_angs = (np.random.random(n_coords)+min_s_ang)*(max_s_ang-min_s_ang)\n",
    "    e_angs = (np.random.random(n_coords)+min_e_ang)*(max_e_ang-min_e_ang)\n",
    "    for i in range(n_coords):\n",
    "        hand_coords[i][0] = l_arm*np.cos(s_angs[i]) + l_farm*np.cos(s_angs[i]+e_angs[i]) # x-coordinate\n",
    "        hand_coords[i][1] = l_arm*np.sin(s_angs[i]) + l_farm*np.sin(s_angs[i]+e_angs[i]) # y-coordinate\n",
    "\n",
    "# list with muscle lengths corresponding to the hand coordinates\n",
    "m_lengths = []\n",
    "for coord in hand_coords:\n",
    "    m_lengths.append(arm.coords_to_lengths(coord))\n",
    "m_lengths = np.array(m_lengths)\n",
    "#(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)\n",
    "# We need to translate these lengths to corresponding SF activity levels.\n",
    "# For that it is necessary to recreate all their transformations\n",
    "# The first transformation is from length to Ia, II afferent activity.\n",
    "### OUT OF THE 36 AFFERENT SIGNALS, WE TAKE THE Ia AND II ###\n",
    "par = net.plants[P].m_params\n",
    "# steady state tensions in the static and dynamic bag fibers (no gamma inputs)\n",
    "Ts_ss = (par['k_se_s']/(par['k_se_s']+par['k_pe_s'])) * (\n",
    "         par['k_pe_s']*(m_lengths - par['l0_s']))\n",
    "Td_ss = (par['k_se_d']/(par['k_se_d']+par['k_pe_d'])) * (\n",
    "         par['k_pe_d']*(m_lengths - par['l0_d']))\n",
    "# steady state afferent outputs (no gamma inputs)\n",
    "Ia_ss = par['fs']*(Ts_ss/par['k_se_s']) + (1.-par['fs'])*(Td_ss/par['k_se_d'])\n",
    "II_ss = par['se_II']*(Ts_ss/par['k_se_s']) + ((1.-par['se_II'])/par['k_pe_s'])*Ts_ss\n",
    "Ia_ss *= par['Ia_gain']\n",
    "II_ss *= par['II_gain']\n",
    "Ia_II_ss = np.concatenate((Ia_ss, II_ss), axis=1)\n",
    "# Next transformation is through the afferent units\n",
    "Pe__AF_ws = np.array(Pe__AF_syn['init_w'][6:18])\n",
    "Pi__AF_ws = np.array(Pi__AF_syn['init_w'][6:18])\n",
    "#Ia_II_avgs = np.mean(Ia_II_ss, axis=0)  # when using hundreds of random targets\n",
    "# target averages\n",
    "AFe_thr = np.array([net.units[u].thresh for u in AF[6:18]])\n",
    "AFi_thr = np.array([net.units[u].thresh for u in AF[24:36]])\n",
    "#AF_Ia = np.maximum((Ia_ss - AF_avgs[0:6])*Pe__AF_Ia_ws - AF_thr[0:6], 0.)\n",
    "#AF_II = np.maximum((II_ss - AF_avgs[6:12])*Pe__AF_II_ws - AF_thr[6:12], 0.)\n",
    "AFe_Ia_II = np.log(1. + np.maximum((Ia_II_ss)*Pe__AF_ws - AFe_thr, 0.))\n",
    "AFi_Ia_II = np.log(1. + np.maximum((Ia_II_ss)*Pi__AF_ws - AFi_thr, 0.))\n",
    "#(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)\n",
    "# Next is from AF to SF\n",
    "SF_arg = AFe__SF_syn['init_w']*AFe_Ia_II + AFi__SF_syn['init_w']*AFi_Ia_II\n",
    "SF_out = 1./ (1. + np.exp(-SF_params['slope']*(SF_arg - SF_params['thresh'])))\n",
    "SF_params['init_val'] = SF_out # this might cause a smooth start\n",
    "# now we set the values in SP\n",
    "m_idxs = np.random.randint(len(hand_coords), size=1000) # index of all targets\n",
    "    #m_idxs[0] = 0 # for testing\n",
    "AF_us = [net.units[u] for u in AF]\n",
    "\n",
    "def SF_sigmo(idx, arg):\n",
    "    \"\"\" The sigmoidal function for SF unit with index SF[idx]. \"\"\"\n",
    "    return 1./ (1. + np.exp(-SF_params['slope'][idx]*(arg - SF_params['thresh'][idx])))\n",
    "\n",
    "def cur_target(t):\n",
    "    \"\"\" Returns the index of the target at time t. \"\"\"\n",
    "    return m_idxs[int(np.floor(t/t_pres))]\n",
    "\n",
    "def make_fun(idx):\n",
    "    \"\"\" create a function for the SP unit with index 'idx'. \"\"\"\n",
    "    return lambda t: SF_sigmo(idx, \n",
    "                        AFe__SF_syn['init_w'][idx] * (\n",
    "                        np.log(1. + max(Ia_II_ss[cur_target(t)][idx] * Pe__AF_ws[idx] - \n",
    "                        net.units[AF[6+idx]].thresh, 0.))) +\n",
    "                        AFi__SF_syn['init_w'][idx] * (\n",
    "                        np.log(1. + max(Ia_II_ss[cur_target(t)][idx] * Pi__AF_ws[idx] - \n",
    "                        net.units[AF[24+idx]].thresh, 0.))))\n",
    "    #return lambda t: SF_out[m_idxs[int(np.floor(t/t_pres))]][idx]\n",
    "\n",
    "for idx, u in enumerate(SP):\n",
    "    net.units[u].set_function(make_fun(idx))\n",
    "\n",
    "# tracking units\n",
    "M_CE_track = net.create(len(M), track_params) # to track weights from M to CE\n",
    "#M_CI_track = net.create(len(M), track_params) # to track weights from M to CI\n",
    "AF_M0_track = net.create(18, track_params) # to track the weights from AF to M0\n",
    "\n",
    "# xp_track = net.create(1, track_params) # del_avg_inp_deriv of C0 at port 1\n",
    "# up_track = net.create(1, track_params) # to track the derivative of CE0\n",
    "# if rga_diff is True:\n",
    "#     sp_now_track = net.create(1, track_params)\n",
    "#     sp_del_track = net.create(1, track_params)\n",
    "#     spj_now_track = net.create(1, track_params)\n",
    "#     spj_del_track = net.create(1, track_params)\n",
    "# else:\n",
    "#     sp_track = net.create(1, track_params) # avg_inp_deriv_mp for CE0 at port 0\n",
    "#     spj_track = net.create(1, track_params) # input derivative for MX--CE0\n",
    "\n",
    "ipx_track = net.create(12, track_params) # x coordinates of insertion points\n",
    "ipy_track = net.create(12, track_params) # y coordinates of insertion points\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# CONNECTING\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# from M to CE\n",
    "net.connect(M, CE, M__CE_conn, M__CE_syn)\n",
    "# from M to CI\n",
    "net.connect(M, CI, M__CI_conn, M__CI_syn)\n",
    "# from CE to AL\n",
    "net.connect(CE, AL, CE__AL_conn, CE__AL_syn)\n",
    "# from CI to AL\n",
    "net.connect(CI, AL, CI__AL_conn, CI__AL_syn)\n",
    "# from AL to P\n",
    "net.set_plant_inputs(AL, P, AL__P_conn, AL__P_syn)\n",
    "# from P to AF\n",
    "net.set_plant_outputs(P, AF[0:18], P__AF_conn, Pe__AF_syn)\n",
    "net.set_plant_outputs(P, AF[18:36], P__AF_conn, Pi__AF_syn)\n",
    "# from AF to SF. Only Ia and II are selected\n",
    "net.connect(AF[6:18], SF, AFe__SF_conn, AFe__SF_syn)\n",
    "net.connect(AF[24:36], SF, AFi__SF_conn, AFi__SF_syn)\n",
    "# from AF to M\n",
    "## When connecting from all afferents:\n",
    "net.connect(AF, M, AF__M_conn, AF__M_syn) # should be made before SPF-->M\n",
    "## When connecting only from tension afferents\n",
    "#net.connect(AF[0:6]+AF[18:24], M, AF__M_conn, AF__M_syn) # should be made before SPF-->M\n",
    "# from AF to CE,CI\n",
    "#net.connect(AF, CE, AF__CE_conn, AF__CE_syn)\n",
    "#net.connect(AF, CI, AF__CI_conn, AF__CI_syn)\n",
    "# from SP to SPF (or LP->LPF_SP->SPF)\n",
    "if lowpass_SP:\n",
    "    net.connect(SP, LPF_SP, SP__LPF_SP_conn, SP__LPF_SP_syn)\n",
    "    #net.connect(LPF_SP, SPF, LPF_SPe__SPF_conn, LPF_SPe__SPF_syn) # P-F\n",
    "    net.connect(LPF_SP, SPF, LPF_SPi__SPF_conn, LPF_SPi__SPF_syn) # F-P\n",
    "else:\n",
    "    net.connect(SP, SPF, SPi__SPF_conn, SPi__SPF_syn) # F-P\n",
    "    #net.connect(SP, SPF, SPe__SPF_conn, SPe__SPF_syn)  # P-F\n",
    "# from SF to SPF\n",
    "net.connect(SF, SPF, SFe__SPF_conn, SFe__SPF_syn) # F-P\n",
    "#net.connect(SF, SPF, SFi__SPF_conn, SFi__SPF_syn)  # P-F\n",
    "# from SPF to M (or to LPF_SPF)\n",
    "net.connect(SPF, M, SPF__M_conn, SPF__M_syn) # should be after AF-->M\n",
    "# from SPF to ACT\n",
    "net.connect(SPF, ACT, SPF__ACT_conn, SPF__ACT_syn)\n",
    "# from SP to SP_CHG\n",
    "net.connect(SP, SP_CHG, SP__SP_CHG_conn, SP__SP_CHG_syn)\n",
    "# from SP_CHG to CE,CI\n",
    "net.connect(SP_CHG, CE, SP_CHG__CE_conn, SP_CHG__CE_syn)\n",
    "net.connect(SP_CHG, CI, SP_CHG__CI_conn, SP_CHG__CI_syn)\n",
    "# from SP_CHG to M\n",
    "net.connect(SP_CHG, M, SP_CHG__M_conn, SP_CHG__M_syn)\n",
    "# from SP_CHG to ACT\n",
    "net.connect(SP_CHG, ACT, SP_CHG__ACT_conn, SP_CHG__ACT_syn)\n",
    "# from ACT to CE, CI\n",
    "net.connect(ACT, CE, ACT__CE_conn, ACT__CE_syn)\n",
    "net.connect(ACT, CI, ACT__CI_conn, ACT__CI_syn)\n",
    "# intraspinal connections \n",
    "# from CE to CI, and CI to CE\n",
    "#net.connect(CE, CI, CE__CI_conn, CE__CI_syn)\n",
    "#net.connect(CI, CE, CI__CE_conn, CI__CE_syn)\n",
    "# agonists and antagonists\n",
    "for pair in all_pairs:\n",
    "    if pair in synergists:\n",
    "        net.connect([CE[pair[0]]], [CE[pair[1]]], C__C_conn, C__C_syn_syne)\n",
    "        net.connect([CE[pair[0]]], [CI[pair[1]]], C__C_conn, C__C_syn_null_aff)\n",
    "        net.connect([CI[pair[0]]], [CE[pair[1]]], C__C_conn, C__C_syn_null_aff)\n",
    "        net.connect([CI[pair[0]]], [CI[pair[1]]], C__C_conn, C__C_syn_null_lat)\n",
    "    elif pair in part_syne:\n",
    "        net.connect([CE[pair[0]]], [CE[pair[1]]], C__C_conn, C__C_syn_p_syne)\n",
    "        net.connect([CE[pair[0]]], [CI[pair[1]]], C__C_conn, C__C_syn_null_aff)\n",
    "        net.connect([CI[pair[0]]], [CE[pair[1]]], C__C_conn, C__C_syn_null_aff)\n",
    "        net.connect([CI[pair[0]]], [CI[pair[1]]], C__C_conn, C__C_syn_null_lat)\n",
    "    elif pair in antagonists:\n",
    "        net.connect([CE[pair[0]]], [CI[pair[1]]], C__C_conn, C__C_syn_antag)\n",
    "        net.connect([CE[pair[0]]], [CE[pair[1]]], C__C_conn, C__C_syn_null_lat)\n",
    "        net.connect([CI[pair[0]]], [CE[pair[1]]], C__C_conn, C__C_syn_null_aff)\n",
    "        net.connect([CI[pair[0]]], [CI[pair[1]]], C__C_conn, C__C_syn_null_lat)\n",
    "    elif pair in part_antag:\n",
    "        net.connect([CE[pair[0]]], [CI[pair[1]]], C__C_conn, C__C_syn_p_antag)\n",
    "        net.connect([CE[pair[0]]], [CE[pair[1]]], C__C_conn, C__C_syn_null_lat)\n",
    "        net.connect([CI[pair[0]]], [CE[pair[1]]], C__C_conn, C__C_syn_null_aff)\n",
    "        net.connect([CI[pair[0]]], [CI[pair[1]]], C__C_conn, C__C_syn_null_lat)\n",
    "    elif pair in self_conn:\n",
    "        net.connect([CE[pair[0]]], [CI[pair[1]]], CE__CI_conn, CE__CI_syn)\n",
    "        net.connect([CI[pair[0]]], [CE[pair[1]]], CI__CE_conn, CI__CE_syn)\n",
    "    else:\n",
    "        net.connect([CE[pair[0]]], [CE[pair[1]]], C__C_conn, C__C_syn_null_lat)\n",
    "        net.connect([CE[pair[0]]], [CI[pair[1]]], C__C_conn, C__C_syn_null_aff)\n",
    "        net.connect([CI[pair[0]]], [CE[pair[1]]], C__C_conn, C__C_syn_null_aff)\n",
    "        net.connect([CI[pair[0]]], [CI[pair[1]]], C__C_conn, C__C_syn_null_lat)\n",
    "\n",
    "# SETTING UP WEIGHT TRACKING -- depends on the order of statements above!!!!!!\n",
    "# This assumes the first connections to C are M-->C\n",
    "def M_CE0_fun(idx):\n",
    "    \"\"\" Creates a function to track a weight from M to CE0. \"\"\"\n",
    "    return lambda t: net.syns[CE[0]][idx].w\n",
    "for idx in range(len(M)):\n",
    "    net.units[M_CE_track[idx]].set_function(M_CE0_fun(idx))\n",
    "# This assumes the first connections to M are AF-->M    \n",
    "def AF_M0_fun(idx):\n",
    "    \"\"\" Creates a function to track a weight from AF to M0. \"\"\"\n",
    "    return lambda t: net.syns[M[0]][idx].w\n",
    "for idx, uid in enumerate(AF_M0_track):\n",
    "    net.units[uid].set_function(AF_M0_fun(idx))\n",
    "\n",
    "# SETTING TRACKING OF PLASTICITY FACTORS FOR MX-->CE0\n",
    "# X = 0 # index of the M unit we'll monitor\n",
    "# if rga_diff:\n",
    "#     CE0 = net.units[CE[0]]\n",
    "#     net.units[xp_track[0]].set_function(lambda t: CE0.double_del_avg_inp_deriv_mp[1][1])\n",
    "#     po_de = CE0.custom_inp_del2\n",
    "#     pre_de = CE0.custom_inp_del2 - CE0.custom_inp_del\n",
    "#     net.units[up_track[0]].set_function(lambda t: CE0.get_lpf_fast(po_de) - CE0.get_lpf_mid(po_de))\n",
    "#     net.units[sp_now_track[0]].set_function(lambda t: CE0.avg_inp_deriv_mp[0])\n",
    "#     net.units[sp_del_track[0]].set_function(lambda t: CE0.double_del_avg_inp_deriv_mp[0][0])\n",
    "#     ds = net.syns[CE[0]][X].delay_steps\n",
    "#     net.units[spj_now_track[0]].set_function(lambda t: net.units[M[X]].get_lpf_fast(ds) - \n",
    "#                                                        net.units[M[X]].get_lpf_mid(ds))\n",
    "#     net.units[spj_del_track[0]].set_function(lambda t: CE0.double_del_inp_deriv_mp[0][0][net.syns[CE[0]][X].ddidm_idx])\n",
    "# else:\n",
    "#     net.units[xp_track[0]].set_function(lambda t: net.units[CE[0]].del_avg_inp_deriv_mp[1])\n",
    "#     po_de = net.units[CE[0]].custom_inp_del\n",
    "#     net.units[up_track[0]].set_function(lambda t: net.units[CE[0]].get_lpf_fast(po_de) - \n",
    "#                                         net.units[CE[0]].get_lpf_mid(po_de))\n",
    "#     net.units[sp_track[0]].set_function(lambda t: net.units[CE[0]].avg_inp_deriv_mp[0])\n",
    "#     ds = net.syns[CE[0]][0].delay_steps\n",
    "#     net.units[spj_track[0]].set_function(lambda t: net.units[M[X]].get_lpf_fast(ds) - \n",
    "#                                          net.units[M[X]].get_lpf_mid(ds))\n",
    "\n",
    "# TRACKING OF INSERTION POINTS (for the arm animation)\n",
    "# make the source units track the tensions\n",
    "def create_xtracker(arm_id, idx):\n",
    "    return lambda t: net.plants[arm_id].ip[idx][0]\n",
    "def create_ytracker(arm_id, idx):\n",
    "    return lambda t: net.plants[arm_id].ip[idx][1]\n",
    "for idx, uid in enumerate(ipx_track):\n",
    "    net.units[uid].set_function(create_xtracker(P, idx))\n",
    "for idx, uid in enumerate(ipy_track):\n",
    "    net.units[uid].set_function(create_ytracker(P, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "times, data, plant_data  = net.flat_run(640.)\n",
    "#times, data, plant_data  = net.run(40.)\n",
    "print('Execution time is %s seconds' % (time.time() - start_time))\n",
    "data = np.array(data)\n",
    "#Execution time is 8.687349319458008 seconds  << before sc_inp_sum_mp, flat_run(5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the adaptation\n",
    "for uid in CE+CI:\n",
    "    for syn in net.syns[uid]:\n",
    "        if syn.preID in ACT:\n",
    "            syn.w = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower M thresholds\n",
    "for uid in M:\n",
    "    net.units[uid].thresh = -0.1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# reducing the scope of the plots\n",
    "data_back = data\n",
    "times_back = times\n",
    "plant_data_back = [np.array([])]\n",
    "plant_data_back[0] = plant_data[0]\n",
    "\n",
    "first_idx=100*200\n",
    "second_idx=115*200\n",
    "times = times[first_idx:second_idx]\n",
    "data = data[:, first_idx:second_idx]\n",
    "plant_data[0] = plant_data[0][first_idx:second_idx,:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# recover the data\n",
    "data = data_back\n",
    "plant_data[0] = plant_data_back[0]\n",
    "times = times_back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same history as `v3_nst_afx`\n",
    "\n",
    "---\n",
    "**Using logarithmic units in SF **\n",
    "---\n",
    "* With: \n",
    "SF_params['slope'] = 8.*np.array([1.35, 1.38, 1.43, 1.37, 1.35, 1.36, 1.35, 1.38, 1.43, 1.37, 1.35, 1.36])\n",
    "CE_params['tau'] = 0.02\n",
    "CI_params['tau'] = 0.1\n",
    "ACT_params['y_min'] = 0.2\n",
    "ACT_params['tau_u'] = 7.\n",
    "P_params['k_pe_e'] = 25.\n",
    "P_params['k_se_e'] = 20.\n",
    "P_params['g_e'] = 2.*np.array([17., 20., 18., 17., 20., 20.])\n",
    "CI__CE_syn['init_w'] = -2.\n",
    "SPFw = 1.3\n",
    "SPe__SPF_syn['init_w'] = SPFw\n",
    "SPi__SPF_syn['init_w'] = -SPFw\n",
    "SFe__SPF_syn['init_w'] = SPFw\n",
    "SFi__SPF_syn['init_w'] = -SPFw\n",
    "AL_params['thresh'] = 0.3\n",
    "AL_params['tau'] = 0.02\n",
    "CE_params['integ_amp'] = 0.\n",
    "CI_params['integ_amp'] = 0.\n",
    "CE_params['adapt_amp'] = 5.\n",
    "CI_params['adapt_amp'] = 5.  \n",
    "Reaching is done with oscillations. Mean error of ~0.1 after removing adaptation. Elbow seems uncapable of reaching small angles.\n",
    "* Adding a bit more strength to the elbow extensor, and more damping to the muscles:\n",
    "P_params['b_e'] = 8., \n",
    "P_params['g_e'] = 2.*np.array([17., 20., 18., 17., 20., 22.]).  \n",
    "Reaching seems to be lazier.\n",
    "* Removing some damping from the muscles:\n",
    "P_params['b_e'] = 4.  \n",
    "Reaching got pretty lazy. Mean error of ~0.2 in the first 1000 seconds.\n",
    "* Adding more damping to the muscles\n",
    "P_params['b_e'] = 8.  \n",
    "Reching looks OK, but the elbow seems too lazy. Converging took ~600 seconds, but after that the average error was around 0.11.\n",
    "* Adding monster elbow rotators:\n",
    "P_params['g_e'] = 2.*np.array([17., 20., 18., 17., 30., 32.]).  \n",
    "Seems to have gotten worse. \n",
    "* Using a waker arm, and also 20/20 muscle tensions: \n",
    "P_params['g_e'] = 1.5*np.array([17., 20., 18., 17., 20., 22.]).,\n",
    "P_params['k_pe_e'] = 20.,\n",
    "P_params['k_se_e'] = 20. ...\n",
    "---\n",
    "* to reduce the trajectory asymmetry  \n",
    "C__C_syn_antag['init_w'] = 1.5   \n",
    "C__C_syn_p_antag['init_w'] = .2  \n",
    "to balance the muscles  \n",
    "P_params['g_e'] = 2.5*np.array([17., 20., 20., 17., 24., 26.])  \n",
    "to stop circular reaching in high-gain sitauations  \n",
    "CE__CI_syn['init_w'] = .7 ...  \n",
    "not very good"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save the state of the network\n",
    "state = net.save_state()\n",
    "state[\"comments\"] = \"Saved in v3_normal_smac_test.ipynb on 07/17/2020 after running incumbent 9 for 4000 seconds with SF slope multiplier of 5.\"\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "fname = \"state_v3nst\"\n",
    "fname += \"_\" + datetime.now().strftime('%Y-%m-%d__%H_%M')\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(state, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load a saved state\n",
    "import pickle\n",
    "fname = 'state_v3nst_2020-07-17__15_05'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    results = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_activs = plant_data[P]\n",
    "# SPF\n",
    "fs = (25,6)\n",
    "SPF_fig = plt.figure(figsize=fs)\n",
    "SPF_data = np.array(data[SPF])\n",
    "plt.plot(times, SPF_data.transpose())\n",
    "SPF_legends = ['SPF'+str(i) for i in range(len(SPF))]\n",
    "plt.legend(SPF_legends)\n",
    "plt.title('SPF')\n",
    "print(SPF_data[:,-1])\n",
    "\n",
    "# M\n",
    "M_fig = plt.figure(figsize=fs)\n",
    "M_data = np.array(data[M])\n",
    "plt.plot(times, M_data.transpose())\n",
    "M_legends = ['M'+str(i) for i in range(len(M))]\n",
    "plt.legend(M_legends)\n",
    "plt.title('M')\n",
    "print(M_data[:,-1])\n",
    "\n",
    "# C\n",
    "C_fig = plt.figure(figsize=fs)\n",
    "CE_data = np.array(data[CE])\n",
    "CI_data = np.array(data[CI])\n",
    "plt.plot(times, CE_data.transpose(), linewidth=2)\n",
    "plt.plot(times, CI_data.transpose(), '--')\n",
    "C_legends = ['CE'+str(i) for i in range(len(CE))]\n",
    "C_legends += ['CI'+str(i) for i in range(len(CI))]\n",
    "plt.legend(C_legends)\n",
    "plt.title('C')\n",
    "\n",
    "# M--CE0 weights\n",
    "W_fig1 = plt.figure(figsize=fs)\n",
    "w_track_data = np.array(data[M_CE_track])\n",
    "plt.plot(times, w_track_data.transpose())\n",
    "M_CE0_legends = ['M'+str(i)+'--CE0' for i in range(len(M_CE_track))]\n",
    "plt.legend(M_CE0_legends)\n",
    "plt.title('M--CE0 weights')\n",
    "\n",
    "# AF--M0 weights\n",
    "W_fig2 = plt.figure(figsize=fs)\n",
    "w_track_data2 = np.array(data[AF_M0_track[0:18]])\n",
    "plt.plot(times, w_track_data2.transpose())\n",
    "AF_M0_legends = ['AF'+str(i)+'--M0' for i in range(len(AF_M0_track[:18]))]\n",
    "plt.legend(AF_M0_legends)\n",
    "plt.title('AF--M0 weights exc')\n",
    "\"\"\"\n",
    "W_fig3 = plt.figure(figsize=fs)\n",
    "w_track_data3 = np.array(data[AF_M0_track[18:]])\n",
    "plt.plot(times, w_track_data3.transpose())\n",
    "AF_M0_legends2 = ['AF'+str(i)+'--M0' for i in range(len(AF_M0_track[18:]))]\n",
    "plt.legend(AF_M0_legends2)\n",
    "plt.title('AF--M0 weights inh')\n",
    "\"\"\"\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P\n",
    "P_fig = plt.figure(figsize=fs)\n",
    "P_state = plant_data[P][:,0:4:2]\n",
    "plt.plot(times, P_state)\n",
    "#plt.legend(['sh ang', 'sh ang vel', 'elb ang', 'elb ang vel'])\n",
    "plt.legend(['sh ang', 'elb ang',])\n",
    "plt.title('double pendulum state variables')\n",
    "print(\"shoulder angle: %f, shoulder vel: %f\" % (P_state[-1,0],P_state[-1,1]))\n",
    "\n",
    "# AF plus\n",
    "AFe_fig = plt.figure(figsize=fs)\n",
    "AFe_data = np.array(data[AF[0:18]])\n",
    "plt.plot(times, AFe_data.transpose())\n",
    "AF_legends = ['Ib' + str(i) for i in range(6)] + \\\n",
    "             ['Ia' + str(i) for i in range(6)] + \\\n",
    "             ['II' + str(i) for i in range(6)]\n",
    "plt.legend(AF_legends)\n",
    "plt.title('AF excited')\n",
    "print('AFe_data:')\n",
    "print(AFe_data[:,-1])\n",
    "\n",
    "# AF minus\n",
    "AFi_fig = plt.figure(figsize=fs)\n",
    "AFi_data = np.array(data[AF[18:36]])\n",
    "plt.plot(times, AFi_data.transpose())\n",
    "AF_legends = ['Ib' + str(i) for i in range(6)] + \\\n",
    "             ['Ia' + str(i) for i in range(6)] + \\\n",
    "             ['II' + str(i) for i in range(6)]\n",
    "plt.legend(AF_legends)\n",
    "plt.title('AF inhibited')\n",
    "print('AFi_data:')\n",
    "print(AFi_data[:,-1])\n",
    "\n",
    "fs = (30,10)\n",
    "# SF, SP\n",
    "SF_fig, axs = plt.subplots(2, 2, figsize=(fs[0], 2.2*fs[1]))\n",
    "SF_data = np.array(data[SF])\n",
    "SP_data = np.array(data[SP])\n",
    "if 'lowpass_SP' in locals() and lowpass_SP is True:\n",
    "    LPF_SP_data = np.array(data[LPF_SP])\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        ax = axs[row][col]\n",
    "        base = 3*col + 6*row\n",
    "        ax.plot(times, SF_data[base:base+3, :].transpose(), linewidth=2)\n",
    "        ax.plot(times, SP_data[base:base+3, :].transpose(), '--', linewidth=1)\n",
    "        if 'lowpass_SP' in locals() and lowpass_SP is True:\n",
    "            ax.plot(times, LPF_SP_data[base:base+3, :].transpose(), linewidth=2)\n",
    "        ax.set_title('SF, SP, units %d to %d' % (base, base+3))\n",
    "        SF_legends = ['SF '+ str(base+i) for i in range(3)]\n",
    "        SP_legends = ['SP '+ str(base+i) for i in range(3)]\n",
    "        ax.legend(SF_legends + SP_legends)\n",
    "\n",
    "plt.show()\n",
    "print('SF = ')\n",
    "print(SF_data[:,-1])\n",
    "print('SP = ')\n",
    "print(SP_data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x,window_len=11,window='hanning'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "    \n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal \n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "    \n",
    "    input:\n",
    "        x: the input signal \n",
    "        window_len: the dimension of the smoothing window; should be an odd integer\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    output:\n",
    "        the smoothed signal\n",
    "        \n",
    "    example:\n",
    "\n",
    "    t=linspace(-2,2,0.1)\n",
    "    x=sin(t)+randn(len(t))*0.1\n",
    "    y=smooth(x)\n",
    "    \n",
    "    see also: \n",
    "    \n",
    "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "    scipy.signal.lfilter\n",
    " \n",
    "    TODO: the window parameter could be the window itself if an array instead of a string\n",
    "    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n",
    "    \"\"\"\n",
    "\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError(\"smooth only accepts 1 dimension arrays.\")\n",
    "    if x.size < window_len:\n",
    "        raise ValueError(\"Input vector needs to be bigger than window size.\")\n",
    "    if window_len<3:\n",
    "        return x\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise ValueError(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('np.'+window+'(window_len)')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n",
    "\n",
    "chg_fig = plt.figure(figsize=fs)\n",
    "chg_data = np.array(data[SP_CHG])[0]\n",
    "plt.plot(times, chg_data)\n",
    "plt.title('SP_CHG')\n",
    "\n",
    "act_fig = plt.figure(figsize=fs)\n",
    "act_data = np.array(data[ACT])[0]\n",
    "plt.plot(times, act_data)\n",
    "plt.plot(times, 0.8*np.ones_like(times), 'k--')\n",
    "plt.title('ACT')\n",
    "\n",
    "plant = net.plants[P]\n",
    "# modified copy-paste of plt.upd_ip_impl\n",
    "q1 = arm_activs[:,0]\n",
    "q2 = arm_activs[:,2]\n",
    "q12 = q1+q2\n",
    "c_elbow = np.array((plant.l_arm*np.cos(q1), plant.l_arm*np.sin(q1)))\n",
    "c_hand = np.array((c_elbow[0] + plant.l_farm*np.cos(q12),\n",
    "                   c_elbow[1] + plant.l_farm*np.sin(q12))).transpose()\n",
    "if 'start_t' in locals():\n",
    "    coord_idxs = np.floor((times-start_t)/t_pres).astype(int) # after resetting the targets\n",
    "    des_coords = np.array([hand_coords[idx] for idx in [m_idxs[cid] for cid in coord_idxs]])\n",
    "else:\n",
    "    coord_idxs = np.floor(times/t_pres).astype(int)  # before resetting the targets\n",
    "    des_coords = np.array(hand_coords)[m_idxs[coord_idxs],:] # desired coordinates at each moment in time\n",
    "coords_fig = plt.figure(figsize=fs)\n",
    "plt.plot(times, c_hand)\n",
    "plt.plot(times, des_coords)\n",
    "plt.title('desired vs. actual hand coordinates')\n",
    "plt.legend(['X', 'Y', 'des_X', 'des_Y'])\n",
    "\n",
    "err_fig = plt.figure(figsize=fs)\n",
    "w_len = 10001\n",
    "hand_error = np.linalg.norm(c_hand-des_coords, axis=1)\n",
    "smooth_hand_error = smooth(hand_error, window_len=w_len)[int(np.floor(w_len/2)):-int(np.floor(w_len/2))]\n",
    "plt.plot(times, smooth_hand_error)\n",
    "plt.plot(times, hand_error, 'r--')\n",
    "plt.plot(times, 0.1+np.zeros(smooth_hand_error.size), 'k--')\n",
    "plt.title('distance error')\n",
    "avg_error = hand_error.sum()/hand_error.size\n",
    "print(\"average error: %f\" % (avg_error))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha units\n",
    "fs2 =(25,5)\n",
    "AL_fig = plt.figure(figsize=fs2)\n",
    "AL_data = np.array(data[AL])\n",
    "plt.plot(times, AL_data.transpose())\n",
    "AL_legends = ['AL'+str(i) for i in range(len(AL))]\n",
    "plt.legend(AL_legends)\n",
    "plt.title('AL')\n",
    "print('AL_data:')\n",
    "print(AL_data[:,-1])\n",
    "\n",
    "# plotting muscle outputs\n",
    "#fs = (20,5)\n",
    "legs = ['Ib', 'Ia', 'II']\n",
    "\n",
    "for i in range(6):\n",
    "    next_fig = plt.figure(figsize=fs2)\n",
    "    Ib = arm_activs[:,22+i]\n",
    "    Ia = arm_activs[:,28+i]\n",
    "    II = arm_activs[:,34+i]\n",
    "    plt.plot(times, Ib, times, Ia, times, II)\n",
    "    #plt.plot(times, Ib)\n",
    "    plt.legend(legs)\n",
    "    plt.title('m' + str(i))\n",
    "    print('Ib avg for muscle '+ str(i) + '= ' + str(np.mean(Ib)))\n",
    "    print('Ia avg for muscle '+ str(i) + '= ' + str(np.mean(Ia)))\n",
    "    print('II avg for muscle '+ str(i) + '= ' + str(np.mean(II)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new targets\n",
    "t_pres = 20. # new presentation time\n",
    "start_t = net.sim_time # starting time for new simulation\n",
    "# 8 radial targets in sequence, from 0 to 315 degrees\n",
    "r = 0.12 # distance from center to targets\n",
    "center = np.array([0.3, 0.3]) # initial hand location\n",
    "n_trgs = 8 # number of targets\n",
    "angs = np.linspace(0., 2.*np.pi, n_trgs+1)[:-1]\n",
    "circle = np.array([np.array([np.cos(ang),np.sin(ang)]) for ang in angs])\n",
    "targets = center + r*circle # coordinates of the targets\n",
    "hand_coords = [center, targets[0],\n",
    "               center, targets[1],\n",
    "               center, targets[2],\n",
    "               center, targets[3],\n",
    "               center, targets[4],\n",
    "               center, targets[5],\n",
    "               center, targets[6],\n",
    "               center, targets[7]]\n",
    "\n",
    "hand_coords = 50*hand_coords # many repetitions of the same sequence\n",
    "#hand_coords = 10*[targets[i] for i in np.random.permutation(len(targets))]\n",
    "#### next is a copy-pasta of the code to set the SP values\n",
    "# list with muscle lengths corresponding to the hand coordinates\n",
    "m_lengths = []\n",
    "for coord in hand_coords:\n",
    "    m_lengths.append(arm.coords_to_lengths(coord))\n",
    "m_lengths = np.array(m_lengths)\n",
    "#(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)\n",
    "# We need to translate these lengths to corresponding SF activity levels.\n",
    "# For that it is necessary to recreate all their transformations\n",
    "# The first transformation is from length to Ia, II afferent activity.\n",
    "### OUT OF THE 36 AFFERENT SIGNALS, WE TAKE THE Ia AND II ###\n",
    "par = net.plants[P].m_params\n",
    "# steady state tensions in the static and dynamic bag fibers (no gamma inputs)\n",
    "Ts_ss = (par['k_se_s']/(par['k_se_s']+par['k_pe_s'])) * (\n",
    "         par['k_pe_s']*(m_lengths - par['l0_s']))\n",
    "Td_ss = (par['k_se_d']/(par['k_se_d']+par['k_pe_d'])) * (\n",
    "         par['k_pe_d']*(m_lengths - par['l0_d']))\n",
    "# steady state afferent outputs (no gamma inputs)\n",
    "Ia_ss = par['fs']*(Ts_ss/par['k_se_s']) + (1.-par['fs'])*(Td_ss/par['k_se_d'])\n",
    "II_ss = par['se_II']*(Ts_ss/par['k_se_s']) + ((1.-par['se_II'])/par['k_pe_s'])*Ts_ss\n",
    "Ia_ss *= par['Ia_gain']\n",
    "II_ss *= par['II_gain']\n",
    "Ia_II_ss = np.concatenate((Ia_ss, II_ss), axis=1)\n",
    "# Next transformation is through the afferent units\n",
    "Pe__AF_ws = np.array(Pe__AF_syn['init_w'][6:18])\n",
    "Pi__AF_ws = np.array(Pi__AF_syn['init_w'][6:18])\n",
    "#Ia_II_avgs = np.mean(Ia_II_ss, axis=0)  # when using hundreds of random targets\n",
    "# target averages\n",
    "AFe_thr = np.array([net.units[u].thresh for u in AF[6:18]])\n",
    "AFi_thr = np.array([net.units[u].thresh for u in AF[24:36]])\n",
    "AFe_Ia_II = np.log(1. + np.maximum((Ia_II_ss)*Pe__AF_ws - AFe_thr, 0.))\n",
    "AFi_Ia_II = np.log(1. + np.maximum((Ia_II_ss)*Pi__AF_ws - AFi_thr, 0.))\n",
    "#(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)\n",
    "# Next is from AF to SF\n",
    "SF_arg = AFe__SF_syn['init_w']*AFe_Ia_II + AFi__SF_syn['init_w']*AFi_Ia_II\n",
    "SF_out = 1./ (1. + np.exp(-SF_params['slope']*(SF_arg - SF_params['thresh'])))\n",
    "SF_params['init_val'] = SF_out # this might cause a smooth start\n",
    "# now we set the values in SP\n",
    "\n",
    "#m_idxs = np.random.randint(len(hand_coords), size=1000) # index of all targets\n",
    "m_idxs = list(range(len(hand_coords))) # reach list targets sequentially\n",
    "    \n",
    "AF_us = [net.units[u] for u in AF]\n",
    "\n",
    "def SF_sigmo(idx, arg):\n",
    "    \"\"\" The sigmoidal function for SF unit with index SF[idx]. \"\"\"\n",
    "    return 1./ (1. + np.exp(-SF_params['slope'][idx]*(arg - SF_params['thresh'][idx])))\n",
    "\n",
    "def cur_target(t):\n",
    "    \"\"\" Returns the index of the target at time t. \"\"\"\n",
    "    return m_idxs[int(np.floor(t/t_pres))]\n",
    "\n",
    "def make_fun(idx):\n",
    "    \"\"\" create a function for the SP unit with index 'idx'. \"\"\"\n",
    "    return lambda t: SF_sigmo(idx, \n",
    "                        AFe__SF_syn['init_w'][idx] * (\n",
    "                        np.log(1. + max(Ia_II_ss[cur_target(t-start_t)][idx] * Pe__AF_ws[idx] - \n",
    "                        net.units[AF[6+idx]].thresh, 0.))) +\n",
    "                        AFi__SF_syn['init_w'][idx] * (\n",
    "                        np.log(1. + max(Ia_II_ss[cur_target(t-start_t)][idx] * Pi__AF_ws[idx] - \n",
    "                        net.units[AF[24+idx]].thresh, 0.))))\n",
    "    #return lambda t: SF_out[m_idxs[int(np.floor(t/t_pres))]][idx]\n",
    "\n",
    "for idx, u in enumerate(SP):\n",
    "    net.units[u].set_function(make_fun(idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will obtain mean firing rates corresponding to each of the 8 directions.\n",
    "To do this, from the onset of a reach, until the velocity begins to decrease, a mean rate is obtained for each of the units in M.\n",
    "\n",
    "The protocol is to first run a normal simulation until the arm is doing reaches with oscillations, ~600 seconds. Then new targets are set with the cell above, and the simulation is continued so that every target is attempted twice (which requires 32*t_pres seconds of simulated time). The mean rates are obtained from the second set of reaches.\n",
    "\n",
    "If the initial training simulation lasts 600 seconds, and t_pres=20, the time when the reach to the first target begins (`fr_time` below) is 600 + 16*20 + 20 = 940"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We measure velocities for each reach.\n",
    "# We define the velocity at times[i] to be the norm of the vector from the hand position at \n",
    "# times[i] to the hand position at times[i+idely], divided by (times[i+idely]-times[i]).\n",
    "idely = 20 # a difference of 0.1 seconds if min_delay=0.005\n",
    "# angles of shoulder and elbow\n",
    "theta_s = arm_activs[:,0]\n",
    "theta_e = arm_activs[:,2]\n",
    "phi = theta_s + theta_e # elbow angle wrt x axis\n",
    "# coordinates of hand and elbow\n",
    "l1 = net.plants[P].l_arm\n",
    "l2 = net.plants[P].l_farm\n",
    "xe = np.cos(theta_s)*l1\n",
    "ye = np.sin(theta_s)*l1\n",
    "xh = xe + np.cos(phi)*l2\n",
    "yh = ye + np.sin(phi)*l2\n",
    "# obtaining difference vector\n",
    "dv_x = xh[idely:] - xh[:-idely]\n",
    "dv_y = yh[idely:] - yh[:-idely]\n",
    "diff_vec = np.concatenate((dv_x.reshape(1,dv_x.size), dv_y.reshape(1,dv_y.size)), axis=0)\n",
    "# obtaining the velocity vector\n",
    "vels = np.linalg.norm(diff_vec, axis=0) / (times[idely:]-times[:-idely])\n",
    "vels = np.concatenate((vels, np.zeros(idely))) # so it keeps the same length\n",
    "dv_x = np.concatenate((dv_x, np.zeros(idely)))\n",
    "dv_y = np.concatenate((dv_y, np.zeros(idely)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining mean M activities from reach initiation to peak velocity\n",
    "# Assuming that simulation started with a reach to central position, then \n",
    "# reaches alternated center-target-center-target every t_pres seconds.\n",
    "if 'targets' in locals():\n",
    "    n_trgs = len(targets) # number of targets\n",
    "else:\n",
    "    raise AssertionError('No targets array found!')\n",
    "#---------------------------------------------------------------------------\n",
    "## obtaining peak velocity times (when acceleration first becomes negative)\n",
    "#---------------------------------------------------------------------------\n",
    "vels_diff = vels[idely:] - vels[:-idely]\n",
    "vels_diff = np.concatenate((np.zeros(idely), vels_diff)) # so it keeps the same length\n",
    "# segmenting the vectors into reaches to individual peripheral targets\n",
    "pr_len = int(np.round(t_pres/net.min_delay)) # number of vector entries per presentation\n",
    "vels_pr = [vels[(2*trg+1)*pr_len:2*(trg+1)*pr_len] for trg in range(n_trgs)] # vels per reach\n",
    "vels_diff_pr = [vels_diff[(2*trg+1)*pr_len:2*(trg+1)*pr_len] for trg in range(n_trgs)] # ditto\n",
    "# for each target find index of first negative acceleration\n",
    "first_neg_pr = [pr_len for _ in range(n_trgs)] # index of first negative accel per target\n",
    "for trg in range(n_trgs):\n",
    "    for idx in range(idely, pr_len):\n",
    "        if vels_diff_pr[trg][idx] < 0:\n",
    "            first_neg_pr[trg] = idx\n",
    "            break\n",
    "#---------------------------------------------------------------------------\n",
    "# segmenting M activities per target\n",
    "M_data_pr = [M_data[:,(2*trg+1)*pr_len:2*(trg+1)*pr_len] for trg in range(n_trgs)]\n",
    "# obtaining means\n",
    "# M_means_pr[i][j]: mean rate of the j-th unit in M when starting to reach\n",
    "# towards the i-th target\n",
    "M_means_pr = []\n",
    "for trg in range(n_trgs):\n",
    "    M_means_pr.append(np.mean(M_data_pr[trg][:,:first_neg_pr[trg]], axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the preferred directions of units in M through planar regression\n",
    "\n",
    "# The M mean rates are fit using a plane, and the preferred angle is the angle\n",
    "# of the projection of this plane's normal vector onto the XY plane.\n",
    "# The coefficients of the normal vector come from a 3x3 linear system,\n",
    "# whose coefficients are calculated next.\n",
    "#trgs = targets # original targets\n",
    "trgs = targets - center #circle # targets centered at the origin\n",
    "X = trgs[:,0].sum()\n",
    "Y = trgs[:,1].sum()\n",
    "XY = (trgs[:,0]*trgs[:,1]).sum()\n",
    "X2 = (trgs[:,0]*trgs[:,0]).sum()\n",
    "Y2 = (trgs[:,1]*trgs[:,1]).sum()\n",
    "m = n_trgs\n",
    "A = np.array([[X2, XY, X], [XY, Y2, Y], [X, Y, m]])\n",
    "detA = np.linalg.det(A) # determinant of A\n",
    "if detA == 0.:\n",
    "    raise ValueError('Indeterminate system found!')\n",
    "invA = np.linalg.inv(A)\n",
    "# The RHS of the system depends on the M unit's rates\n",
    "prf_angs = np.zeros(len(M)) # preferred angles, in radians\n",
    "normal_vecs = [] # list with the vectors normal to the plane fitting the rates\n",
    "for idx in range(len(M)): # for each M unit...\n",
    "    M_means = np.array([M_means_pr[trg][idx] for trg in range(n_trgs)]) # means for this unit   \n",
    "    Rx = (trgs[:,0]*M_means).sum()\n",
    "    Ry = (trgs[:,1]*M_means).sum()\n",
    "    R = M_means.sum()\n",
    "    n = np.matmul(invA, np.array([Rx, Ry, R])) # the normal vector\n",
    "    normal_vecs.append(n/np.linalg.norm(n)) # appending normalized vector\n",
    "    prf_angs[idx] = np.arctan2(n[1], n[0]) # preferred angle\n",
    "    # obtaining residuals, coefficient of determination, R^2\n",
    "    residuals = [M_means[trg]-(n[0]*trgs[trg,0]+n[1]*trgs[trg,1]+n[2]) for trg in range(n_trgs)]\n",
    "    avg_mean = R/M_means.size\n",
    "    devs = [M_means[trg]-avg_mean for trg in range(n_trgs)]\n",
    "    SSr = sum([r*r for r in residuals])\n",
    "    SSt = sum([d*d for d in devs])\n",
    "    R = 1. - (SSr/SSt)\n",
    "    print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of preferred directions for the 12 cells\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.plot(prf_angs, np.ones(len(prf_angs)), '*')\n",
    "ax.set_rmax(1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each reach, decode the direction of movement from the M rates\n",
    "\n",
    "# pred_v[0][i] # x component of predicted velocity at time with index t\n",
    "# pred_v[1][i] # y component of predicted velocity at time with index t\n",
    "pred_v = np.zeros((2,len(times)))\n",
    "for idx in range(len(M)):\n",
    "    pred_v[0,:] += normal_vecs[idx][0]*M_data[idx,:]\n",
    "    pred_v[1,:] += normal_vecs[idx][1]*M_data[idx,:]\n",
    "\n",
    "# Obtain the average angle between the predicted and actual velocity\n",
    "norm_pred_v = pred_v[:,:-idely] # so it has the same length as diff_vec\n",
    "norm_pred_v = norm_pred_v / np.linalg.norm(norm_pred_v, axis=0) # normalizing\n",
    "norm_diff_vec = diff_vec / np.linalg.norm(diff_vec, axis=0)\n",
    "dots = (norm_pred_v * norm_diff_vec).sum(axis=0)  # dot products for all vectors\n",
    "vel_angs = np.arccos(dots)\n",
    "mean_dot = np.mean(dots)\n",
    "mean_vel_ang = np.arccos(mean_dot)\n",
    "print(mean_vel_ang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining \"velocity tuning\" based on correlations between M rates and directions\n",
    "\n",
    "# Assuming the cell starting with \"We measure velocities for each reach.\" has been executed,\n",
    "# so the dv_x and dv_y vectors are already present.\n",
    "\n",
    "# First we obtain the velocity angle at each simulation step\n",
    "vel_angs = np.arctan2(dv_y, dv_x)\n",
    "# Transforming the range of the angles from [-pi,pi] to [0,2pi]\n",
    "vel_angs = np.mod(vel_angs+2.*np.pi, 2.*np.pi)\n",
    "\n",
    "# Now we specify in which velocity \"bin\" each velocity belongs\n",
    "n_bins = 16 # number of directions\n",
    "ang_bit = 2.*np.pi/n_bins\n",
    "vel_bins = np.floor_divide(vel_angs, ang_bit)\n",
    "\n",
    "# For each direction, count the number of times the hand was following it\n",
    "# dir_count = np.zeros(n_bins)\n",
    "# for idx in range(n_bins):\n",
    "#     dir_count[idx] = np.sum(vel_bins == idx)\n",
    "dir_count2, edges = np.histogram(vel_angs, bins=n_bins)\n",
    "\n",
    "# Next, for each angle bin we create an array with all the M activities when the velocity\n",
    "# was in the corresponding angle.\n",
    "bin_arrays = []\n",
    "for ang_bin in range(n_bins):\n",
    "    bin_arrays.append(M_data[:,ang_bin==vel_bins])\n",
    "\n",
    "# Finally, we obtain the mean rate of M units for each angle bin\n",
    "# bin_M_means[i][j]: mean rate of j-th M unit when hand moving in direction of bin i\n",
    "bin_M_means = []\n",
    "for ang_bin in range(n_bins):\n",
    "    if bin_arrays[ang_bin].size > 0:\n",
    "        bin_M_means.append(np.mean(bin_arrays[ang_bin], axis=1))\n",
    "    else:\n",
    "        bin_M_means.append(np.zeros(len(M)))\n",
    "            \n",
    "# print histogram for frequency of movement directions\n",
    "# Using hist. Could compare with dir_count\n",
    "plt.figure()\n",
    "#plt.hist(vel_angs, bins=n_bins, range=(0.,1.*np.pi))\n",
    "plt.hist(edges[:-1], edges, weights=dir_count2)\n",
    "\n",
    "fig2 = plt.figure()\n",
    "hist_axs2 = plt.subplot()\n",
    "hist_axs2.axis('equal')\n",
    "x_coords = np.cos(edges[:-1]) # x-coordinates of each unit velocity vector\n",
    "y_coords = np.sin(edges[:-1]) # y-coordinates of each unit velocity vector\n",
    "norm_dc = dir_count2/np.linalg.norm(dir_count2)\n",
    "for trg in range(n_bins):\n",
    "    hist_axs2.plot([0., norm_dc[trg]*x_coords[trg]], [0., norm_dc[trg]*y_coords[trg]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preferred directions through planar regression using all velocities\n",
    "\n",
    "# The M mean rates are fit using a plane, and the preferred angle is the angle\n",
    "# of the projection of this plane's normal vector onto the XY plane.\n",
    "# The coefficients of the normal vector come from a 3x3 linear system,\n",
    "# whose coefficients are calculated next.\n",
    "angs = np.linspace(0., 2.*np.pi, n_bins, endpoint=False)\n",
    "trgs = np.array([np.array([np.cos(ang),np.sin(ang)]) for ang in angs])\n",
    "X = trgs[:,0].sum()\n",
    "Y = trgs[:,1].sum()\n",
    "XY = (trgs[:,0]*trgs[:,1]).sum()\n",
    "X2 = (trgs[:,0]*trgs[:,0]).sum()\n",
    "Y2 = (trgs[:,1]*trgs[:,1]).sum()\n",
    "m = n_bins\n",
    "A = np.array([[X2, XY, X], [XY, Y2, Y], [X, Y, m]])\n",
    "detA = np.linalg.det(A) # determinant of A\n",
    "if detA == 0.:\n",
    "    raise ValueError('Indeterminate system found!')\n",
    "invA = np.linalg.inv(A)\n",
    "# The RHS of the system depends on the M unit's rates\n",
    "prf_angs3 = np.zeros(len(M)) # preferred angles, in radians\n",
    "normal_vecs3 = [] # list with the vectors normal to the plane fitting the rates\n",
    "for idx in range(len(M)): # for each M unit...\n",
    "    M_means = np.array([bin_M_means[trg][idx] for trg in range(n_bins)]) # means for this unit   \n",
    "    Rx = (trgs[:,0]*M_means).sum()\n",
    "    Ry = (trgs[:,1]*M_means).sum()\n",
    "    R = M_means.sum()\n",
    "    n = np.matmul(invA, np.array([Rx, Ry, R])) # the normal vector\n",
    "    normal_vecs3.append(n/np.linalg.norm(n)) # appending normalized vector\n",
    "    prf_angs3[idx] = np.arctan2(n[1], n[0]) # preferred angle\n",
    "    # obtaining residuals, coefficient of determination, R^2\n",
    "    residuals3 = [M_means[trg]-(n[0]*trgs[trg,0]+n[1]*trgs[trg,1]+n[2]) for trg in range(n_bins)]\n",
    "    avg_mean3 = R/M_means.size\n",
    "    devs3 = [M_means[trg]-avg_mean for trg in range(n_bins)]\n",
    "    SSr = sum([r*r for r in residuals3])\n",
    "    SSt = sum([d*d for d in devs3])\n",
    "    R = 1. - (SSr/SSt)\n",
    "    print(R)\n",
    "    \n",
    "# plot of preferred directions for the 12 cells\n",
    "fig_pf3, ax_pf3 = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax_pf3.plot(prf_angs3, np.ones(len(prf_angs3)), '*')\n",
    "ax_pf3.set_rmax(1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot alternate velocity vector for all M units\n",
    "\n",
    "# For each velocity angle, get Cartesian coordiantes of its unit vector\n",
    "angles = np.linspace(0., 2.*np.pi, n_bins+1)[:-1]\n",
    "x_coords = np.cos(angles) # x-coordinates of each unit velocity vector\n",
    "y_coords = np.sin(angles) # y-coordinates of each unit velocity vector\n",
    "\n",
    "# M_coords[i][j][k]: coordinates (j=0, x coordinate; j=1, y coordinate) of\n",
    "# the i-th unit velocity vector scaled by the mean firing rate of the\n",
    "# k-th M unit when the hand is moving in the direction of that i-th vector\n",
    "M_coords = [[bin_M_means[i]*x_coords[i],bin_M_means[i]*y_coords[i]]\n",
    "            for i in range(n_bins)]\n",
    "\n",
    "# avg_vels[i][j]: for the i-th M unit the x (if j=0) or y (if j=1)\n",
    "# coordinate of its preferred velocity vector, arising from an average\n",
    "# of M_coords[:][j][i]\n",
    "avg_vels = np.zeros((len(M), 2))\n",
    "for idx in range(len(M)):\n",
    "    avg_vels[idx,0] = sum([M_coords[d][0][idx] for d in range(n_bins)])/n_bins\n",
    "    avg_vels[idx,1] = sum([M_coords[d][1][idx] for d in range(n_bins)])/n_bins\n",
    "\n",
    "vel_fig, vel_axs = plt.subplots(3, 4, figsize=(fs[0], 3.3*fs[1]))\n",
    "\n",
    "for row in range(3):\n",
    "    for col in range(4):\n",
    "        ax = vel_axs[row][col]\n",
    "        m_id = 4*row + col\n",
    "        max_x = max([M_coords[i][0][m_id] for i in range(n_bins)])\n",
    "        min_x = min([M_coords[i][0][m_id] for i in range(n_bins)])\n",
    "        max_y = max([M_coords[i][1][m_id] for i in range(n_bins)])\n",
    "        min_y = min([M_coords[i][1][m_id] for i in range(n_bins)])\n",
    "        ax.set_xlim([1.2*min_x, 1.2*max_x])\n",
    "        ax.set_ylim([1.2*min_y, 1.2*max_y])\n",
    "        ax.grid()\n",
    "        ax.set_title(\"M = %d\"%(m_id))\n",
    "        for trg in range(n_bins):\n",
    "            ax.plot([M_coords[trg][0][m_id]], [M_coords[trg][1][m_id]], '*')\n",
    "            ax.plot([0., M_coords[trg][0][m_id]], [0., M_coords[trg][1][m_id]], 'b', linewidth=3)\n",
    "        ax.plot([0., avg_vels[m_id][0]], [0., avg_vels[m_id][1]], 'r-o', linewidth=5)\n",
    "        avg_norm = np.linalg.norm(avg_vels[m_id][:3])\n",
    "        ax.plot([0., avg_norm*normal_vecs3[m_id][0]], \n",
    "                [0., avg_norm*normal_vecs3[m_id][1]], 'g-o', linewidth=5)\n",
    "        \n",
    "# Plot the prefered directions only\n",
    "prf_angs2 = np.arctan2(avg_vels[:,1], avg_vels[:,0])\n",
    "prf_dir2_fig, prf_dir2_ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "prf_dir2_ax.plot(prf_angs2, np.ones(len(prf_angs2)), '*')\n",
    "prf_dir2_ax.set_rmax(1.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once more, predict velocities\n",
    "# pred_v2[i][j]: x (if i=0) or y (if i=1) component of predicted\n",
    "# velocity at time index 'j'\n",
    "pred_v2 = np.zeros((2,len(times)))\n",
    "for idx in range(len(M)):\n",
    "    pred_v2[0,:] += avg_vels[idx][0]*M_data[idx,:]\n",
    "    pred_v2[1,:] += avg_vels[idx][1]*M_data[idx,:]\n",
    "\n",
    "# Obtain the average angle between the predicted and actual velocity\n",
    "norm_pred_v2 = pred_v2[:,:-idely] # so it has the same length as diff_vec\n",
    "norm_pred_v2 = norm_pred_v2 / np.linalg.norm(norm_pred_v2, axis=0) # normalizing\n",
    "norm_diff_vec = diff_vec / np.linalg.norm(diff_vec, axis=0)\n",
    "dots2 = (norm_pred_v2 * norm_diff_vec).sum(axis=0)  # dot products for all vectors\n",
    "vel_angs2 = np.arccos(dots2)\n",
    "mean_dot2 = np.mean(dots2)\n",
    "mean_vel_ang2 = np.arccos(mean_dot2)\n",
    "print(mean_vel_ang2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to interpret the plots below\n",
    "**For the first two plot grids**:  \n",
    "The value at `t=0` is the that comes from using the current `custom_inp_del(2)` values in the rga_diff rule.\n",
    "Negative `t` values correspond to delay in the M signal, which is what makes most sense in the physical implementation. The value at `t=-x` can be interpreted as the direction of change that the rga_diff learning rule would imply if both `custom_inp_del` and `custom_inp_del2` were increased by `x` time units.\n",
    "\n",
    "\n",
    "**For the third plot grid**:  \n",
    "The value at `t=0` is the value of the M-C correlation when C is delayed by `custom_inp_del2`. Values to the left imply increasing the delay in C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS OF CORRELATIONS BETWEEN MOTOR UNITS AND C UNITS\n",
    "# Modified for the rga_diff rule\n",
    "\n",
    "# obtaining M,C unit activities and their derivatives\n",
    "full_size = len(data[M[0]])\n",
    "D_size = 100000 # number of points we will take from the data signals\n",
    "corr_size = 1000 # number of points in the correlation vector\n",
    "MD = data[M, -D_size:].transpose() # take the data from the latest points\n",
    "w_l = 31 # window length for smoothing\n",
    "for idx in range(len(M)): # smoothing MD\n",
    "    MD[:,idx] = smooth(MD[:,idx], window_len=w_l)[int(np.floor(w_l/2)):-int(np.floor(w_l/2))]\n",
    "MD_diff = np.gradient(MD, axis=0) / net.min_delay\n",
    "MD_diff_roll = np.roll(MD_diff, -CE_params['custom_inp_del']+CE_params['custom_inp_del2'], axis=0) # advancing MD_diff\n",
    "# Obtaining means over 2 seconds\n",
    "mean_win = int(2./net_params['min_delay']) # number of points in the window to extract the means\n",
    "MD_diff_means = np.zeros_like(MD_diff)\n",
    "MD_diff_roll_means = np.zeros_like(MD_diff_roll)\n",
    "for idx in range(mean_win,len(MD_diff[:,0])-1):\n",
    "        MD_diff_means[idx,:] = np.sum(MD_diff_roll[idx-mean_win:idx,:], axis=0)/mean_win\n",
    "        MD_diff_roll_means[idx,:] = np.sum(MD_diff_roll[idx-mean_win:idx,:], axis=0)/mean_win\n",
    "MD_diff_center = MD_diff_means - MD_diff # The NEGATIVE of the centered derivative\n",
    "MD_diff_roll_center = MD_diff_roll - MD_diff_roll_means\n",
    "MD_diff_center_red = MD_diff_center[:-corr_size,:]\n",
    "MD_diff_roll_center_red = MD_diff_roll_center[:-corr_size,:] # when it's second in np.correlate\n",
    "\n",
    "CD = data[CE+CI, -D_size:].transpose()\n",
    "CD_diff = np.gradient(CD, axis=0) / net.min_delay\n",
    "CD_diff_roll = np.roll(CD_diff, CE_params['custom_inp_del2'], axis=0)\n",
    "CD_diff_roll_means = np.zeros_like(CD_diff_roll)\n",
    "for idx in range(6):\n",
    "    CD_diff_roll_means[:, idx] = np.mean(np.delete(CD_diff_roll[:,0:6], idx, axis=1), axis=1)\n",
    "for idx in range(6,12):\n",
    "    CD_diff_roll_means[:, idx] = np.mean(np.delete(CD_diff_roll[:,6:12], idx-6, axis=1), axis=1)\n",
    "CD_diff_roll_center = CD_diff_roll - CD_diff_roll_means\n",
    "#CD_diff_roll_center_red = CD_diff_roll_center[:-corr_size,:]\n",
    "hlf_cspan = int(round(corr_size/2.))\n",
    "CD_diff_roll_center_red = CD_diff_roll_center[hlf_cspan:-hlf_cspan,:]\n",
    "\n",
    "# plots for the signals used in this the analysis\n",
    "plt_len=4000  # number of points to plot\n",
    "fig, axs = plt.subplots(3, 1, figsize=(30, 28))\n",
    "axs[0].plot(MD[0:plt_len,0])\n",
    "axs[0].set_title('motor unit activities')\n",
    "\n",
    "axs[1].plot(MD_diff_center[0:plt_len,0])\n",
    "axs[1].plot(MD_diff_roll_center[0:plt_len,0])\n",
    "axs[1].plot(np.zeros(plt_len), 'k')\n",
    "axs[1].set_title('centered derivatives for motor unit activities')\n",
    "#axs[1].plot(np.zeros(MD_diff_center.shape[0]), 'k')\n",
    "axs[1].set_ylim([-.1, .1])\n",
    "\n",
    "axs[2].plot(CD_diff_roll_center[0:plt_len,0])\n",
    "axs[2].plot(np.zeros(plt_len), 'k')\n",
    "#axs[2].set_ylim([-2., 2.])\n",
    "axs[2].set_title('centered derivatives for C units')\n",
    "#axs[2].plot(np.zeros(CD_diff_center.shape[0]), 'k')\n",
    "\n",
    "# plotting the expected weights for pairs of M and CE/CI signals\n",
    "M__CE_w = [[syn.w for syn in net.syns[c] if syn.preID in M] for c in CE]\n",
    "corr_figE, corr_axsE = plt.subplots(12, 6, figsize=(40,50))\n",
    "\n",
    "M__CI_w = [[syn.w for syn in net.syns[c] if syn.preID in M] for c in CI]\n",
    "corr_figI, corr_axsI = plt.subplots(12, 6, figsize=(40,50))\n",
    "\n",
    "# plotting the differential correlations for pairs of M and CE/CI signals\n",
    "corr_figX, corr_axsX = plt.subplots(6, 6, figsize=(40,20))\n",
    "\n",
    "base_idx = 0 # index for positive Ia afferent for muscle 0\n",
    "plt_span = min(300, corr_size)   # span to plot for the correlation\n",
    "#t = np.linspace(-plt_span*net.min_delay, plt_span*net.min_delay, 2*plt_span)\n",
    "                \n",
    "hlf_pspn = int(round(plt_span/2.))\n",
    "t = np.linspace(-hlf_pspn*net.min_delay, hlf_pspn*net.min_delay, plt_span)\n",
    "#pos_t = np.linspace(0., plt_span*net.min_delay, plt_span)\n",
    "#neg_t = np.linspace(-(plt_span+1)*net.min_delay, -net.min_delay, plt_span)\n",
    "#all_t = np.concatenate((neg_t,pos_t))\n",
    "eqs = np.zeros((12,12)) # matrix indicating whether weight and correlation have same sign\n",
    "corr_w = np.zeros((12,12)) # what the weight should be, according to the correlation\n",
    "des_val_idx = hlf_cspan # index in the correlation vector where the weight should be...\n",
    "                        # depends on CD_diff_diff_roll_center_red was reduced\n",
    "\n",
    "for col in range(12):  # ranges through C units\n",
    "    if col < 6:\n",
    "        axes = corr_axsE\n",
    "        weights = M__CE_w\n",
    "        color='b'\n",
    "    else:\n",
    "        axes = corr_axsI\n",
    "        weights = M__CI_w\n",
    "        color='r'\n",
    "    mcol = col%6\n",
    "    for row in range(12):  # ranges through M units\n",
    "        cur_idx = 12*mcol+row\n",
    "        if cur_idx == base_idx: lw = 4\n",
    "        else: lw = 1\n",
    "        # This corresponds to what should be learned with two different single delays\n",
    "        # In 'corr' MD is not delayed, and CD is delayed by dely2 (CE_params[custom_inp_del2])\n",
    "        corr = np.correlate(MD_diff_center[:,row], CD_diff_roll_center_red[:,col], mode='valid')\n",
    "        #corr = np.correlate(CD_diff_roll_center[:,col], MD_diff_center[:,row], mode='valid')\n",
    "        # In corr MD is additionally delayed by dely2-dely1\n",
    "        corr2 = np.correlate(MD_diff_roll_center[:,row], CD_diff_roll_center_red[:,col], mode='valid')\n",
    "        # this corresponds to what should be learned using the \"diff\" learning rule\n",
    "        corr_diff = corr - corr2\n",
    "        \n",
    "        # plot value of rga_diff learning rule\n",
    "        axes[row,mcol].plot(t, corr_diff[hlf_cspan-hlf_pspn:hlf_cspan+hlf_pspn], linewidth=lw, color=color)\n",
    "        \n",
    "        corr_w[row,col] = corr_diff[des_val_idx]\n",
    "        acw = abs(corr_w[row,col])\n",
    "        t_des = t[hlf_pspn]\n",
    "        axes[row,mcol].plot(t, max(min(10.*weights[mcol][row],acw),-acw)*np.ones(len(t)), linewidth=3)\n",
    "        axes[row,mcol].plot(t, corr_diff[des_val_idx]*np.ones(len(t)), 'g--', linewidth=1)\n",
    "        axes[row,mcol].plot([t_des, t_des], [-corr_w[row,col], corr_w[row,col]], 'g--', linewidth=1)\n",
    "        axes[row,mcol].plot(t, np.zeros(len(t)), 'k--', linewidth=1)\n",
    "        axes[row,mcol].set_title('M' + str(row) + ', C' + str(col))\n",
    "        \n",
    "        if col<6 and row<6:  # plot differential correlation\n",
    "            # Legacy code:\n",
    "            #---------------------------------------\n",
    "            # These are further values of corr when CD rather than MD is further delayed\n",
    "            # Because the first array is shorter, the arguments will be reversed (see np.convolve documentation);\n",
    "            # however, the sign of the indexes is not inverted. This means:\n",
    "            # correlate(MD_diff_center_red,CD_diff_roll_center) == correlate(CD_diff_roll_center,MD_diff_center_red)[::-1]\n",
    "            #rev_corr = np.correlate(MD_diff_center_red[:,row], CD_diff_roll_center[:,col], mode='valid')\n",
    "            #corr_axsX[row,col].plot(all_t, np.concatenate((rev_corr[-plt_span:],corr[0:plt_span])), linewidth=3, color='b')\n",
    "            #---------------------------------------\n",
    "            corr_axsX[row,col].plot(t, corr[hlf_cspan-hlf_pspn:hlf_cspan+hlf_pspn], linewidth=3, color='b')\n",
    "            corr_axsX[row,mcol].set_title('M' + str(row) + ', C' + str(col))\n",
    "            corr_axsX[row,mcol].plot(t, np.zeros(len(t)), 'k--', linewidth=1)\n",
    "            c0 = abs(corr[des_val_idx])\n",
    "            corr_axsX[row,mcol].plot([t_des, t_des], [-c0, c0], 'g--', linewidth=1)\n",
    "        \n",
    "        # Finding if weights are following the correlations\n",
    "        scat_s = 50\n",
    "        scat_c = 'r'\n",
    "        if np.sign(weights[mcol][row]) == np.sign(corr_diff[des_val_idx]):\n",
    "            eqs[row,col] = 1.\n",
    "            scat_s = 90\n",
    "            scat_c = 'g'\n",
    "        axes[row,mcol].scatter([t_des], [corr_diff[des_val_idx]], s=scat_s, c=scat_c)\n",
    "plt.show()\n",
    "\n",
    "# Regarding whether correlations and weights have the same sign\n",
    "print(eqs)\n",
    "print(np.sum(eqs, axis=0))\n",
    "print(np.sum(eqs, axis=1))\n",
    "print(sum(eqs.flatten())/(eqs.shape[0]*eqs.shape[1]))\n",
    "# Regarding desired weights according to correlations\n",
    "# normalizing columns of corr_w (weights on the same C unit)\n",
    "n_corr_w = corr_w / np.linalg.norm(corr_w, axis=0)\n",
    "import re\n",
    "print('normalized M__CE correlation weight matrix:')\n",
    "print(re.sub('\\[,', '[', re.sub('\\ +', ', ', str(n_corr_w[:,:6]))))\n",
    "print('normalized M__CI correlation weight matrix:')\n",
    "print(re.sub('\\[,', '[', re.sub('\\ +', ', ', str(n_corr_w[:,6:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking some connections\n",
    "print(\"Connections to motor units\")\n",
    "for idx, syn in enumerate(net.syns[M[0]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_type is plant_models.planar_arm_v3:\n",
    "        pre_pop = 'P'\n",
    "    elif pre_id in AF:\n",
    "        pre_pop = 'AF'\n",
    "    elif pre_id in SPF:\n",
    "        pre_pop = 'SPF'\n",
    "    else:\n",
    "        pre_pop = 'erroneous'\n",
    "    if pre_pop == 'P':\n",
    "        plant_out = str(syn.plant_out)\n",
    "    else:\n",
    "        plant_out = 'None'\n",
    "    print('%d) %s (%d) --> M, w=%f, port=%d, plant_out=%s'%(idx, pre_pop, pre_id, syn.w, syn.port, plant_out))\n",
    "print(\"-------------------------\\n\")\n",
    "    \n",
    "print(\"Connections to afferent units\")\n",
    "for idx, syn in enumerate(net.syns[AF[0]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_type is plant_models.planar_arm_v3:\n",
    "        pre_pop = 'P'\n",
    "    elif pre_id in AF:\n",
    "        pre_pop = 'A'\n",
    "    elif pre_id in SPF:\n",
    "        pre_pop = 'SPF'\n",
    "    else:\n",
    "        pre_pop = 'other'\n",
    "    if pre_pop == 'P':\n",
    "        plant_out = str(syn.plant_out)\n",
    "    else:\n",
    "        plant_out = 'None'\n",
    "    print('%d) %s (%d) --> A, w=%f, port=%d, plant_out=%s'%(idx, pre_pop, pre_id, syn.w, syn.port, plant_out))\n",
    "print(\"-------------------------\\n\")\n",
    "    \n",
    "print(\"Connections to spinal units\")\n",
    "for idx, syn in enumerate(net.syns[CE[0]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_type is plant_models.planar_arm_v3:\n",
    "        pre_pop = 'P'\n",
    "    elif pre_id in AF:\n",
    "        pre_pop = 'AF'\n",
    "    elif pre_id in SPF:\n",
    "        pre_pop = 'SPF'\n",
    "    elif pre_id in M:\n",
    "        pre_pop = 'M'\n",
    "    elif pre_id in CE:\n",
    "        pre_pop = 'CE'\n",
    "    elif pre_id in CI:\n",
    "        pre_pop = 'CI'\n",
    "    else:\n",
    "        pre_pop = 'other'\n",
    "    if pre_pop == 'P':\n",
    "        plant_out = str(syn.plant_out)\n",
    "    else:\n",
    "        plant_out = 'None'\n",
    "    print('%d) %s (%d) --> CE, w=%f, port=%d, plant_out=%s'%(idx, pre_pop, pre_id, syn.w, syn.port, plant_out))\n",
    "print(\"-------------------------\\n\")\n",
    "\n",
    "for idx, syn in enumerate(net.syns[CI[0]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_type is plant_models.planar_arm_v3:\n",
    "        pre_pop = 'P'\n",
    "    elif pre_id in AF:\n",
    "        pre_pop = 'AF'\n",
    "    elif pre_id in SPF:\n",
    "        pre_pop = 'SPF'\n",
    "    elif pre_id in M:\n",
    "        pre_pop = 'M'\n",
    "    elif pre_id in CE:\n",
    "        pre_pop = 'CE'\n",
    "    elif pre_id in CI:\n",
    "        pre_pop = 'CI'\n",
    "    else:\n",
    "        pre_pop = 'other'\n",
    "    if pre_pop == 'P':\n",
    "        plant_out = str(syn.plant_out)\n",
    "    else:\n",
    "        plant_out = 'None'\n",
    "    print('%d) %s (%d) --> CI, w=%f, port=%d, plant_out=%s'%(idx, pre_pop, pre_id, syn.w, syn.port, plant_out))\n",
    "print(\"-------------------------\\n\")\n",
    "\n",
    "\n",
    "print(\"Connections to plant\")\n",
    "for idx, syn in enumerate(net.plants[P].inp_syns[0]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_id in AL:\n",
    "        pre_pop = 'AL'\n",
    "    else:\n",
    "        pre_pop = 'erroneous'\n",
    "    print('%d) %s (%d, %s) --> P, w=%f'%(idx, pre_pop, pre_id, pre_type, syn.w))\n",
    "print(\"-------------------------\\n\")\n",
    "\n",
    "print(\"Connections to SF units\")\n",
    "for idx, syn in enumerate(net.syns[SF[0]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_id == P:\n",
    "        pre_pop = 'P'\n",
    "    elif pre_id in AF:\n",
    "        pre_pop = 'AF'\n",
    "    elif pre_id in SPF:\n",
    "        pre_pop = 'SPF'\n",
    "    elif pre_id in M:\n",
    "        pre_pop = 'M'\n",
    "    else:\n",
    "        pre_pop = 'erroneous'\n",
    "    if pre_pop == 'P':\n",
    "        plant_out = str(syn.plant_out)\n",
    "    else:\n",
    "        plant_out = 'None'\n",
    "    print('%d) %s (%d) --> SF, w=%f, port=%d, plant_out=%s'%(idx, pre_pop, pre_id, syn.w, syn.port, plant_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for animation\n",
    "from numpy import cos, sin\n",
    "if not 'targets' in locals():\n",
    "    targets = np.array([[0.3, 0.3]])\n",
    "start_time = 0.\n",
    "start_idx = int(start_time/net.min_delay)\n",
    "fdelay = 4000 # number of frames to plot for hand trajectory\n",
    "# angles of shoulder and elbow\n",
    "theta_s = arm_activs[start_idx:,0]\n",
    "theta_e = arm_activs[start_idx:,2]\n",
    "phi = theta_s + theta_e # elbow angle wrt x axis\n",
    "# data from tracking units\n",
    "#acts = np.array(data[1])\n",
    "ipx = data[ipx_track,start_idx:]\n",
    "ipy = data[ipy_track,start_idx:]\n",
    "ten = arm_activs[start_idx:, np.array(range(4,10))].transpose()\n",
    "# coordinates of hand and elbow\n",
    "l1 = net.plants[P].l_arm\n",
    "l2 = net.plants[P].l_farm\n",
    "xe = cos(theta_s)*l1\n",
    "ye = sin(theta_s)*l1\n",
    "xh = xe + cos(phi)*l2\n",
    "yh = ye + sin(phi)*l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reach trajectories from center to targets\n",
    "reach_fig = plt.figure(figsize=(10,10))\n",
    "reach_ax = plt.gca()\n",
    "trial = 0\n",
    "reach_ax.scatter(targets[:,0], targets[:,1], s=300, c='cyan')\n",
    "reach_ax.scatter(center[0], center[1], s=1000, c='blue')\n",
    "plt.axis('equal')\n",
    "reach_ax.grid()\n",
    "t_pres_idx = int(round(t_pres/net.min_delay))\n",
    "for trg in range(n_trgs):\n",
    "    base_idx  = t_pres_idx *(1 + trial*16 + 2*trg)\n",
    "    reach_ax.plot(xh[base_idx:base_idx+t_pres_idx], yh[base_idx:base_idx+t_pres_idx],\n",
    "                  linewidth=3)\n",
    "#from IPython.display import Image\n",
    "#Image(filename='temp_fig')\n",
    "#plt.savefig('temp_fig2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Animation of the arm and muscles\n",
    "%matplotlib widget\n",
    "from matplotlib.animation import FuncAnimation\n",
    "# creating the figure and axis\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis('equal')\n",
    "ax = plt.gca()\n",
    "lim = l1 + l2\n",
    "ax.set_xlim([-.2, lim])\n",
    "ax.set_ylim([-.2, lim])\n",
    "ax.grid()\n",
    "ax.scatter(targets[:,0], targets[:,1], s=150, c='cyan')\n",
    "# creating lines and points\n",
    "line, = ax.plot([], [], 'o-k', lw=2)\n",
    "points, = ax.plot([], [], '+k')\n",
    "target, = ax.plot([], [], 'gD')\n",
    "traj, = ax.plot([], [], 'tab:gray', lw=1)\n",
    "pred_vel, = ax.plot([], [], 'r-o')\n",
    "ax.scatter([0.3], [0.3], s=200, c='cyan')\n",
    "# preparing a colormap for the tensions\n",
    "ten_max = np.mean(np.max(ten, axis=1))\n",
    "ten_min = np.mean(np.min(ten, axis=1))\n",
    "for row_idx, row in enumerate(ten):\n",
    "    for ent_idx, entry in enumerate(row):\n",
    "        if entry > 0:\n",
    "            ten[row_idx, ent_idx] = entry/ten_max\n",
    "        else:\n",
    "            ten[row_idx, ent_idx] = entry/abs(ten_min)\n",
    "#ten = (ten / 2.) + 0.5 # we'll have only positive tensions\n",
    "mus_lines = []\n",
    "#cmap=plt.get_cmap('Reds')\n",
    "#cmap=plt.get_cmap('coolwarm')\n",
    "cmap=plt.get_cmap('bwr')\n",
    "for i in range(6):\n",
    "    mus_lines.append(ax.plot([], [], color=cmap(0.5))[0])\n",
    "# stuff used to plot the target\n",
    "#strt_idx = int(np.round(times[0]/t_pres)) # initial index in m_idxs\n",
    "strt_idx = int(np.round((times[0]+start_time)/t_pres)) # initial index in m_idxs\n",
    "\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    points.set_data([], [])\n",
    "    traj.set_data([], [])\n",
    "    pred_vel.set_data([], [])\n",
    "    for i in range(6):\n",
    "        mus_lines = []\n",
    "        mus_lines.append(ax.plot([], [], color=cmap(0.5))[0])\n",
    "    return line, points, mus_lines\n",
    "\n",
    "def update(frame):\n",
    "    coord_x = [0, xe[frame], xh[frame]]\n",
    "    coord_y = [0, ye[frame], yh[frame]]\n",
    "    ip_x = ipx[:,frame]\n",
    "    ip_y = ipy[:,frame]\n",
    "    tens = ten[:, frame]\n",
    "    line.set_data(coord_x, coord_y)\n",
    "    points.set_data(ip_x, ip_y)\n",
    "    #traj.set_data(xh[0:frame], yh[0:frame])\n",
    "    #traj.set_data(xh[frame-max(0,frame-fdelay):frame], yh[frame-max(0,frame-fdelay):frame])\n",
    "    if frame > fdelay:\n",
    "        traj.set_data(xh[frame-fdelay:frame], yh[frame-fdelay:frame])\n",
    "    for i, ml in enumerate(mus_lines):\n",
    "        idx = 2*i\n",
    "        ml.set_data(ip_x[idx:idx+2], ip_y[idx:idx+2])\n",
    "        ml.set_color(cmap(tens[i]))\n",
    "    \n",
    "    cur_time = (frame+start_idx)*net.min_delay\n",
    "    fig.suptitle('time: ' + '{:f}'.format(cur_time))\n",
    "    # plotting target\n",
    "    #cur_idx = int(cur_time/t_pres) + strt_idx\n",
    "    #cur_idx = int(frame*net.min_delay/t_pres) + strt_idx\n",
    "    cur_idx = int(frame*net.min_delay/t_pres)  # if using new targets\n",
    "    x_coord, y_coord = hand_coords[m_idxs[cur_idx]]\n",
    "    target.set_data([x_coord], [y_coord])\n",
    "    # plotting predicted velocity\n",
    "    #pred_vel.set_data([xh[frame], xh[frame]+0.3*pred_v[0][frame]], [yh[frame], yh[frame]+0.3*pred_v[1][frame]])\n",
    "    #pred_vel.set_data([xh[frame], xh[frame]+5.*pred_v2[0][frame]], [yh[frame], yh[frame]+5.*pred_v2[1][frame]])\n",
    "    \n",
    "    return line, points, mus_lines #muscle1\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=np.arange(0, len(theta_s), 20), init_func=init, blit=True, interval=20)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate way to display the animation\n",
    "from IPython.display import HTML\n",
    "#HTML(ani.to_jshtml(fps=20))\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the animation\n",
    "import matplotlib.animation as animation\n",
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=24, metadata=dict(artist='Sergio Verduzco'), bitrate=2000)\n",
    "ani.save('test_ani2.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with variable lrate\n",
    "n_reps = 6\n",
    "t_rep = 150\n",
    "MCbase_rate = 10.\n",
    "MCdecay_rate = 0.7\n",
    "MCdev_rate = 20.\n",
    "AFMbase_rate = 5.\n",
    "AFMdecay_rate = 0.7\n",
    "AFMdev_rate = 20.\n",
    "for rep in range(n_reps):\n",
    "    # set learning rates\n",
    "    M__C_lrate = MCbase_rate + MCdev_rate * np.exp(-MCdecay_rate*rep)\n",
    "    AF__M_lrate = AFMbase_rate + AFMdev_rate * np.exp(-AFMdecay_rate*rep)\n",
    "    \n",
    "    for syn_list in net.syns:\n",
    "        for syn in syn_list:\n",
    "            if syn.preID in M and syn.postID in (CE+CI):\n",
    "                syn.lrate = M__C_lrate\n",
    "                syn.alpha = syn.lrate * net.min_delay\n",
    "            elif syn.preID in AF and syn.postID in M:\n",
    "                syn.lrate = AF__M_lrate\n",
    "                syn.alpha = syn.lrate * net.min_delay\n",
    "\n",
    "    # simulate\n",
    "    start_time = time.time()\n",
    "    times, data, plant_data  = net.flat_run(t_rep)\n",
    "\n",
    "    print('Execution time on rep %d is %s seconds' % (rep, time.time() - start_time))\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#points.clear()\n",
    "#target.clear()\n",
    "#traj.clear()\n",
    "\n",
    "ax.clear()\n",
    "fig.clear()\n",
    "\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
