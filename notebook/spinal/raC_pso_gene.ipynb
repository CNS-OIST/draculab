{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# raC_pso_gene.ipynb\n",
    "\n",
    "Hyperparameter search on the reach_analysis_C model using either Particle Swarm Optimization, a genetic algorithm, or a combinatin of both using two machines.\n",
    "\n",
    "When running both algorithms, one machine maintains a population evolved through the PSO algorithm, whereas the second machine uses a genetic algorithm. They share their configurations through a shared file system.\n",
    "\n",
    "-Sergio Verduzco-Flores  \n",
    "May 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/z/projects/draculab\n"
     ]
    }
   ],
   "source": [
    "%cd ../..\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "from pathos.multiprocessing import ProcessingPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from draculab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/z/projects/draculab/notebook/spinal\n",
      "/home/z/projects/draculab\n"
     ]
    }
   ],
   "source": [
    "%cd /home/z/projects/draculab/notebook/spinal/\n",
    "from net_builders import *\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility methods, ranges, search configuration parameters\n",
    "\n",
    "focus_params = True # whether to focus mutations on a specific set of parameters\n",
    "max_evals = 8 # maximum number of times to evaluate a configuration\n",
    "target_fitness = 0.02 # stop if fitness reaches this value\n",
    "\n",
    "# we have 5 separate network configurations to explore\n",
    "class sim_config(Enum):\n",
    "    C_LEARNS = 1\n",
    "    M_LEARNS = 2\n",
    "    STATIC_CONN = 3\n",
    "    C_LEARNS_SYNE = 4\n",
    "    C_LEARNS_ROT = 5\n",
    "    \n",
    "test = sim_config['C_LEARNS_SYNE'] # select the configuration\n",
    "\n",
    "# Specify paramters and ranges\n",
    "ranges = {\"A__C_lrate\" : {\"low\": 0.1, \"high\": 30., \"default\":15.},\n",
    "          \"A__C_w_max_frac\" : {\"low\": .05, \"high\": 1., \"default\":.3},\n",
    "          \"A__C_w_sum\" : {\"low\": .5, \"high\": 10., \"default\":.8},\n",
    "          \"A__M_lrate\" : {\"low\": 0.1, \"high\": 30., \"default\":20.},\n",
    "          \"A__M_w_max_frac\" : {\"low\": .05, \"high\": 1., \"default\":.4},\n",
    "          \"A__M_w_sum\" : {\"low\": .5, \"high\": 10., \"default\":2.},\n",
    "          \"AL_thresh\" : {\"low\": -.1, \"high\": 1.5, \"default\":.7},\n",
    "          \"b_e\": {\"low\": .5, \"high\": 5., \"default\":1.},\n",
    "          \"C__C_antag\": {\"low\": 0.1, \"high\": 3., \"default\":1.5},\n",
    "          \"C__C_p_antag\": {\"low\": 0., \"high\": 1.5, \"default\":.25},\n",
    "          \"C__C_p_syne\": {\"low\": 0., \"high\": 1., \"default\":.3},\n",
    "          \"C__C_syne\": {\"low\": 0., \"high\": 2.5, \"default\":1.},\n",
    "          \"C_adapt_amp\": {\"low\": 0., \"high\": 5., \"default\":.0},\n",
    "          \"C_cid\" : {\"low\": 0.1, \"high\": 2., \"default\":.15},\n",
    "          \"C_sigma\" : {\"low\": 0., \"high\": 1., \"default\":.4},\n",
    "          \"C_slope\" : {\"low\": 0.5, \"high\": 4., \"default\":2.3},\n",
    "          \"C_tau\" : {\"low\": 0.01, \"high\": .4, \"default\":.2},\n",
    "          \"C_tau_slow\" : {\"low\": 2., \"high\": 20., \"default\":5.},\n",
    "          \"CE_thresh\" : {\"low\": 0., \"high\": 4., \"default\":1.},\n",
    "          \"CE__CI_w\": {\"low\": 0., \"high\": 2.5, \"default\":.5},\n",
    "          \"CI__CE_w\": {\"low\": -2.5, \"high\": 0, \"default\":-1.8},\n",
    "          \"CI_slope\" : {\"low\": 1., \"high\": 5., \"default\":3.8},\n",
    "          \"CI_tau\" : {\"low\": 0.01, \"high\": .2, \"default\":.025},\n",
    "          \"CI_thresh\" : {\"low\": 0., \"high\": 4., \"default\":1.5},  \n",
    "          \"g_e_03\": {\"low\": 15., \"high\": 25., \"default\":20.},  \n",
    "          \"g_e_factor\": {\"low\": 0.5, \"high\": 4., \"default\":3.},\n",
    "          \"II_g_03\": {\"low\": 2., \"high\": 9., \"default\":3.},\n",
    "          \"k_pe_e\": {\"low\": 16., \"high\": 25., \"default\":20.},\n",
    "          \"k_se_e\": {\"low\": 16., \"high\": 25., \"default\":20.},\n",
    "          \"M__AL_lrate\" : {\"low\": .1, \"high\": 600., \"default\":500.},\n",
    "          \"M__AL_w_sum\": {\"low\": 0.5, \"high\": 8., \"default\": 1.5},\n",
    "          \"M_adapt_amp\": {\"low\": 0., \"high\": 5., \"default\":.0},\n",
    "          \"M__C_lrate\" : {\"low\": .1, \"high\": 600., \"default\":500.},\n",
    "          \"M__C_w_sum\": {\"low\": 0.5, \"high\": 8., \"default\": 3.},\n",
    "          \"M__M_w\": {\"low\": 0., \"high\": -3., \"default\":-.5},   # must set to zero when permutting M\n",
    "          \"M_cid\": {\"low\": 0.05, \"high\": 2., \"default\": 1.1},\n",
    "          \"M_des_out_w_abs_sum\": {\"low\": 0.5, \"high\": 4., \"default\": 2.},\n",
    "          \"M_tau\": {\"low\": .005, \"high\":.2, \"default\":.03},\n",
    "          \"M_slope\": {\"low\": .5, \"high\":4., \"default\":2.7},\n",
    "          \"M_thresh\" : {\"low\": 0., \"high\": 3.5, \"default\":.5},\n",
    "          \"M_sigma\" : {\"low\": 0., \"high\": 1., \"default\":.4},\n",
    "          \"SF_slope\": {\"low\": .5, \"high\":4.5, \"default\":4.},\n",
    "          \"SF_thresh_03\": {\"low\": .2, \"high\": 1.1, \"default\":.55},\n",
    "          \"SPF__M_lrate\": {\"low\": .1, \"high\": 600., \"default\":500.},\n",
    "          \"SPF__M_w_sum\": {\"low\": .5, \"high\": 5., \"default\":2.5},\n",
    "          \"SPF_des_out_w_abs_sum\": {\"low\": .5, \"high\": 5., \"default\":1.5},\n",
    "          \"SPF__SPF_w\": {\"low\": -3., \"high\": 0., \"default\":-1.77}\n",
    "         }\n",
    "\n",
    "def set_value(name, value):\n",
    "    \"\"\" Set a static value for a parameter in the 'ranges' dictionary. \"\"\"\n",
    "    ranges[name]['low'] = value\n",
    "    ranges[name]['high'] = value\n",
    "    ranges[name]['default'] = value\n",
    "\n",
    "if test.value == sim_config.STATIC_CONN.value:\n",
    "    rga_on_M = False # whether to use rga_21 connections on SPF__M\n",
    "    M_noise = False # whether M units are noisy (use euler_maru integrator)\n",
    "    C_noise = False # whether C units are noisy (use euler_maru integrator)\n",
    "    M__C_rand_w = False #True # whether to randomly intialize weights for the M__C connections\n",
    "    old_M__C = False # when using hand-set M__C connections  (e.g. M__C_rand_w=False)\n",
    "                 # old_M__C=False uses permutted M with no negative connections\n",
    "    M__M_conns = True # antagonist inhibition in M\n",
    "    rand_targets = False # Random or radial targets\n",
    "    use_syne = False\n",
    "    rot_SPF = False\n",
    "    set_value('M__C_lrate', 0.1) # remove M__C plasticity\n",
    "    set_value('M__AL_lrate', 0.1)\n",
    "    set_value('M__M_w', 0.)\n",
    "    set_value('C_adapt_amp', 0.)\n",
    "    set_value('M_adapt_amp', 0.)\n",
    "#     main_pars = {'A__C_w_sum', 'A__M_w_sum', 'AL_thresh', 'CI_slope', 'CI_thresh', 'CE_thresh', \n",
    "#                  'M_slope', 'M_thresh', 'M__C_w_sum', 'M__AL_w_sum', 'C_slope', 'C_tau', 'M_tau',\n",
    "#                  'SF_slope', 'g_e_03', 'II_g_03', 'SPF__M_w_sum'}\n",
    "    main_pars = {'A__C_w_max_frac', 'A__M_w_max_frac', 'A__C_w_sum', 'A__M_w_sum',\n",
    "                'CE_thresh', 'CI_thresh', 'C_tau', 'M_thresh'}\n",
    "elif (test.value == sim_config.C_LEARNS.value or\n",
    "      test.value == sim_config.C_LEARNS_SYNE.value or\n",
    "      test.value == sim_config.C_LEARNS_ROT.value):\n",
    "    rga_on_M = False # whether to use rga_21 connections on SPF__M\n",
    "    M_noise = False # whether M units are noisy (use euler_maru integrator)\n",
    "    C_noise = True # whether C units are noisy (use euler_maru integrator)\n",
    "    M__C_rand_w = True # whether to randomly intialize weights for the M__C connections\n",
    "    old_M__C = None\n",
    "    M__M_conns = True # antagonist inhibition in M\n",
    "    rand_targets = True # Random or radial targets\n",
    "    if test.value == sim_config.C_LEARNS_ROT.value:\n",
    "        rot_SPF = True\n",
    "        M__M_conns = False\n",
    "    else:\n",
    "        rot_SPF = False\n",
    "    if test.value == sim_config.C_LEARNS_SYNE.value:\n",
    "        use_syne = True # whether to use the version of the network with \"synergies\"\n",
    "    else:\n",
    "        use_syne = False\n",
    "    set_value('M_adapt_amp', 0.)\n",
    "    set_value('SPF__M_lrate', 0.)\n",
    "    main_pars = {'A__C_w_max_frac', 'A__M_w_max_frac', 'A__C_w_sum', 'A__M_w_sum',\n",
    "                 'M__M_w', 'CE_thresh', 'CI_thresh', 'C_sigma', 'C_cid', 'M_slope',\n",
    "                 'C_slope', 'CI_slope', 'M_thresh', 'M__C_w_sum', 'C_adapt_amp',\n",
    "                 'C_tau', 'SPF__M_w_sum'}\n",
    "elif test.value == sim_config.M_LEARNS.value:\n",
    "    rga_on_M = True # whether to use rga_21 connections on SPF__M\n",
    "    M_noise = True # whether M units are noisy (use euler_maru integrator)\n",
    "    C_noise = False # whether C units are noisy (use euler_maru integrator)\n",
    "    M__C_rand_w = False # whether to randomly intialize the M__C connections\n",
    "    old_M__C = False # when using hand-set M__C connections  (e.g. M__C_rand_w=False)\n",
    "                 # old_M__C=False uses permutted M with no negative connections\n",
    "    M__M_conns = False # antagonist inhibition in M\n",
    "    rand_targets = True # Random or radial targets\n",
    "    use_syne = False\n",
    "    rot_SPF = False\n",
    "    set_value('M__C_lrate', 0.)\n",
    "    set_value('M__AL_lrate', 0.)\n",
    "    set_value('C_adapt_amp', 0.)\n",
    "\n",
    "    main_pars = {'CE_thresh', 'CI_thresh', 'M_sigma', 'SPF__M_lrate', 'M_cid', \n",
    "                 'C_slope', 'CI_slope', 'M_thresh', 'M_slope', 'M__C_w_sum', \n",
    "                 'SPF_des_out_w_abs_sum', 'SPF__M_w_sum', 'SPF__M_lrate', \n",
    "                 'M_adapt_amp', 'A__M_w_max_frac', 'A__M_w_sum'}\n",
    "    ranges['M_thresh']['default'] = (ranges['SPF_des_out_w_abs_sum']['default'] + \n",
    "                                     ranges['SPF__M_w_sum']['default']) / 4.\n",
    "else:\n",
    "    raise ValueError('Invalid simulation configuration')\n",
    "\n",
    "\n",
    "#par_list = [name for name in ranges] # ordered list with names of the parameters\n",
    "par_list = list(ranges.keys())\n",
    "# parameters to focus on\n",
    "# main_pars.update({'A__C_lrate', 'A__C_w_max_frac', 'A__C_w_sum', 'AL_thresh', \"A__M_w_max_frac\",\n",
    "#                   \"A__M_w_sum\", \"A__M_lrate\", \"g_e_03\", \"SF_thresh_03\", \"M_tau\", \n",
    "#                   \"M_des_out_w_abs_sum\", \"C_slope\", \"C_tau\", \"CI_slope\", \"CI_tau\", \"C_tau_slow\"})\n",
    "main_pars = list(main_pars)\n",
    "if focus_params:\n",
    "    par_list = main_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for the genetic algorithm and for creating initial parameters\n",
    "\n",
    "def mutate(cfg, name_list=par_list):\n",
    "    \"\"\" Mutate a single parameter of the given configuration. \n",
    "    \n",
    "        Args:\n",
    "            name_list: list with names of candidate parameters.\n",
    "    \"\"\"\n",
    "    n = np.random.randint(len(name_list))\n",
    "    par_name = name_list[n]\n",
    "    l = ranges[par_name]['low']\n",
    "    h = ranges[par_name]['high']\n",
    "    cfg[par_name] =  l + (h-l)*np.random.random()\n",
    "    \n",
    "def soft_mutate(cfg, ma, name_list=par_list):\n",
    "    \"\"\" Soft-mutate a single parameter of the given configuration.\n",
    "    \n",
    "        A 'soft mutation' keeps the mutated value close to the original value.\n",
    "        The maximum amplitude of the mutation is given by the 'ma' argument.\n",
    "        \n",
    "        Args:\n",
    "            ma : float in (0,1]. Max. amplitude as fraction of the parameter's range \n",
    "            name_list: list with names of candidate parameters.\n",
    "    \"\"\"\n",
    "    n = np.random.randint(len(name_list))\n",
    "    par_name = name_list[n]\n",
    "    l = ranges[par_name]['low']\n",
    "    h = ranges[par_name]['high']\n",
    "    cfg[par_name] = max(l, min(h, cfg[par_name] + ma * (h-l) * (np.random.random()-0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create the initial population: method 1\n",
    "\n",
    "# create variations of the parameters we want to investigtate\n",
    "pop_size = 90 # number of configurations in the population\n",
    "\n",
    "default_dic = {}\n",
    "for name in list(ranges.keys()):\n",
    "    default_dic[name] = ranges[name]['default']\n",
    "\n",
    "pop = [default_dic.copy() for _ in range(pop_size)]\n",
    "\n",
    "n_def = 3 # how many will have the default values\n",
    "        \n",
    "# fill variations in both directions\n",
    "chg_name = [\"low\", \"default\", \"high\"] # auxiliary list\n",
    "for ind in range(n_def, pop_size):\n",
    "    for name in par_list:\n",
    "        chg_dir = chg_name[np.random.randint(3)] \n",
    "        pop[ind][name] = 0.5 * (ranges[name][chg_dir] + ranges[name][\"default\"])\n",
    "            \n",
    "# Throw n_muts mutations, and n_soft_muts soft mutations\n",
    "n_muts = 20\n",
    "n_soft_muts = 10 # must have n_muts + n_soft_muts < pop_size-1\n",
    "perm = np.random.permutation(range(1,pop_size)) # don't mutate the first element\n",
    "for i in range(n_muts):\n",
    "    mutate(pop[perm[i]])\n",
    "for i in range(n_muts,n_muts+n_soft_muts):\n",
    "    soft_mutate(pop[perm[i]], 0.2)\n",
    "    \n",
    "pop[10] = {'A__C_lrate': 15.0,\n",
    "         'A__C_w_max_frac': 0.3,\n",
    "         'A__C_w_sum': 0.8,\n",
    "         'A__M_lrate': 20.0,\n",
    "         'A__M_w_max_frac': 0.7,\n",
    "         'A__M_w_sum': 1.5,\n",
    "         'AL_thresh': 0.7,\n",
    "         'b_e': 1.0,\n",
    "         'C__C_antag': 1.5,\n",
    "         'C__C_p_antag': 0.25,\n",
    "         'C__C_p_syne': 0.3,\n",
    "         'C__C_syne': 1.0,\n",
    "         'C_adapt_amp': 0.0,\n",
    "         'C_cid': 0.15,\n",
    "         'C_sigma': 0.2,\n",
    "         'C_slope': 1.4,\n",
    "         'C_tau': 0.30000000000000004,\n",
    "         'C_tau_slow': 12.5,\n",
    "         'CE_thresh': 1.0,\n",
    "         'CE__CI_w': 0.5,\n",
    "         'CI__CE_w': -1.8,\n",
    "         'CI_slope': 3.8,\n",
    "         'CI_tau': 0.0175,\n",
    "         'CI_thresh': 1.5,\n",
    "         'g_e_03': 17.5,\n",
    "         'g_e_factor': 3.0,\n",
    "         'II_g_03': 6.0,\n",
    "         'k_pe_e': 20.0,\n",
    "         'k_se_e': 20.0,\n",
    "         'M__AL_lrate': 0.1,\n",
    "         'M__AL_w_sum': 1.5,\n",
    "         'M__C_lrate': 0.1,\n",
    "         'M__C_w_sum': 3.0,\n",
    "         'M__M_w': -0.5,\n",
    "         'M_cid': 1.55,\n",
    "         'M_des_out_w_abs_sum': 2.0,\n",
    "         'M_tau': 0.115,\n",
    "         'M_slope': 2.7,\n",
    "         'M_thresh': 0.5,\n",
    "         'SF_thresh_03': 0.375,\n",
    "         'SPF__M_lrate': 500.0,\n",
    "         'SPF__M_w_sum': 2.5,\n",
    "         'SPF_des_out_w_abs_sum': 1.5,\n",
    "         'SPF__SPF_w': -1.77,\n",
    "         'fitness': 0.02124628616637105,\n",
    "         'n_evals': 1,\n",
    "         't_pres': 40,\n",
    "         'par_heter': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the initial population using an MN star\n",
    "\n",
    "# 1) Obtain star\n",
    "def MNstar(N, M, mu, theta, Dt, maxiters=1e4, miniters=100, V=None):\n",
    "    \"\"\"Returns M N-dimensional maximally-separated vectors.\n",
    "    \n",
    "        Args:\n",
    "            N: dimension of the vectors\n",
    "            M: number of vectors\n",
    "            mu: viscous friction coefficient\n",
    "            theta: simulation will continue until max. change < theta\n",
    "            Dt: simulation time step\n",
    "        Optional Args:\n",
    "            maxiters: max number of steps\n",
    "            V: initial vectors\n",
    "            miniters: minimum number of sim steps (to get things moving)\n",
    "        Returns:\n",
    "            V: an NxM numpy array with the separated vectors\n",
    "            c_max: a measure of how much the vectors were changing\n",
    "            step: simulation step where the function terminated\n",
    "    \"\"\"\n",
    "    c_max = theta + 1\n",
    "    if V is None:\n",
    "        V = 1. - 2.*np.random.random((N,M))\n",
    "    V = V / np.linalg.norm(V, axis=0) # normalizing\n",
    "    init_V = V.copy()\n",
    "    dV = np.zeros_like(V)\n",
    "    P = np.zeros((M,M))\n",
    "    step = 0\n",
    "    while (c_max > theta and step < maxiters) or step < miniters:\n",
    "        ddV = np.zeros_like(V)\n",
    "        for j in range(M):\n",
    "            for k in range(j+1,M):\n",
    "                P[j,k] = max(min(np.dot(V[:,j],V[:,k]), 1.-1e-10), -1.+1e-10) \n",
    "                q = min(1. / max((np.arccos(P[j,k])**2) * (1. - P[j,k]*P[j,k]), 1e-10), 1.e2)\n",
    "                ddV[:,j] = ddV[:,j] + q * (P[j,k] * V[:,j] - V[:,k])\n",
    "                ddV[:,k] = ddV[:,k] + q * (P[j,k] * V[:,k] - V[:,j])\n",
    "                \n",
    "        c_max = 0.\n",
    "        for j in range(M):\n",
    "            ddV[:,j] = ddV[:,j] - mu * dV[:,j]\n",
    "            dV[:,j] = dV[:,j] + Dt * ddV[:,j]\n",
    "            v_old = V[:,j].copy()\n",
    "            V[:,j] = V[:,j] + Dt * dV[:,j]\n",
    "            V[:,j] = V[:,j] / np.linalg.norm(V[:,j])\n",
    "            c = max(min(np.dot(V[:,j], v_old), 1.-1e-10), -1.+1e-10)\n",
    "            dV[:,j] = (c*V[:,j] - v_old) / Dt\n",
    "            if 1.-c > c_max: c_max = 1.-c\n",
    "        step += 1\n",
    "        \n",
    "    return V, c_max, step\n",
    "\n",
    "pop_size = 90 # number of configurations in the population\n",
    "\n",
    "# A star is born\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "star, _, _  = MNstar(len(par_list), pop_size-1, .2, 1e-6, .1)   #!!!!!\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "# 2) Obtain initial population and center\n",
    "default_dic = {}\n",
    "\n",
    "# Using the default values in 'ranges' as the center\n",
    "#-----------------------------------------------------------\n",
    "# for name in list(ranges.keys()):\n",
    "#     default_dic[name] = ranges[name]['default']\n",
    "\n",
    "# center = default_dic\n",
    "#-----------------------------------------------------------\n",
    "# If you want to use a center different from the default\n",
    "# load a parameter configuration\n",
    "# fname = '/home/z/Dropbox (OIST)/saves/gene_2022-05-17'\n",
    "# with (open(fname, \"rb\")) as f:\n",
    "#     pop_load = pickle.load(f)\n",
    "#     f.close()\n",
    "# center = pop_load[0]\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "center = {'A__C_lrate': 22.5,\n",
    "         'A__C_w_max_frac': 0.18,\n",
    "         'A__C_w_sum': 1.68,\n",
    "         'A__M_lrate': 26.17,\n",
    "         'A__M_w_max_frac': 0.56,\n",
    "         'A__M_w_sum': 0.85,\n",
    "         'AL_thresh': 1.1,\n",
    "         'b_e': 1.0,\n",
    "         'C__C_antag': 1.83,\n",
    "         'C__C_p_antag': 0.16,\n",
    "         'C__C_p_syne': 0.18,\n",
    "         'C__C_syne': 0.5,\n",
    "         'C_adapt_amp': 3.1,\n",
    "         'C_cid': 0.33,\n",
    "         'C_sigma': 0.63,\n",
    "         'C_slope': 1.63,\n",
    "         'C_tau': 0.14,\n",
    "         'C_tau_slow': 11.0,\n",
    "         'CE_thresh': 2.,\n",
    "         'CE__CI_w': 0.5,\n",
    "         'CI__CE_w': -1.8,\n",
    "         'CI_slope': 4.,\n",
    "         'CI_tau': 0.018,\n",
    "         'CI_thresh': 1.5,\n",
    "         'g_e_03': 22.37,\n",
    "         'g_e_factor': 3.0,\n",
    "         'II_g_03': 7.46,\n",
    "         'k_pe_e': 20.0,\n",
    "         'k_se_e': 20.0,\n",
    "         'M__AL_lrate': 300.0,\n",
    "         'M__AL_w_sum': 2.86,\n",
    "         'M__C_lrate': 500.0,\n",
    "         'M__C_w_sum': 3.29,\n",
    "         'M__M_w': -0.93,\n",
    "         'M_cid': 0.94,\n",
    "         'M_des_out_w_abs_sum': 2.52,\n",
    "         'M_tau': 0.047,\n",
    "         'M_slope': 1.46,\n",
    "         'M_thresh': 1.3,\n",
    "         'M_sigma': 0.45,\n",
    "         'SF_thresh_03': 0.75,\n",
    "         'SPF__M_lrate': 0.,\n",
    "         'SPF__M_w_sum': 3.24,\n",
    "         'SPF_des_out_w_abs_sum': 3.23,\n",
    "         'SPF__SPF_w': -1.77,\n",
    "         'fitness': 0.02491251754816184,\n",
    "         'n_evals': 1,\n",
    "         't_pres': 40.0,\n",
    "         'par_heter': 0.01,\n",
    "         'SF_slope': 3.,\n",
    "         'SPF_M_lrate': 500.0 }\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "pop = [center.copy() for _ in range(pop_size)]\n",
    "\n",
    "# 3) Expand configuration around the center\n",
    "for conf_idx, conf in enumerate(pop[2:]):\n",
    "    for par_idx, par_name in enumerate(par_list):\n",
    "        move = 0.5 * star[par_idx, conf_idx]\n",
    "        dir_tag = 'low' if move < 0. else 'high'\n",
    "        conf[par_name] = center[par_name] + abs(move) * (ranges[par_name][dir_tag] - center[par_name])\n",
    "\n",
    "#pop[1] = center2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create the initial population: method 2\n",
    "\n",
    "# Load the results from a previous run\n",
    "#fname = '/home/z/projects/draculab/saves/v3ft3p2ph2_pop_2021-05-28__10_53'\n",
    "fname = '/home/z/Dropbox (OIST)/saves/gene_2021-06-17'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    prev_pop1 = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "fname = '/home/z/Dropbox (OIST)/saves/gene_2021-06-24'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    prev_pop2 = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "fname = '/home/z/Dropbox (OIST)/saves/pso_2021-06-28'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    prev_pop3 = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "fname = '/home/z/Dropbox (OIST)/saves/pso_2021-06-24'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    prev_pop4 = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "fname = '/home/z/Dropbox (OIST)/saves/gene_2021-07-19'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    prev_pop5 = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "fname = '/home/z/Dropbox (OIST)/saves/pso_2021-07-19'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    prev_pop6 = pickle.load(f)\n",
    "    f.close()\n",
    "# If the results are from a run with fewer parameters\n",
    "# fill it with the default values.\n",
    "for cfg in prev_pop1 + prev_pop2 + prev_pop3 + prev_pop4:\n",
    "    for name in ranges:\n",
    "        if not name in cfg:\n",
    "            cfg[name] = ranges[name]['default']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Mix configurations from the two methods\n",
    "pop[0:15] = prev_pop1[:20]\n",
    "pop[15:30] = prev_pop2[:20]\n",
    "pop[30:45] = prev_pop3[:20]\n",
    "pop[45:60] = prev_pop4[:20]\n",
    "pop[60:75] = prev_pop5[:20]\n",
    "pop[75:90] = prev_pop6[:20]\n",
    "\n",
    "# Best configuration from June 11th\n",
    "cfg11 = {'A__M_w_max_frac': 0.9,\n",
    "         'A__M_w_sum': 2.0,\n",
    "         'C_adapt_amp': 4.4,\n",
    "         'C_cid': 0.12,\n",
    "         'C_sigma': 0.67,\n",
    "         'M_cid': 1.1,\n",
    "         'M_des_out_w_abs_sum': 3.0,\n",
    "         'g_e_factor': 3.0,\n",
    "         'C_slope': 2.,\n",
    "         'C_thresh': 1.1,\n",
    "         'C_tau': 0.26,\n",
    "         'C_tau_slow': 10.0,\n",
    "         'A__M_lrate': 8.0,\n",
    "         'AL_thresh': 0.55,\n",
    "         'b_e': 1.0,\n",
    "         'C__C_antag': 1.5,\n",
    "         'C__C_p_antag': 0.25,\n",
    "         'C__C_p_syne': 0.3,\n",
    "         'C__C_syne': 1.0,\n",
    "         'CE__CI_w': 0.5,\n",
    "         'CI__CE_w': -1.3,\n",
    "         'M__C_lrate': 300.0,\n",
    "         'M__C_w_sum': 2.3,\n",
    "         'M__M_w': -0.5,\n",
    "         'SPF__SPF_w': -1.5,\n",
    "         'fitness': None,\n",
    "         'n_evals': 0,\n",
    "         't_pres': 40,\n",
    "         'par_heter': 0.01,\n",
    "         'CI_slope': 2.5,\n",
    "         'CI_thresh': 1.4,\n",
    "         'CI_tau': 0.15,\n",
    "         'g_e_03': 20.0,\n",
    "         'II_g_03': 3.0,\n",
    "         'M_tau': 0.01,\n",
    "         'SF_thresh_03': 0.4}\n",
    "cfg_syne={'A__M_lrate': 20.0,\n",
    "     'A__M_w_max_frac': 0.3,\n",
    "     'A__M_w_sum': 1.0,\n",
    "     'AL_thresh': 0.55,\n",
    "     'b_e': 1.5,\n",
    "     'C__C_antag': 1.5,\n",
    "     'C__C_p_antag': 0.25,\n",
    "     'C__C_p_syne': 0.28,\n",
    "     'C__C_syne': 1.,\n",
    "     'C_adapt_amp': 0.4,\n",
    "     'C_cid': 0.15,\n",
    "     'C_sigma': 0.5,\n",
    "     'C_slope': 2.1,\n",
    "     'C_tau': 0.23,\n",
    "     'C_tau_slow': 40.0,\n",
    "     'C_thresh': 0.93,\n",
    "     'CE__CI_w': 0.5,\n",
    "     'CI__CE_w': -1.3,\n",
    "     'g_e_03': 25.,\n",
    "     'CI_slope': 3.6,\n",
    "     'CI_tau': 0.017,\n",
    "     'CI_thresh': 1.4,\n",
    "     'g_e_factor': 3.2,\n",
    "     'II_g_03': 3.16,\n",
    "     'M__C_lrate': 200.,\n",
    "     'M__C_w_sum': 2.5,\n",
    "     'M__M_w': 0.0,\n",
    "     'M_cid': 1.1,\n",
    "     'M_des_out_w_abs_sum': 3.,\n",
    "     'M_tau': 0.024,\n",
    "     'SF_thresh_03': 0.63,\n",
    "     'SPF__SPF_w': -1.5,\n",
    "     'fitness': None,\n",
    "     'n_evals': 0,\n",
    "     't_pres': 40.,\n",
    "     'par_heter': 0.01}\n",
    "\n",
    "cfg_std={'A__M_lrate': 20.0,\n",
    "     'A__M_w_max_frac': 0.34,\n",
    "     'A__M_w_sum': 1.0,\n",
    "     'AL_thresh': 0.56,\n",
    "     'b_e': 1.,\n",
    "     'C__C_antag': 1.6,\n",
    "     'C__C_p_antag': 0.15,\n",
    "     'C__C_p_syne': 0.26,\n",
    "     'C__C_syne': 1.1,\n",
    "     'C_adapt_amp': 0.0,\n",
    "     'C_cid': 0.17,\n",
    "     'C_sigma': 0.5,\n",
    "     'C_slope': 2.25,\n",
    "     'C_tau': 0.24,\n",
    "     'C_tau_slow': 2.0,\n",
    "     'C_thresh': 1.14,\n",
    "     'CE__CI_w': 0.39,\n",
    "     'CI__CE_w': -1.8,\n",
    "     'g_e_03': 20.,\n",
    "     'CI_slope': 3.9,\n",
    "     'CI_tau': 0.06,\n",
    "     'CI_thresh': 1.37,\n",
    "     'g_e_factor': 3.,\n",
    "     'II_g_03': 2.73,\n",
    "     'M__C_lrate': 500.0,\n",
    "     'M__C_w_sum': 3.28,\n",
    "     'M__M_w': 0.0,\n",
    "     'M_cid': 1.,\n",
    "     'M_des_out_w_abs_sum': 1.87,\n",
    "     'M_tau': 0.012,\n",
    "     'SF_thresh_03': 0.59,\n",
    "     'SPF__SPF_w': -1.6,\n",
    "     'fitness': None,\n",
    "     'n_evals': 0,\n",
    "     't_pres': 40.,\n",
    "     'par_heter': 0.01}\n",
    "\n",
    "pop[68] = cfg_std\n",
    "pop[78] = cfg_syne\n",
    "pop[88] = cfg11\n",
    "\n",
    "# If configurations have fewer parameters, fill them with the default values.\n",
    "# Also, homogeneize parameters not in par_list\n",
    "for cfg in pop:\n",
    "    for name in ranges:\n",
    "        if (not name in cfg or \n",
    "            (focus_params and not name in par_list)):\n",
    "            cfg[name] = cfg11[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset fitness and number of evaluations\n",
    "for dic in pop:\n",
    "    if not 'fitness' in dic or not 'nevals' in dic:\n",
    "        dic['fitness'] = None # average fitness value\n",
    "        dic['n_evals'] = 0  # number of times fitness has been evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set search parameters present in the configurations\n",
    "for cfg in pop:\n",
    "    cfg['t_pres'] = 40.\n",
    "    cfg['par_heter'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A__C_lrate':22.5, 'A__C_w_max_frac':0.18, 'A__C_w_sum':1.68, 'A__M_lrate':26.17, 'A__M_w_max_frac':0.56, 'A__M_w_sum':0.85, 'AL_thresh':1.1, 'b_e':1.0, 'C__C_antag':1.83, 'C__C_p_antag':0.16, 'C__C_p_syne':0.18, 'C__C_syne':0.5, 'C_adapt_amp':3.1, 'C_cid':0.33, 'C_sigma':0.63, 'C_slope':1.63, 'C_tau':0.14, 'C_tau_slow':11.0, 'CE_thresh':2.0, 'CE__CI_w':0.5, 'CI__CE_w':-1.8, 'CI_slope':4.0, 'CI_tau':0.018, 'CI_thresh':1.5, 'g_e_03':22.37, 'g_e_factor':3.0, 'II_g_03':7.46, 'k_pe_e':20.0, 'k_se_e':20.0, 'M__AL_lrate':300.0, 'M__AL_w_sum':2.86, 'M__C_lrate':500.0, 'M__C_w_sum':3.29, 'M__M_w':-0.93, 'M_cid':0.94, 'M_des_out_w_abs_sum':2.52, 'M_tau':0.047, 'M_slope':1.46, 'M_thresh':1.3, 'M_sigma':0.45, 'SF_thresh_03':0.75, 'SPF__M_lrate':0.0, 'SPF__M_w_sum':3.24, 'SPF_des_out_w_abs_sum':3.23, 'SPF__SPF_w':-1.77, 'fitness':None, 'n_evals':0, 't_pres':40.0, 'par_heter':0.01, 'SF_slope':3.0, 'SPF_M_lrate':500.0, }\n",
      "\n",
      "{'A__C_lrate':22.5, 'A__C_w_max_frac':0.18, 'A__C_w_sum':1.68, 'A__M_lrate':26.17, 'A__M_w_max_frac':0.56, 'A__M_w_sum':0.85, 'AL_thresh':1.1, 'b_e':1.0, 'C__C_antag':1.83, 'C__C_p_antag':0.16, 'C__C_p_syne':0.18, 'C__C_syne':0.5, 'C_adapt_amp':3.1, 'C_cid':0.33, 'C_sigma':0.63, 'C_slope':1.63, 'C_tau':0.14, 'C_tau_slow':11.0, 'CE_thresh':2.0, 'CE__CI_w':0.5, 'CI__CE_w':-1.8, 'CI_slope':4.0, 'CI_tau':0.018, 'CI_thresh':1.5, 'g_e_03':22.37, 'g_e_factor':3.0, 'II_g_03':7.46, 'k_pe_e':20.0, 'k_se_e':20.0, 'M__AL_lrate':300.0, 'M__AL_w_sum':2.86, 'M__C_lrate':500.0, 'M__C_w_sum':3.29, 'M__M_w':-0.93, 'M_cid':0.94, 'M_des_out_w_abs_sum':2.52, 'M_tau':0.047, 'M_slope':1.46, 'M_thresh':1.3, 'M_sigma':0.45, 'SF_thresh_03':0.75, 'SPF__M_lrate':0.0, 'SPF__M_w_sum':3.24, 'SPF_des_out_w_abs_sum':3.23, 'SPF__SPF_w':-1.77, 'fitness':None, 'n_evals':0, 't_pres':40.0, 'par_heter':0.01, 'SF_slope':3.0, 'SPF_M_lrate':500.0, }\n",
      "\n",
      "{'A__C_lrate':22.5, 'A__C_w_max_frac':0.21488225011759804, 'A__C_w_sum':1.6756711106776672, 'A__M_lrate':26.17, 'A__M_w_max_frac':0.47603184379529306, 'A__M_w_sum':0.8375525679891747, 'AL_thresh':1.1, 'b_e':1.0, 'C__C_antag':1.83, 'C__C_p_antag':0.16, 'C__C_p_syne':0.18, 'C__C_syne':0.5, 'C_adapt_amp':3.212951564004632, 'C_cid':0.727416923205598, 'C_sigma':0.5966996798799812, 'C_slope':1.4744374867296037, 'C_tau':0.1341104587122363, 'C_tau_slow':11.0, 'CE_thresh':1.8674869041617839, 'CE__CI_w':0.5, 'CI__CE_w':-1.8, 'CI_slope':4.070946977755611, 'CI_tau':0.018, 'CI_thresh':1.5972612953533352, 'g_e_03':22.37, 'g_e_factor':3.0, 'II_g_03':7.46, 'k_pe_e':20.0, 'k_se_e':20.0, 'M__AL_lrate':300.0, 'M__AL_w_sum':2.86, 'M__C_lrate':500.0, 'M__C_w_sum':2.8172815960238045, 'M__M_w':-0.7735979192069055, 'M_cid':0.94, 'M_des_out_w_abs_sum':2.52, 'M_tau':0.047, 'M_slope':2.086675409335982, 'M_thresh':1.340135387636933, 'M_sigma':0.45, 'SF_thresh_03':0.75, 'SPF__M_lrate':0.0, 'SPF__M_w_sum':3.3841542160935982, 'SPF_des_out_w_abs_sum':3.23, 'SPF__SPF_w':-1.77, 'fitness':None, 'n_evals':0, 't_pres':40.0, 'par_heter':0.01, 'SF_slope':3.0, 'SPF_M_lrate':500.0, }\n",
      "\n",
      "{'A__C_lrate':22.5, 'A__C_w_max_frac':0.24283780992975273, 'A__C_w_sum':1.7910693304370704, 'A__M_lrate':26.17, 'A__M_w_max_frac':0.5253432987898695, 'A__M_w_sum':1.4394338690107857, 'AL_thresh':1.1, 'b_e':1.0, 'C__C_antag':1.83, 'C__C_p_antag':0.16, 'C__C_p_syne':0.18, 'C__C_syne':0.5, 'C_adapt_amp':2.6182699449286067, 'C_cid':0.3090480068016087, 'C_sigma':0.6652312992530125, 'C_slope':1.4093759012364733, 'C_tau':0.1456831234472704, 'C_tau_slow':11.0, 'CE_thresh':2.220582231811782, 'CE__CI_w':0.5, 'CI__CE_w':-1.8, 'CI_slope':4.0149949273019345, 'CI_tau':0.018, 'CI_thresh':1.1745600092539097, 'g_e_03':22.37, 'g_e_factor':3.0, 'II_g_03':7.46, 'k_pe_e':20.0, 'k_se_e':20.0, 'M__AL_lrate':300.0, 'M__AL_w_sum':2.86, 'M__C_lrate':500.0, 'M__C_w_sum':3.609424553775657, 'M__M_w':-0.7751098308793836, 'M_cid':0.94, 'M_des_out_w_abs_sum':2.52, 'M_tau':0.047, 'M_slope':1.5532700448034003, 'M_thresh':1.5253723938803252, 'M_sigma':0.45, 'SF_thresh_03':0.75, 'SPF__M_lrate':0.0, 'SPF__M_w_sum':3.6391354960162183, 'SPF_des_out_w_abs_sum':3.23, 'SPF__SPF_w':-1.77, 'fitness':None, 'n_evals':0, 't_pres':40.0, 'par_heter':0.01, 'SF_slope':3.0, 'SPF_M_lrate':500.0, }\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A__C_lrate': 22.5,\n",
       " 'A__C_w_max_frac': 0.18,\n",
       " 'A__C_w_sum': 1.68,\n",
       " 'A__M_lrate': 26.17,\n",
       " 'A__M_w_max_frac': 0.56,\n",
       " 'A__M_w_sum': 0.85,\n",
       " 'AL_thresh': 1.1,\n",
       " 'b_e': 1.0,\n",
       " 'C__C_antag': 1.83,\n",
       " 'C__C_p_antag': 0.16,\n",
       " 'C__C_p_syne': 0.18,\n",
       " 'C__C_syne': 0.5,\n",
       " 'C_adapt_amp': 3.1,\n",
       " 'C_cid': 0.33,\n",
       " 'C_sigma': 0.63,\n",
       " 'C_slope': 1.63,\n",
       " 'C_tau': 0.14,\n",
       " 'C_tau_slow': 11.0,\n",
       " 'CE_thresh': 2.0,\n",
       " 'CE__CI_w': 0.5,\n",
       " 'CI__CE_w': -1.8,\n",
       " 'CI_slope': 4.0,\n",
       " 'CI_tau': 0.018,\n",
       " 'CI_thresh': 1.5,\n",
       " 'g_e_03': 22.37,\n",
       " 'g_e_factor': 3.0,\n",
       " 'II_g_03': 7.46,\n",
       " 'k_pe_e': 20.0,\n",
       " 'k_se_e': 20.0,\n",
       " 'M__AL_lrate': 300.0,\n",
       " 'M__AL_w_sum': 2.86,\n",
       " 'M__C_lrate': 500.0,\n",
       " 'M__C_w_sum': 3.29,\n",
       " 'M__M_w': -0.93,\n",
       " 'M_cid': 0.94,\n",
       " 'M_des_out_w_abs_sum': 2.52,\n",
       " 'M_tau': 0.047,\n",
       " 'M_slope': 1.46,\n",
       " 'M_thresh': 1.3,\n",
       " 'M_sigma': 0.45,\n",
       " 'SF_thresh_03': 0.75,\n",
       " 'SPF__M_lrate': 0.0,\n",
       " 'SPF__M_w_sum': 3.24,\n",
       " 'SPF_des_out_w_abs_sum': 3.23,\n",
       " 'SPF__SPF_w': -1.77,\n",
       " 'fitness': None,\n",
       " 'n_evals': 0,\n",
       " 't_pres': 40.0,\n",
       " 'par_heter': 0.01,\n",
       " 'SF_slope': 3.0,\n",
       " 'SPF_M_lrate': 500.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print used configuration\n",
    "for dic in pop[0:4]:\n",
    "    print('{',end='')\n",
    "    for name in dic.keys():\n",
    "        print(\"\\'%s\\':%s, \"%(name, dic[name]), end='')\n",
    "#         if name in net_conf:\n",
    "#             print(\"\\'%s\\':%s, \"%(name, dic[name]), end='')\n",
    "#         if name != 'fitness' or dic['fitness'] != None:\n",
    "#             print(\"\\'%s\\':%.2f, \" % (name, dic[name]), end='')\n",
    "    print('}\\n')\n",
    "\n",
    "pop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_new_targets(net,\n",
    "                    pops_dict,\n",
    "                    r,\n",
    "                    t_pres,\n",
    "                    n_trgs,\n",
    "                    n_rounds,\n",
    "                    pds,\n",
    "                    permute_targets=True):\n",
    "    \"\"\" Set new targets for reaching.\n",
    "        \n",
    "        Args:\n",
    "            net: the draculab network\n",
    "            pops_dict: dictionary with unit IDs for each population\n",
    "            r: distance from center to targets\n",
    "            t_pres: new presentation time\n",
    "            n_trgs: number of targets\n",
    "            n_rounds: number of times the n_trgs targets will be presented\n",
    "            pds : parameter dictionaries used to calculate SP values.\n",
    "            permute_targets: (boolean) are targets presented permuted?\n",
    "\n",
    "            \n",
    "        Returns:\n",
    "            hand_coords : list with target coordinates (each a numpy 2-array).\n",
    "            targets : list, only with targets\n",
    "            center : only the center coordinates\n",
    "            trg_ids: target used for each presentation\n",
    "    \"\"\"\n",
    "    \n",
    "    start_t = net.sim_time # starting time for new simulation\n",
    "    # 8 radial targets in sequence, from 0 to 315 degrees\n",
    "    r = 0.1 # distance from center to targets\n",
    "    center = np.array([0.3, 0.3]) # initial hand location\n",
    "    angs = np.linspace(0., 2.*np.pi, n_trgs+1)[:-1]\n",
    "    circle = np.array([np.array([np.cos(ang),np.sin(ang)]) for ang in angs])\n",
    "    targets = center + r*circle # coordinates of the targets\n",
    "\n",
    "    if permute_targets:\n",
    "        # version with permuted targets, all are seen every 8 presentations\n",
    "        trg_ids = np.random.permutation(n_trgs*n_rounds)%n_trgs # target for each presentation\n",
    "        hand_coords = []\n",
    "        for idx in trg_ids:\n",
    "            hand_coords += [center, targets[idx]]\n",
    "        hand_coords += [center] # to avoid indexes out of bounds\n",
    "    else:    \n",
    "        # version with sequential targets\n",
    "        hand_coords = [center, targets[0],\n",
    "                       center, targets[1],\n",
    "                       center, targets[2],\n",
    "                       center, targets[3],\n",
    "                       center, targets[4],\n",
    "                       center, targets[5],\n",
    "                       center, targets[6],\n",
    "                       center, targets[7]]\n",
    "        hand_coords = n_rounds * hand_coords # many repetitions of the same sequence\n",
    "        hand_coords += [center] # to avoid indexes out of bounds\n",
    "        trg_ids = np.arange(len(hand_coords))%n_trgs # target for each presentation\n",
    "\n",
    "    SP = pops_dict['SP']\n",
    "    A = pops_dict['A']\n",
    "    P = pops_dict['P']\n",
    "    #### next is a copy-pasta of the code to set the SP values\n",
    "    # list with muscle lengths corresponding to the hand coordinates\n",
    "    m_lengths = []\n",
    "    for coord in hand_coords:\n",
    "        m_lengths.append(net.plants[P].coords_to_lengths(coord))\n",
    "    m_lengths = np.array(m_lengths)\n",
    "    #(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)\n",
    "    # We need to translate these lengths to corresponding SF activity levels.\n",
    "    # For that it is necessary to recreate all their transformations\n",
    "    # The first transformation is from length to II afferent activity.\n",
    "    ### OUT OF THE 36 AFFERENT SIGNALS, WE TAKE II ###\n",
    "    par = net.plants[P].m_params\n",
    "    # steady state tensions in the static and dynamic bag fibers (no gamma inputs)\n",
    "    Ts_ss = (par['k_se_s']/(par['k_se_s']+par['k_pe_s'])) * (\n",
    "             par['k_pe_s']*(m_lengths - par['l0_s']))\n",
    "    Td_ss = (par['k_se_d']/(par['k_se_d']+par['k_pe_d'])) * (\n",
    "             par['k_pe_d']*(m_lengths - par['l0_d']))\n",
    "    # steady state afferent outputs (no gamma inputs)\n",
    "    #Ia_ss = par['fs']*(Ts_ss/par['k_se_s']) + (1.-par['fs'])*(Td_ss/par['k_se_d'])\n",
    "    II_ss = par['se_II']*(Ts_ss/par['k_se_s']) + ((1.-par['se_II'])/par['k_pe_s'])*Ts_ss\n",
    "    #Ia_ss *= par['Ia_gain']\n",
    "    II_ss *= par['II_gain']\n",
    "    #Ia_II_ss = np.concatenate((Ia_ss, II_ss), axis=1)\n",
    "    # Next transformation is through the afferent units\n",
    "    P__A_ws = np.array(pds['P__A_syn']['init_w'][12:18])\n",
    "    #Ia_II_avgs = np.mean(Ia_II_ss, axis=0)  # when using hundreds of random targets\n",
    "    # target averages\n",
    "    A_thr = np.array([net.units[u].thresh for u in A[12:18]])\n",
    "    A_II = np.log(1. + np.maximum((II_ss)*P__A_ws - A_thr, 0.))\n",
    "    #(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)\n",
    "    # Next is from A to SF\n",
    "    SF_arg = pds['A__SF_syn']['init_w']*A_II\n",
    "    SF_params = pds['SF_params']\n",
    "    SF_out = 1./ (1. + np.exp(-SF_params['slope']*(SF_arg - SF_params['thresh'])))\n",
    "    SF_params['init_val'] = SF_out # this might cause a smooth start\n",
    "    # now we set the values in SP\n",
    "    #m_idxs = np.random.randint(len(hand_coords), size=1000) # index of all targets\n",
    "    m_idxs = list(range(len(hand_coords)+1)) # reach list targets sequentially\n",
    "        #m_idxs[0] = 0 # for testing\n",
    "    A_us = [net.units[u] for u in A]\n",
    "\n",
    "    def SF_sigmo(idx, arg):\n",
    "        \"\"\" The sigmoidal function for SF unit with index SF[idx]. \"\"\"\n",
    "        return 1./ (1. + np.exp(-SF_params['slope'][idx]*(arg - SF_params['thresh'][idx])))\n",
    "\n",
    "    def cur_target(t):\n",
    "        \"\"\" Returns the index of the target at time t. \"\"\"\n",
    "        return m_idxs[int(np.floor((t-start_t)/t_pres))]\n",
    "\n",
    "    def make_fun(idx):\n",
    "        \"\"\" create a function for the SP unit with index 'idx'. \"\"\"\n",
    "        return lambda t: SF_sigmo(idx, \n",
    "                            pds['A__SF_syn']['init_w'][idx] * (\n",
    "                            np.log(1. + max(II_ss[cur_target(t)][idx] * P__A_ws[idx] - \n",
    "                            net.units[A[12+idx]].thresh, 0.))))\n",
    "\n",
    "    for idx, u in enumerate(SP):\n",
    "        net.units[u].set_function(make_fun(idx))\n",
    "        \n",
    "    return hand_coords, targets, center, trg_ids, m_idxs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# A function that evaluates the fitness of a given configuration\n",
    "# Single run evaluation\n",
    "def eval_config(cfg):\n",
    "    \"\"\" Returns the error for a network with a given configuration.\n",
    "\n",
    "        Args:\n",
    "            cfg : a configuration dictionary.\n",
    "        Returns:\n",
    "            error : A float calculated from the sum of activities in the SPF layer.\n",
    "    \"\"\"\n",
    "    np.random.seed() # will try to get a seed from /dev/urandom\n",
    "    if cfg['n_evals'] > max_evals: # if the fitness has been evaluated \"enough\" times. See cell below...\n",
    "        return cfg['fitness']\n",
    "    t_pres = cfg['t_pres']\n",
    "    \n",
    "    # obtain a network with the given configuration\n",
    "    net, pops_dict, hand_coords, m_idxs, pds = net_from_cfg(cfg,\n",
    "                                                       t_pres = t_pres,\n",
    "                                                       par_heter = cfg['par_heter'],\n",
    "                                                       set_C_delay = False,\n",
    "                                                       rand_targets = rand_targets,\n",
    "                                                       track_weights = False,\n",
    "                                                       track_ips = False,\n",
    "                                                       C_noise = C_noise,\n",
    "                                                       M__C_rand_w = M__C_rand_w,\n",
    "                                                       M_noise = M_noise,\n",
    "                                                       rga_on_M = rga_on_M,\n",
    "                                                       rdc_on_M = False,\n",
    "                                                       rot_SPF = False,\n",
    "                                                       M__M_conns = M__M_conns,\n",
    "                                                       old_M__C = old_M__C)\n",
    "    # run the network\n",
    "    run_time = 5 #2. * 5. * 12 * t_pres #400 # 1000.\n",
    "    #start_time = time.time()\n",
    "    times, data, plant_data  = net.flat_run(run_time)\n",
    "    #print('Execution time is %s seconds' % (time.time() - start_time))\n",
    "\n",
    "    # calculate average error in last half of reaching\n",
    "    P = pops_dict['P']\n",
    "    arm_activs = plant_data[P]\n",
    "    plant = net.plants[P]\n",
    "    # modified copy-paste of plt.upd_ip_impl\n",
    "    q1 = arm_activs[:,0]\n",
    "    q2 = arm_activs[:,2]\n",
    "    q12 = q1+q2\n",
    "    c_elbow = np.array((plant.l_arm*np.cos(q1), plant.l_arm*np.sin(q1)))\n",
    "    c_hand = np.array((c_elbow[0] + plant.l_farm*np.cos(q12),\n",
    "                    c_elbow[1] + plant.l_farm*np.sin(q12))).transpose()\n",
    "    coord_idxs = np.floor(times/t_pres).astype(int)\n",
    "    des_coords = np.array(hand_coords)[m_idxs[coord_idxs],:] # desired coordinates at each moment in time\n",
    "\n",
    "    error_time = run_time - round(run_time/2.)\n",
    "    error_idx = int(round(error_time/net.min_delay))\n",
    "    hand_error = np.linalg.norm(c_hand-des_coords, axis=1)\n",
    "    hand_error_integ = hand_error[error_idx:].sum()\n",
    "    avg_hand_error = hand_error_integ / (hand_error.size - error_idx)\n",
    "\n",
    "    #return hand_error_integ\n",
    "    return avg_hand_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that evaluates the fitness of a given configuration\n",
    "# Double run evaluation\n",
    "def eval_config(cfg):\n",
    "    \"\"\" Returns the error for a network with a given configuration.\n",
    "\n",
    "        Args:\n",
    "            cfg : a configuration dictionary.\n",
    "        Returns:\n",
    "            error : A float calculated from the sum of activities in the SPF layer.\n",
    "    \"\"\"\n",
    "    np.random.seed() # will try to get a seed from /dev/urandom\n",
    "    if cfg['n_evals'] > max_evals: # if the fitness has been evaluated \"enough\" times. See cell below...\n",
    "        return cfg['fitness']\n",
    "    t_pres_l  = 40. # presentation time during initial learning\n",
    "    n_reaches_l = 12\n",
    "    r = .1 # distance from target to center during radial reaching\n",
    "    t_pres = 5. # presentation time during radial reaching\n",
    "    n_trgs = 8 # number of targets for radial reaching\n",
    "    n_rounds = 4 # number of times the n_trgs targets will be presented\n",
    "    \n",
    "    ad = {'new_noise': 0.,\n",
    "          'new_gain': 1. }\n",
    "    \n",
    "    #print('o')\n",
    "    # obtain a network with the given configuration\n",
    "    if not use_syne:\n",
    "        net, pops_dict, hand_coords, m_idxs, pds = net_from_cfg(cfg,\n",
    "                                                           t_pres = t_pres_l,\n",
    "                                                           par_heter = cfg['par_heter'],\n",
    "                                                           set_C_delay = False,\n",
    "                                                           rand_targets = rand_targets,\n",
    "                                                           track_weights = False,\n",
    "                                                           track_ips = False,\n",
    "                                                           C_noise = C_noise,\n",
    "                                                           M__C_rand_w = M__C_rand_w,\n",
    "                                                           M_noise = M_noise,\n",
    "                                                           rga_on_M = rga_on_M,\n",
    "                                                           rdc_on_M = False,\n",
    "                                                           rot_SPF = rot_SPF,\n",
    "                                                           M__M_conns = M__M_conns,\n",
    "                                                           old_M__C = old_M__C)\n",
    "    else:\n",
    "        net, pops_dict, hand_coords, m_idxs, pds = syne_net(cfg,\n",
    "                                                        t_pres = t_pres_l,\n",
    "                                                        par_heter = cfg['par_heter'],\n",
    "                                                        set_C_delay = False,\n",
    "                                                        rand_targets = rand_targets,\n",
    "                                                        track_weights = False,\n",
    "                                                        track_ips = False,\n",
    "                                                        C_noise = C_noise,\n",
    "                                                        M__C_rand_w = M__C_rand_w,\n",
    "                                                        M_noise = M_noise,\n",
    "                                                        rga_on_M = rga_on_M,\n",
    "                                                        rdc_on_M = False,\n",
    "                                                        rot_SPF = rot_SPF,\n",
    "                                                        M__M_conns = M__M_conns,\n",
    "                                                        old_M__C = old_M__C)\n",
    "    #print('+')\n",
    "    # run the network\n",
    "    run_time_l = t_pres_l * n_reaches_l #2. * 5. * 12 * t_pres #400 # 1000.\n",
    "    times_l, data_l, plant_data_l  = net.flat_run(run_time_l)\n",
    "    \n",
    "#     print('~')\n",
    "    # set new targets with the function\n",
    "    start_t = net.sim_time # starting time for new simulation\n",
    "    hand_coords, targets, center, trg_ids, m_idxs = set_new_targets(net, \n",
    "                                                              pops_dict,\n",
    "                                                                      r, \n",
    "                                                                 t_pres,\n",
    "                                                                 n_trgs, \n",
    "                                                                n_rounds,\n",
    "                                                                pds)\n",
    "    \n",
    "#     print('.')\n",
    "    # remove noise from C or M units\n",
    "    if use_syne:\n",
    "        for u in [net.units[c] for c in pops_dict['SYNE']+pops_dict['SYNI']]:\n",
    "            u.sigma = ad['new_noise']    \n",
    "    else:\n",
    "        for u in [net.units[c] for c in pops_dict['CE']+pops_dict['CI']]:\n",
    "            u.sigma = ad['new_noise']\n",
    "    if rga_on_M:\n",
    "        for u in [net.units[m] for m in pops_dict['M']]:\n",
    "            u.sigma = ad['new_noise']\n",
    "    \n",
    "    #print('-')\n",
    "    sim_time2 = 2 * t_pres * n_trgs * n_rounds\n",
    "    times, data, plant_data  = net.flat_run(sim_time2)\n",
    "    data = np.array(data)\n",
    "    \n",
    "#     print('$')\n",
    "    # calculate average error in last half of reaching\n",
    "    P = pops_dict['P']\n",
    "    arm_activs = plant_data[P]\n",
    "    plant = net.plants[P]\n",
    "    # modified copy-paste of plt.upd_ip_impl\n",
    "    q1 = arm_activs[:,0]\n",
    "    q2 = arm_activs[:,2]\n",
    "    q12 = q1+q2\n",
    "    c_elbow = np.array((plant.l_arm*np.cos(q1), plant.l_arm*np.sin(q1)))\n",
    "    c_hand = np.array((c_elbow[0] + plant.l_farm*np.cos(q12),\n",
    "                    c_elbow[1] + plant.l_farm*np.sin(q12))).transpose()\n",
    "        \n",
    "    coord_idxs = np.floor((times-start_t+1e-8)/t_pres).astype(int) # after resetting the targets\n",
    "    des_coords = np.array([hand_coords[idx] for idx in [m_idxs[cid] for cid in coord_idxs]])\n",
    "\n",
    "    error_time = sim_time2 - round(sim_time2/2.)\n",
    "    error_idx = int(round(error_time/net.min_delay))\n",
    "    hand_error = np.linalg.norm(c_hand-des_coords, axis=1)\n",
    "    hand_error_integ = hand_error[error_idx:].sum()\n",
    "    avg_hand_error = hand_error_integ / (hand_error.size - error_idx)\n",
    "\n",
    "    #return hand_error_integ\n",
    "    return avg_hand_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Genetic algorithm  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to produce offspring by crossing individuals\n",
    "par_names = list(ranges.keys()) #list(pop[0].keys()) # list with all parameter names\n",
    "\n",
    "def create_offspring(cfg1, cfg2, par_list=par_names):\n",
    "    \"\"\" Given 2 configurations, return 2 offspring from random swapping.\n",
    "    \n",
    "        To produce offspring, first we choose one split point in the\n",
    "        dictionary. The first offspring has the values of cfg1 up to that\n",
    "        point, and cfg2 afterwards. The second offspring has the cfg2 values\n",
    "        up to the split point, and cfg1 afterwards. Since the dictionaries are\n",
    "        not ordered, we use a parameter list to set the split point.\n",
    "    \n",
    "        Args:\n",
    "            cfg1, cfg2: parameter dictionaries\n",
    "            par_list: list with the keys in cfg1, cfg2 (unless focus_params)\n",
    "        Returns:\n",
    "            cfg3, cfg4: dictionaries from swapping values in cfg1, cfg2\n",
    "    \"\"\"\n",
    "    if focus_params:\n",
    "        par_list = main_pars\n",
    "    sp = np.random.randint(len(par_list))# split point as an index to par_list\n",
    "    cfg3 = cfg1.copy()\n",
    "    cfg4 = cfg2.copy()\n",
    "    for i in range(sp, len(par_list)):\n",
    "        cfg3[par_list[i]] = cfg2[par_list[i]]\n",
    "        cfg4[par_list[i]] = cfg1[par_list[i]]\n",
    "    return cfg3, cfg4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n",
      "/home/z/projects/draculab/requirements/requirements.py:1456: UserWarning: setting the 0 value for the acc_slow reset port\n",
      "  warn('setting the 0 value for the acc_slow reset port')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 evaluated. Best fitness: 0.031\n",
      "Mean fitness = 0.268\n",
      "to replace: [67, 78, 62, 23, 13, 82, 88, 87, 41, 81, 83, 72, 54, 80, 24, 74, 4, 84, 79, 73, 12, 55, 86, 66, 65, 77, 68, 34, 26, 64]\n",
      "to mutate: [82, 71, 84, 53, 81, 68, 50, 86]\n",
      "generation 0 finished in 16709.902908802032 seconds\n",
      "Generation 1 evaluated. Best fitness: 0.031\n",
      "Mean fitness = 0.223\n",
      "to replace: [81, 78, 76, 83, 85, 58, 88, 31, 80, 71, 57, 72, 42, 89, 87, 86, 23, 46, 75, 82, 43, 52, 69, 74, 68, 63, 55, 33, 66, 79]\n",
      "to mutate: [73, 83, 72, 88, 55, 45, 76, 24]\n",
      "generation 1 finished in 16686.057859897614 seconds\n",
      "Generation 2 evaluated. Best fitness: 0.032\n",
      "Mean fitness = 0.169\n",
      "to replace: [73, 88, 69, 78, 74, 87, 68, 75, 61, 57, 80, 59, 11, 81, 56, 82, 58, 49, 79, 25, 89, 76, 48, 70, 86, 65, 72, 67, 43, 83]\n",
      "to mutate: [88, 89, 30, 87, 60, 63, 37, 69]\n",
      "generation 2 finished in 16671.6106235981 seconds\n",
      "Generation 3 evaluated. Best fitness: 0.031\n",
      "Mean fitness = 0.137\n",
      "to replace: [88, 43, 71, 77, 40, 80, 47, 83, 76, 69, 31, 85, 74, 67, 36, 75, 27, 22, 38, 87, 89, 86, 81, 7, 42, 73, 10, 28, 82, 53]\n",
      "to mutate: [73, 82, 89, 76, 78, 48, 75, 47]\n",
      "generation 3 finished in 16863.084345579147 seconds\n",
      "Generation 4 evaluated. Best fitness: 0.030\n",
      "Mean fitness = 0.099\n",
      "to replace: [85, 87, 84, 82, 86, 78, 88, 22, 53, 76, 89, 47, 80, 49, 68, 18, 62, 74, 40, 19, 73, 79, 54, 83, 70, 25, 42, 33, 24, 6]\n",
      "to mutate: [58, 89, 74, 75, 42, 69, 84, 66]\n",
      "generation 4 finished in 16863.25782227516 seconds\n",
      "Generation 5 evaluated. Best fitness: 0.029\n",
      "Mean fitness = 0.081\n",
      "to replace: [89, 66, 85, 74, 86, 35, 80, 87, 61, 70, 64, 88, 69, 13, 84, 77, 67, 46, 60, 81, 57, 78, 10, 50, 30, 73, 83, 76, 39, 58]\n",
      "to mutate: [62, 88, 19, 72, 51, 61, 69, 85]\n",
      "generation 5 finished in 16781.52477788925 seconds\n",
      "Generation 6 evaluated. Best fitness: 0.031\n",
      "Mean fitness = 0.071\n",
      "to replace: [13, 52, 82, 86, 77, 40, 44, 89, 70, 30, 72, 43, 20, 57, 78, 83, 16, 69, 45, 87, 85, 58, 74, 34, 22, 59, 80, 29, 71, 76]\n",
      "to mutate: [85, 63, 83, 89, 67, 77, 88, 47]\n",
      "generation 6 finished in 16845.0024228096 seconds\n",
      "Generation 7 evaluated. Best fitness: 0.031\n",
      "Mean fitness = 0.054\n",
      "to replace: [6, 71, 19, 87, 80, 84, 50, 41, 60, 29, 85, 30, 69, 54, 88, 68, 81, 49, 52, 31, 75, 45, 42, 86, 8, 83, 37, 43, 12, 63]\n",
      "to mutate: [36, 86, 43, 62, 87, 59, 55, 74]\n",
      "generation 7 finished in 16865.845138549805 seconds\n",
      "Generation 8 evaluated. Best fitness: 0.026\n",
      "Mean fitness = 0.081\n",
      "to replace: [88, 21, 84, 87, 82, 89, 86, 85, 67, 83, 59, 18, 77, 29, 66, 39, 22, 63, 51, 47, 55, 70, 75, 71, 79, 32, 76, 36, 68, 26]\n",
      "to mutate: [88, 56, 63, 60, 89, 59, 44, 54]\n",
      "generation 8 finished in 16821.89350271225 seconds\n",
      "Generation 9 evaluated. Best fitness: 0.024\n",
      "Mean fitness = 0.053\n",
      "to replace: [31, 88, 86, 83, 82, 20, 44, 89, 45, 87, 26, 84, 39, 77, 78, 56, 70, 52, 11, 64, 72, 79, 14, 19, 65, 36, 76, 74, 21, 4]\n",
      "to mutate: [34, 52, 70, 61, 44, 73, 74, 66]\n",
      "generation 9 finished in 16725.753273010254 seconds\n",
      "Generation 10 evaluated. Best fitness: 0.027\n",
      "Mean fitness = 0.090\n",
      "to replace: [89, 87, 62, 84, 34, 86, 78, 70, 53, 30, 29, 74, 88, 83, 16, 42, 82, 22, 27, 81, 85, 66, 72, 47, 76, 50, 79, 75, 24, 65]\n",
      "to mutate: [75, 63, 86, 89, 80, 27, 88, 77]\n",
      "generation 10 finished in 16584.811348199844 seconds\n",
      "Generation 11 evaluated. Best fitness: 0.026\n",
      "Mean fitness = 0.064\n",
      "to replace: [89, 88, 84, 46, 68, 54, 83, 55, 86, 87, 57, 22, 80, 75, 77, 23, 4, 14, 6, 10, 72, 81, 8, 9, 43, 26, 79, 24, 61, 27]\n",
      "to mutate: [31, 65, 46, 54, 84, 85, 63, 52]\n",
      "generation 11 finished in 16720.472938537598 seconds\n",
      "Generation 12 evaluated. Best fitness: 0.026\n",
      "Mean fitness = 0.044\n",
      "to replace: [86, 11, 6, 51, 89, 83, 50, 70, 19, 18, 53, 49, 52, 40, 57, 88, 41, 81, 71, 72, 79, 36, 58, 42, 65, 78, 74, 33, 39, 12]\n",
      "to mutate: [75, 77, 84, 33, 28, 59, 71, 73]\n",
      "generation 12 finished in 16272.36116027832 seconds\n",
      "Generation 13 evaluated. Best fitness: 0.025\n",
      "Mean fitness = 0.035\n",
      "to replace: [73, 27, 59, 80, 17, 53, 64, 86, 46, 49, 82, 19, 69, 76, 67, 58, 10, 60, 66, 4, 88, 84, 55, 77, 35, 47, 57, 24, 85, 78]\n",
      "to mutate: [39, 48, 44, 25, 55, 87, 70, 69]\n",
      "generation 13 finished in 16043.02535867691 seconds\n",
      "Generation 14 evaluated. Best fitness: 0.026\n",
      "Mean fitness = 0.049\n",
      "to replace: [88, 41, 86, 89, 49, 22, 6, 48, 77, 14, 87, 36, 80, 7, 71, 50, 10, 19, 37, 83, 85, 45, 75, 13, 82, 69, 72, 65, 74, 31]\n",
      "to mutate: [54, 30, 78, 84, 11, 89, 80, 75]\n",
      "generation 14 finished in 16176.110131025314 seconds\n",
      "Generation 15 evaluated. Best fitness: 0.025\n",
      "Mean fitness = 0.045\n",
      "to replace: [62, 89, 86, 5, 74, 7, 42, 15, 76, 32, 81, 56, 44, 71, 22, 21, 36, 47, 54, 87, 29, 12, 60, 24, 61, 23, 41, 85, 88, 31]\n",
      "to mutate: [66, 87, 29, 33, 81, 21, 84, 75]\n",
      "generation 15 finished in 16382.737890720367 seconds\n",
      "Generation 16 evaluated. Best fitness: 0.023\n",
      "Mean fitness = 0.036\n",
      "to replace: [86, 44, 56, 15, 80, 60, 88, 66, 47, 79, 73, 62, 27, 6, 16, 59, 54, 14, 26, 40, 89, 43, 23, 7, 9, 50, 51, 37, 63, 74]\n",
      "to mutate: [50, 63, 87, 84, 49, 13, 72, 64]\n",
      "generation 16 finished in 16214.10110783577 seconds\n",
      "Generation 17 evaluated. Best fitness: 0.023\n",
      "Mean fitness = 0.040\n",
      "to replace: [80, 64, 52, 82, 81, 28, 89, 75, 65, 87, 19, 73, 68, 79, 62, 51, 88, 30, 40, 71, 5, 56, 26, 48, 49, 69, 32, 47, 10, 58]\n",
      "to mutate: [85, 53, 80, 57, 79, 81, 60, 38]\n",
      "generation 17 finished in 16127.642005443573 seconds\n",
      "Generation 18 evaluated. Best fitness: 0.024\n",
      "Mean fitness = 0.039\n",
      "to replace: [25, 57, 21, 89, 87, 27, 7, 88, 33, 80, 45, 43, 20, 86, 59, 81, 76, 84, 83, 75, 8, 37, 73, 58, 72, 31, 15, 17, 9, 18]\n",
      "to mutate: [85, 34, 79, 72, 67, 47, 58, 77]\n",
      "generation 18 finished in 16499.92615199089 seconds\n",
      "Generation 19 evaluated. Best fitness: 0.024\n",
      "Mean fitness = 0.040\n",
      "to replace: [89, 70, 84, 86, 87, 48, 40, 26, 76, 62, 32, 38, 82, 60, 51, 34, 20, 83, 58, 65, 24, 77, 46, 52, 21, 78, 15, 61, 6, 12]\n",
      "to mutate: [22, 64, 76, 85, 77, 74, 82, 81]\n",
      "generation 19 finished in 16202.893777370453 seconds\n",
      "Generation 20 evaluated. Best fitness: 0.023\n",
      "Mean fitness = 0.031\n",
      "to replace: [60, 86, 29, 13, 43, 49, 82, 4, 87, 79, 47, 54, 74, 16, 57, 75, 9, 23, 10, 42, 33, 34, 66, 77, 72, 25, 51, 15, 88, 28]\n",
      "to mutate: [55, 89, 75, 53, 81, 88, 64, 63]\n",
      "generation 20 finished in 16010.512104511261 seconds\n",
      "Generation 21 evaluated. Best fitness: 0.024\n",
      "Mean fitness = 0.032\n",
      "to replace: [68, 84, 11, 75, 12, 83, 54, 64, 31, 30, 15, 65, 38, 71, 66, 87, 89, 61, 62, 23, 37, 46, 18, 52, 53, 47, 42, 34, 86, 78]\n",
      "to mutate: [56, 75, 69, 44, 82, 23, 63, 77]\n",
      "generation 21 finished in 16252.612731933594 seconds\n",
      "Generation 22 evaluated. Best fitness: 0.021\n",
      "Mean fitness = 0.037\n",
      "to replace: [75, 62, 26, 70, 37, 7, 87, 12, 77, 69, 19, 55, 48, 89, 53, 72, 52, 86, 25, 8, 83, 15, 51, 79, 74, 85, 34, 76, 63, 22]\n",
      "to mutate: [38, 76, 44, 71, 64, 86, 89, 72]\n",
      "generation 22 finished in 16355.945400238037 seconds\n",
      "Generation 23 evaluated. Best fitness: 0.023\n",
      "Mean fitness = 0.051\n",
      "to replace: [40, 10, 39, 33, 89, 81, 70, 77, 60, 24, 86, 87, 8, 85, 44, 21, 13, 47, 88, 25, 71, 46, 76, 83, 48, 15, 84, 54, 19, 5]\n",
      "to mutate: [29, 58, 32, 72, 40, 87, 65, 83]\n",
      "generation 23 finished in 16733.42679834366 seconds\n",
      "Generation 24 evaluated. Best fitness: 0.023\n",
      "Mean fitness = 0.036\n",
      "to replace: [45, 28, 24, 84, 87, 81, 68, 58, 22, 17, 33, 62, 85, 89, 20, 19, 73, 42, 86, 72, 54, 61, 55, 88, 30, 78, 74, 59, 6, 57]\n",
      "to mutate: [60, 48, 84, 71, 22, 63, 88, 85]\n",
      "generation 24 finished in 16715.283356904984 seconds\n",
      "Generation 25 evaluated. Best fitness: 0.023\n",
      "Mean fitness = 0.039\n",
      "to replace: [22, 47, 59, 89, 81, 8, 68, 25, 18, 44, 72, 70, 46, 41, 86, 56, 78, 88, 65, 64, 84, 13, 82, 38, 31, 63, 74, 54, 35, 69]\n",
      "to mutate: [75, 77, 69, 18, 68, 74, 61, 50]\n",
      "generation 25 finished in 16034.472798347473 seconds\n",
      "Generation 26 evaluated. Best fitness: 0.023\n",
      "Mean fitness = 0.034\n",
      "to replace: [7, 89, 11, 76, 33, 68, 50, 26, 64, 67, 69, 86, 82, 78, 15, 24, 84, 5, 52, 87, 70, 18, 36, 9, 31, 44, 40, 88, 80, 74]\n",
      "to mutate: [88, 51, 89, 63, 19, 39, 77, 64]\n",
      "generation 26 finished in 13632.611848592758 seconds\n",
      "Generation 27 evaluated. Best fitness: 0.024\n",
      "Mean fitness = 0.036\n",
      "to replace: [89, 52, 62, 66, 61, 68, 64, 47, 82, 65, 71, 63, 55, 86, 28, 85, 88, 21, 19, 36, 80, 8, 24, 87, 50, 35, 26, 33, 49, 70]\n",
      "to mutate: [79, 43, 77, 66, 62, 67, 65, 87]\n",
      "generation 27 finished in 13466.825277328491 seconds\n",
      "Generation 28 evaluated. Best fitness: 0.021\n",
      "Mean fitness = 0.036\n",
      "to replace: [48, 87, 89, 55, 4, 74, 41, 16, 67, 70, 52, 75, 79, 80, 81, 88, 7, 45, 54, 83, 9, 62, 66, 46, 18, 36, 60, 33, 6, 51]\n",
      "to mutate: [73, 65, 75, 44, 21, 41, 8, 82]\n",
      "generation 28 finished in 10879.210871696472 seconds\n",
      "Generation 29 evaluated. Best fitness: 0.022\n",
      "Mean fitness = 0.033\n",
      "to replace: [89, 83, 87, 60, 20, 38, 75, 5, 86, 71, 42, 14, 17, 78, 27, 19, 76, 88, 63, 79, 26, 51, 56, 82, 10, 32, 18, 6, 74, 84]\n",
      "to mutate: [42, 67, 52, 87, 70, 75, 58, 29]\n",
      "generation 29 finished in 10891.301952123642 seconds\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "###### The genetic algorithm ######\n",
    "####################################\n",
    "\n",
    "#pop = pop[0:15] # limit pop size for debugging\n",
    "n_mates = 30 # number of individuals to mate at each generation (even number)\n",
    "max_gens = 30 # maximum number of generations\n",
    "n_soft_mut = 10 # number of individuals to soft-mutate per generation\n",
    "r_soft_mut = 0.2 # relative amplitude of soft mutations\n",
    "n_mut = 8 #number of individuals to mutate per generation\n",
    "n_procs = 15 # number of processes to use for fitness evaluation\n",
    "n_save = 3 #number of individuals to protect from replacement and mutation\n",
    "use_pso = False # whether to insert configurations from the PSO algorithm\n",
    "repl_num = 8 #how many individuals to replace with PSO configurations\n",
    "\n",
    "# setting name for file where parameters will be stored\n",
    "path = \"/home/z/Dropbox (OIST)/saves/\"\n",
    "#path = \"/home/z/projects/draculab/saves/\"\n",
    "fname1 = \"gene\"\n",
    "fname2 = datetime.now().strftime('%Y-%m-%d')\n",
    "fname = path + fname1 + \"_\" + fname2\n",
    "\n",
    "pop_len = len(pop)\n",
    "\n",
    "for gen in range(max_gens):\n",
    "    start_time = time.time()\n",
    "    # 1) Evaluate fitness\n",
    "    # 1.1) Do the evaluation\n",
    "    ######### Single process version\n",
    "    #fits = list(map(eval_config, pop))\n",
    "    ######## parallel version, python multiprocessing module\n",
    "#     with Pool(n_procs) as p:\n",
    "#         fits = list(p.map(eval_config, pop))\n",
    "#         p.close()\n",
    "#         p.join()\n",
    "    ######## parallel version, pathos\n",
    "    with ProcessingPool(n_procs) as p:\n",
    "        fits = list(p.map(eval_config, pop))\n",
    "    #print(fits)\n",
    "    # 1.2) update the average fitness values\n",
    "    for idx, cfg in enumerate(pop):\n",
    "        nr = cfg['n_evals'] # n_evals is not updated yet...\n",
    "        #print(nr)\n",
    "        #print(fits[idx])\n",
    "        #print(cfg['fitness'])\n",
    "        if nr > 0:\n",
    "            if nr <= max_evals:\n",
    "                cfg['fitness'] = (cfg['fitness']*nr + fits[idx])/(nr+1)\n",
    "        else:\n",
    "            cfg['fitness'] = fits[idx]\n",
    "        cfg['n_evals'] = cfg['n_evals'] + 1\n",
    "    #---------------------------------------------------------------------------------\n",
    "    # 1.3) Inserting configurations from the PSO algorithm\n",
    "    if use_pso:\n",
    "        pso_name = path + \"pso_\" + fname2\n",
    "        try:\n",
    "            with open(pso_name, 'rb') as f:\n",
    "                pso_pop = pickle.load(f)\n",
    "                f.close()\n",
    "            pop[-repl_num:] = pso_pop[:repl_num]\n",
    "            ext_pop = pop + pso_pop[repl_num:]\n",
    "            print(\"Mixed pso and gene pops!!!\")\n",
    "        except IOError:\n",
    "            if gen > 2: # if the pso algorithm should likely be done\n",
    "                from warnings import warn\n",
    "                warn('population ' + pso_name + 'could not be imported',\n",
    "                     UserWarning)\n",
    "            ext_pop = pop\n",
    "    #---------------------------------------------------------------------------------\n",
    "    # 2) Sort according to fitness. Lowest error first.\n",
    "    if use_pso:\n",
    "        pop = sorted(ext_pop, key=lambda d: d['fitness'])[:pop_len]\n",
    "    else:\n",
    "        pop = sorted(pop, key=lambda d: d['fitness'])\n",
    "    # 2.1) Save current generation\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(pop, f)\n",
    "        f.close()\n",
    "    # 2.2) A quick message\n",
    "    print(\"Generation %d evaluated. Best fitness: %.3f\"%(gen,pop[0]['fitness']))\n",
    "    print(\"Mean fitness = %.3f\"%(np.mean(np.array(fits))))\n",
    "    # 2.3) If best fitness good enough, break\n",
    "    if pop[0]['fitness'] < target_fitness:\n",
    "        print(\"Good enough parameters found. Stopping search.\")\n",
    "        break\n",
    "    # 3) mate and replace\n",
    "    # 3.1) Select individuals to be replaced with probability proportional to error\n",
    "    fits.sort() # sort the fitnesses (now in the same order as pop)\n",
    "    fits = np.array(fits)\n",
    "    fits = fits/fits.sum() # normalize fitnesses so they add to 1\n",
    "    cumsum_fits = fits[:] # cumsum_fits[i] = sum(fits[:i])\n",
    "    for i in range(1,len(cumsum_fits)):\n",
    "        cumsum_fits[i] = cumsum_fits[i-1] + cumsum_fits[i]\n",
    "    repl_list = [] # list with indexes of individuals to be replaced\n",
    "    while len(repl_list) < n_mates:\n",
    "        min_r = cumsum_fits[n_save] # don't replace the first n_save individuals\n",
    "        r = min_r + (1.-min_r) * np.random.random()\n",
    "        candidate = n_save\n",
    "        for i in range(n_save, len(fits)):\n",
    "            if cumsum_fits[i] > r:\n",
    "                break\n",
    "            candidate += 1\n",
    "        if candidate in repl_list:\n",
    "            continue\n",
    "        else:\n",
    "            repl_list.append(candidate)\n",
    "    print(\"to replace: \", end='')\n",
    "    print(repl_list)\n",
    "    # 3.2) Arrange individuals in random pairs\n",
    "    perm = np.random.permutation(n_mates) # this will do \n",
    "    # 3.3) mate\n",
    "    new_pops = []\n",
    "    for i in range(int(np.floor(n_mates/2))):\n",
    "        off1, off2 = create_offspring(pop[perm[2*i]], pop[perm[2*i+1]])\n",
    "        new_pops.append(off1)\n",
    "        new_pops.append(off2)\n",
    "    # 3.4) replace\n",
    "    for i, cfg in enumerate(new_pops):\n",
    "        pop[repl_list[i]] = cfg\n",
    "    # 4) mutate\n",
    "    # 4.1) soft mutations\n",
    "    for _ in range(n_soft_mut):\n",
    "        idx = np.random.randint(len(pop))\n",
    "        if idx < n_save:\n",
    "            copy = pop[idx].copy()\n",
    "            soft_mutate(copy, r_soft_mut)\n",
    "            pop[-idx-1] = copy\n",
    "            pop[-idx-1]['fitness'] = None\n",
    "            pop[-idx-1]['n_evals'] = 0\n",
    "        else:\n",
    "            soft_mutate(pop[idx], r_soft_mut)\n",
    "            pop[idx]['fitness'] = None\n",
    "            pop[idx]['n_evals'] = 0\n",
    "    # 4.2) mutations\n",
    "    # 4.2.1) select individuals to mutate\n",
    "    # sq_fits = fits*fits\n",
    "    #cumsum_sq_fits = fits * fits # cumsum_sq_fits[i] = sum(sq_fits[:i])\n",
    "    cumsum_sq_fits = fits # proportional to fits, rather than its square\n",
    "    cumsum_sq_fits = cumsum_sq_fits / cumsum_sq_fits.sum()\n",
    "    for i in range(1,len(cumsum_sq_fits)):\n",
    "        cumsum_sq_fits[i] = cumsum_sq_fits[i-1] + cumsum_sq_fits[i]\n",
    "    mut_list = [] # list with indexes of individuals to be mutate\n",
    "    while len(mut_list) < n_mut:\n",
    "        r = np.random.random()\n",
    "        candidate = 0\n",
    "        for i in range(len(fits)):\n",
    "            if cumsum_sq_fits[i] > r:\n",
    "                break\n",
    "            candidate += 1\n",
    "        if candidate in mut_list:\n",
    "            continue\n",
    "        else:\n",
    "            mut_list.append(candidate)\n",
    "    print(\"to mutate: \", end='')\n",
    "    print(mut_list)\n",
    "    for idx in mut_list:\n",
    "        if idx < n_save:\n",
    "            copy = pop[idx].copy()\n",
    "            mutate(copy)\n",
    "            pop[-idx-1] = copy\n",
    "            pop[-idx-1]['fitness'] = None\n",
    "            pop[-idx-1]['n_evals'] = 0\n",
    "        else:\n",
    "            mutate(pop[idx])\n",
    "            pop[idx]['fitness'] = None\n",
    "            pop[idx]['n_evals'] = 0\n",
    "            \n",
    "    print('generation %d finished in %s seconds' % (gen, time.time() - start_time))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Particle Swarm Optimization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for the PSO algorithm\n",
    "# These methods assume that 'par_list' and 'ranges' have been defined.\n",
    "ref_cfg = pop[0] # a configuration with all values, including those that\n",
    "                 # are not in par_list\n",
    "    \n",
    "def add_to_cfg(cfg, vel):\n",
    "    \"\"\" Add a vector to the values of a configuration.\n",
    "    \n",
    "        Args:\n",
    "            cfg : a configuration dictionary\n",
    "            vel : Numpy array of values to be added\n",
    "            \n",
    "        The values in 'vel' are in the order of 'par_list'.\n",
    "        Each entry in vel is a value in the [-mv, mv] interval, where mv\n",
    "        is a parameter indicating the maximum velocity.\n",
    "        \n",
    "        For each parameter 'par_name' in 'par_list', the corresponding\n",
    "        value in vel will be multiplied times\n",
    "        (ranges[par_name]['high'] - ranges[par_name]['low'])\n",
    "        before being added.\n",
    "        \n",
    "        If a value exceeds the limits set in 'ranges' it will be clipped.\n",
    "        After updating cfg, its 'fitness' and 'n_evals' entries will be\n",
    "        reset to their initial values.\n",
    "    \"\"\"\n",
    "    for idx, name in enumerate(par_list):\n",
    "        cfg[name] += vel[idx] * (\n",
    "                       ranges[name]['high'] - ranges[name]['low'])\n",
    "        cfg[name] = max( min(ranges[name]['high'], cfg[name]),\n",
    "                           ranges[name]['low'])\n",
    "    cfg['fitness'] = None\n",
    "    cfg['n_evals'] = 0\n",
    "        \n",
    "def add_vel(vel, acc, mv=0.5):\n",
    "    \"\"\" Add an acceleration to a velocity vector.\n",
    "    \n",
    "        Args:\n",
    "            vel : velocity vector (numpy array).\n",
    "            acc : acceleration vector (numpy array).\n",
    "            mv : maximum velocity.\n",
    "        Returns:\n",
    "            vel + acc\n",
    "            \n",
    "        The entries of 'vel' and 'acc' are in the order of 'par_list'.\n",
    "        If vel[i] + acc[i] > mv, or vel[i] + acc[i] < -mv, values will be\n",
    "        clipped.\n",
    "    \"\"\"\n",
    "    return np.maximum(np.minimum(vel + acc, mv), -mv)\n",
    "    \n",
    "def cfg_to_vec(cfg):\n",
    "    \"\"\" Convert a configuration dictionary to a vector.\n",
    "    \n",
    "        Args:\n",
    "            cfg: configuration dictionary.\n",
    "        Returns:\n",
    "            vec: a numpy array with the values of the configuration.\n",
    "            \n",
    "        The order of the values in 'vec' is that of 'par_list'.\n",
    "        The 'cfg' entries for 'fitness', 'n_evals', 't_pres', and\n",
    "        'par_heter' will be omitted in 'vec'.\n",
    "    \"\"\"\n",
    "    vec = np.zeros(len(par_list))\n",
    "    for idx, name in enumerate(par_list):\n",
    "        vec[idx] = cfg[name]\n",
    "    return vec\n",
    "\n",
    "def vec_to_cfg(vec, fitness=None, n_evals=0, t_pres=None, par_heter=0.01):\n",
    "    \"\"\" Convert a vector to a configuration dictionary.\n",
    "    \n",
    "        Args:\n",
    "            vec: array-like with the values for the configuration.\n",
    "            'fitness', 'n_evals', 't_pres', 'par_heter': values not present\n",
    "                in 'vec' that will be appendend to the configuration dict.\n",
    "        Returns:\n",
    "            cfg: a configuration dictionary with the values in vec.\n",
    "            \n",
    "        The order of the values in vec should be that of 'par_list'.\n",
    "    \"\"\"\n",
    "    cfg = ref_cfg\n",
    "    for val, name in zip(vec, par_list):\n",
    "        cfg[name] = val\n",
    "    cfg['fitness'] = fitness\n",
    "    cfg['n_evals'] = n_evals\n",
    "    cfg['t_pres'] = t_pres\n",
    "    cfg['par_heter'] = par_heter\n",
    "    return cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "###### The PSO algorithm ######\n",
    "###############################\n",
    "\n",
    "W = 0.3 # inertia weight\n",
    "c1 = 0.5 # weight of accel towards personal best\n",
    "c2 = 0.2 # weight of accel towards global best\n",
    "mv = 0.3 # maximum velocity (relative to range witdth of paramter)\n",
    "\n",
    "use_gene = True # insert particles from a concomitant genetic algorithm\n",
    "sig = lambda f: 1./(1. + np.exp(-4.*(f + 0.1))) # to set probability of insertion\n",
    "\n",
    "max_iters = 15 # maximum number of iterations\n",
    "n_procs = 15 # number of processes to use for fitness evaluation\n",
    "\n",
    "g_best_f = 1e10 # best fitness so far\n",
    "p_best_fs = [1e10] * len(pop) # best personal fitnesses\n",
    "t_pres = pop[0]['t_pres'] # assuming all presentation times are equal\n",
    "vels = np.random.random((len(pop), len(par_list))) - 0.5 # initial velocities\n",
    "\n",
    "g_best = cfg_to_vec(pop[0]) # arbitrary initialization of global best\n",
    "p_bests = np.zeros((len(pop), len(par_list)))\n",
    "for idx, cfg in enumerate(pop):\n",
    "    p_bests[idx,:] = cfg_to_vec(cfg)\n",
    "\n",
    "# setting name for file where parameters will be stored\n",
    "#path = \"/home/z/projects/draculab/saves/\"\n",
    "path = \"/home/z/Dropbox (OIST)/saves/\"\n",
    "fname1 = \"pso\"\n",
    "fname2 = datetime.now().strftime('%Y-%m-%d')\n",
    "fname = path + fname1 + \"_\" + fname2\n",
    "\n",
    "for itr in range(max_iters):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 1) Evaluate fitness\n",
    "    # 1.1) Do the evaluation\n",
    "    ######### Single process version\n",
    "    #fits = list(map(eval_config, pop))\n",
    "        ######## parallel version, multiprocessing module\n",
    "#     with Pool(n_procs) as p:\n",
    "#         fits = list(p.map(eval_config, pop))\n",
    "#         p.close()\n",
    "#         p.join()\n",
    "    ######## parallel version, pathos\n",
    "    with ProcessingPool(n_procs) as p:\n",
    "        fits = list(p.map(eval_config, pop))\n",
    "    #print(fits)\n",
    "    # 1.2) update the average fitness values\n",
    "    # In PSO configurations change every iteration, so n_evals is \n",
    "    # either 0 or 1. However, some configuration may have come from the\n",
    "    # genetic algorithm, so we consider the case n_evals > 0\n",
    "    for idx, cfg in enumerate(pop):\n",
    "        nr = cfg['n_evals'] # n_evals is not updated yet...\n",
    "        if nr > 0:\n",
    "            if nr <= max_evals: \n",
    "                cfg['fitness'] = (cfg['fitness']*nr + fits[idx])/(nr+1)\n",
    "        else:\n",
    "            cfg['fitness'] = fits[idx]\n",
    "        cfg['n_evals'] = cfg['n_evals'] + 1\n",
    "        \n",
    "    # 2) Find indexes that sort according to fitness. Lowest error first.\n",
    "    srt_idx = np.argsort(fits)\n",
    "    \n",
    "    # 3.1) Update g_best\n",
    "    if fits[srt_idx[0]] < g_best_f:\n",
    "        g_best_f = fits[srt_idx[0]]\n",
    "        g_best = cfg_to_vec(pop[srt_idx[0]])\n",
    "        \n",
    "    for idx, cfg in enumerate(pop):\n",
    "        cfg_vec = cfg_to_vec(cfg)\n",
    "        # 3.2) Update p_bests\n",
    "        if cfg['fitness'] < p_best_fs[idx]:\n",
    "            p_best_fs[idx] = cfg['fitness']\n",
    "            p_bests[idx] = cfg_vec\n",
    "            \n",
    "        # 4) Update velocities\n",
    "        r1, r2 = np.random.random(2)\n",
    "        vels[idx] = add_vel(W * vels[idx], c1 * r1 * (p_bests[idx] - cfg_vec))\n",
    "        vels[idx] = add_vel(vels[idx], c2 * r2 * (g_best - cfg_vec))\n",
    "    \n",
    "    # 5) Save current iteration\n",
    "    best_pop = [vec_to_cfg(g_best, fitness=g_best_f, n_evals=1, t_pres=t_pres)] + pop\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(best_pop, f)\n",
    "        f.close()\n",
    "    \n",
    "    # A quick message\n",
    "    print(\"Iteration %d evaluated. Best fitness: %.3f\"%(itr, g_best_f))\n",
    "    print(\"Mean fitness = %.3f\"%(np.mean(np.array(fits))))\n",
    "    # 2.3) If best fitness good enough, break\n",
    "    if g_best_f < target_fitness:\n",
    "        print(\"Good enough parameters found. Stopping search.\")\n",
    "        break\n",
    "    \n",
    "    # 6) Update particles\n",
    "    for idx, cfg in enumerate(pop):\n",
    "        add_to_cfg(cfg, vels[idx])\n",
    "        \n",
    "    #---------------------------------------------------------------------------------\n",
    "    # 7) Inserting a configuration from the genetic algorithm\n",
    "    if use_gene:\n",
    "        g_name = path + \"gene_\" + fname2\n",
    "        try:\n",
    "            with open(g_name, 'rb') as f:\n",
    "                gene_pop = pickle.load(f)\n",
    "                f.close()\n",
    "            gene_cfg = gene_pop[0]\n",
    "            in_prob = sig(g_best_f - gene_cfg['fitness']) # insertion probability\n",
    "            if np.random.random() < in_prob:\n",
    "                rem_idx = np.random.randint(len(pop))\n",
    "                pop[rem_idx] = gene_cfg\n",
    "                fits[rem_idx] = gene_cfg['fitness']\n",
    "                print(\"inserted pop \" + str(rem_idx) + \"!!!\")    \n",
    "        except IOError:\n",
    "            if itr > 2: # if the genetic algorithm should likely be done\n",
    "                from warnings import warn\n",
    "                warn('population ' + g_name + 'could not be imported',\n",
    "                     UserWarning)\n",
    "                \n",
    "    print('Iteration %d finished in %s seconds' % (itr, time.time() - start_time))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print final population\n",
    "for dic in pop[:5]:\n",
    "    print('{',end='')\n",
    "    for name in dic.keys():\n",
    "        if name != 'fitness' or dic['fitness'] != None:\n",
    "            print(\"\\'%s\\':%.2f, \" % (name, dic[name]), end='')\n",
    "    print('}\\n')\n",
    "\n",
    "pop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final population\n",
    "fname = \"v3_nst_afx_pop\"\n",
    "fname += \"_\" + datetime.now().strftime('%Y-%m-%d__%H_%M')\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(pop, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved population\n",
    "import pickle\n",
    "fname = 'v3_nst_afx_pop'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    results = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a configuation\n",
    "cfg_id = 0 # index in the population for the configuration\n",
    "net, pops_dict, hand_coords, m_idxs, t_pres, _  = net_from_cfg(pop[cfg_id])\n",
    "pops_names = ['SF', 'SP', 'SPF', 'AL', 'AF', 'SP_CHG', 'CE', 'CI', 'M', 'ACT', 'P']\n",
    "for name in pops_names:\n",
    "    exec(\"%s = %s\"% (name, str(pops_dict[name])))\n",
    "\n",
    "start_time = time.time()\n",
    "times, data, plant_data  = net.flat_run(600.)\n",
    "#times, data, plant_data  = net.run(40.)\n",
    "print('Execution time is %s seconds' % (time.time() - start_time))\n",
    "data = np.array(data)\n",
    "#Execution time is 8.687349319458008 seconds  << before sc_inp_sum_mp, flat_run(5.)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# reducing the scope of the plots\n",
    "data_back = data\n",
    "times_back = times\n",
    "plant_data_back = [np.array([])]\n",
    "plant_data_back[0] = plant_data[0]\n",
    "\n",
    "first_idx=100*200\n",
    "second_idx=115*200\n",
    "times = times[first_idx:second_idx]\n",
    "data = data[:, first_idx:second_idx]\n",
    "plant_data[0] = plant_data[0][first_idx:second_idx,:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# recover the data\n",
    "data = data_back\n",
    "plant_data[0] = plant_data_back[0]\n",
    "times = times_back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same history as `v3_nst_afx`\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
