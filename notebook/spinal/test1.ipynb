{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test1.ipynb\n",
    "First test of the delegational learning rule in the context of the spinal cord project.\n",
    "\n",
    "Let $S_F, S_P, S_{P-F}, M_C$ denote the regions of the cortical model, and $s_F, s_P, s_{P-F}, m_C$ denote their current activities.\n",
    "Assume that each unit $u_j$ in $M_C$ is associated with a vector $\\bar{v}_j$, and that the ouput of the plant is $p = \\sum_j u_j \\bar{v}_j$. We also set $s_F = p$. The rule should be such that $p \\approx s_P$.\n",
    "\n",
    "The plant $P$ can be implemented as a population of linear units.\n",
    "If the connection matrix from $M_C$ to $P$ is called $W$, then\n",
    "$\\bar{v}_j = (W_{1,j}, W_{2,j}, ..., W_{n,j})^T \\equiv W_{:,j}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from draculab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neuronal populations\n",
    "N = 8 # size of each population\n",
    "net_params = {'min_delay' : 0.01,\n",
    "              'min_buff_size' : 10 }\n",
    "SF_params = {'type' : unit_types.sigmoidal,\n",
    "             'thresh' : 0.,\n",
    "             'slope' : 1.,\n",
    "             'init_val' : 0.5,\n",
    "             'tau' : 0.05 }\n",
    "SP_params = {'type' : unit_types.source,\n",
    "             'init_val' : 0.5,\n",
    "             'function' : lambda x: None }\n",
    "SPF_params = {'type' : unit_types.sigmoidal,\n",
    "             'thresh' : 0.,\n",
    "             'slope' : 1.,\n",
    "              'init_val' : 0.5,\n",
    "             'tau' : 0.05 }\n",
    "P_params = {'type' : unit_types.linear,\n",
    "            'init_val' : 0.5,\n",
    "            'tau' : 0.05 }\n",
    "\n",
    "net = network(net_params)\n",
    "SF = net.create(N, SF_params)\n",
    "SP = net.create(N, SP_params)\n",
    "SPF = net.create(N, SPF_params)\n",
    "P = net.create(N, P_params)\n",
    "\n",
    "# Create the connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from units import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class linear in module units.units:\n",
      "\n",
      "class linear(unit)\n",
      " |  An implementation of a linear unit.\n",
      " |  \n",
      " |  The output approaches the sum of the inputs multiplied by their synaptic weights,\n",
      " |  evolving with time constant 'tau'.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      linear\n",
      " |      unit\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, ID, params, network)\n",
      " |      The unit constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          ID, params, network: same as in the 'unit' parent class.\n",
      " |          In addition, params should have the following entries.\n",
      " |              REQUIRED PARAMETERS\n",
      " |              'tau' : Time constant of the update dynamics.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AssertionError.\n",
      " |  \n",
      " |  derivatives(self, y, t)\n",
      " |      This function returns the derivatives of the state variables at a given point in time. \n",
      " |      \n",
      " |      Args: \n",
      " |          y : a 1-element array or list with the current firing rate.\n",
      " |          t: time when the derivative is evaluated.\n",
      " |  \n",
      " |  dt_fun(self, y, s)\n",
      " |      The derivatives function used when the network is flat.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from unit:\n",
      " |  \n",
      " |  euler_maru_update(self, time)\n",
      " |      Advance the dynamics from time to time+min_delay with the Euler-Maruyama method.\n",
      " |      \n",
      " |      The Euler-Maruyama implementation is basically the same as forward Euler.\n",
      " |      The atol and rtol values are meaningless in this case.\n",
      " |      \n",
      " |      This solver does the buuffer's \"rolling\" by itself.\n",
      " |      The unit needs to have 'mu' and 'sigma' attributes.\n",
      " |      self.mu = 0. # Mean of the white noise\n",
      " |      self.sigma = 0.0 # standard deviation of Wiener process.\n",
      " |  \n",
      " |  euler_update(self, time)\n",
      " |      Advance the dynamics from time to time+min_delay using the forward Euler method. \n",
      " |      \n",
      " |      This implementation uses forward Euler integration. Although this may be\n",
      " |      imprecise and unstable in some cases, it is a first step to implement the\n",
      " |      Euler-Maruyama method. And it's also faster than odeint.\n",
      " |      Notice the atol and rtol network parameters are not used in this case.\n",
      " |      Precision is controlled by the step size, which is min_delay/min_buff_size.\n",
      " |  \n",
      " |  exp_euler_update(self, time)\n",
      " |      Advance the dynamics from time to time+min_delay with the exponential Euler method.\n",
      " |      \n",
      " |      This method can only be used when the unit model has noisy dynamics where the \n",
      " |      activity follows an instaneous input function with a particular decay rate. \n",
      " |      This includes the noisy_linear and noisy_sigmoidal models.\n",
      " |      \n",
      " |      The current version is rectifying ouputs by default.\n",
      " |  \n",
      " |  flat_euler_maru_update(self, time)\n",
      " |      The Euler-Maruyama integration used with network.flat_update3.\n",
      " |  \n",
      " |  flat_euler_update(self, time)\n",
      " |      The forward Euler integration method used with network.flat_update3.\n",
      " |  \n",
      " |  flat_exp_euler_update(self, time)\n",
      " |      The exponential Euler integration used with network.flat_update3.\n",
      " |  \n",
      " |  get_act(self, time)\n",
      " |      Gives you the activity at a previous time 't' (within buffer range).\n",
      " |      \n",
      " |      This version works for units that store their previous activity values in a buffer.\n",
      " |      Units without buffers (e.g. source units) have their own get_act function.\n",
      " |      \n",
      " |      This was the most time-consuming method in draculab (thus the various optimizations).\n",
      " |  \n",
      " |  get_exp_sc_input_sum(self, time)\n",
      " |      Returns the sum of inputs, each scaled by its weight and by a scale factor.\n",
      " |      \n",
      " |      The sum accounts for transmission delays. Input ports are ignored.\n",
      " |      The time argument should be within the range of values stored in the unit's buffer.\n",
      " |      \n",
      " |      The scale factor is applied only to excitatory synapses, and it is the scale_facs value\n",
      " |      set by the upd_exp_scale function. This is the way that exp_dist_sigmoidal units get\n",
      " |      their total input.\n",
      " |  \n",
      " |  get_input_sum(self, time)\n",
      " |      Returns the sum of all inputs at the given time, each scaled by its synaptic weight.\n",
      " |      \n",
      " |      The time argument should be within the range of values stored in the unit's buffer.\n",
      " |      The sum accounts for transmission delays. Input ports are ignored.\n",
      " |  \n",
      " |  get_inputs(self, time)\n",
      " |      Returns a list with the inputs received by the unit from all other units at time 'time'.\n",
      " |      \n",
      " |      The time argument should be within the range of values stored in the unit's buffer.\n",
      " |      \n",
      " |      The returned inputs already account for the transmission delays.\n",
      " |      To do this: in the network's act list the entry corresponding to the unit's ID\n",
      " |      (e.g. self.net.act[self.ID]) is a list; for each i-th entry (a function) retrieve\n",
      " |      the value at time \"time - delays[ID][i]\".\n",
      " |      \n",
      " |      \n",
      " |      This function ignores input ports.\n",
      " |  \n",
      " |  get_lpf_fast(self, steps)\n",
      " |      Get the fast low-pass filtered activity, as it was 'steps' simulation steps before.\n",
      " |  \n",
      " |  get_lpf_mid(self, steps)\n",
      " |      Get the mid-speed low-pass filtered activity, as it was 'steps' simulation steps before.\n",
      " |  \n",
      " |  get_lpf_mid_inp_sum(self)\n",
      " |      Get the latest value of the mid-speed low-pass filtered sum of inputs.\n",
      " |  \n",
      " |  get_lpf_slow(self, steps)\n",
      " |      Get the slow low-pass filtered activity, as it was 'steps' simulation steps before.\n",
      " |  \n",
      " |  get_mp_inputs(self, time)\n",
      " |      Returns a list with all the inputs, arranged by input port.\n",
      " |      \n",
      " |      This method is for units where multiport = True, and that have a port_idx attribute.\n",
      " |      \n",
      " |      The i-th element of the returned list is a numpy array containing the raw (not multiplied\n",
      " |      by the synaptic weight) inputs at port i. The inputs include transmision delays.\n",
      " |      \n",
      " |      The time argument should be within the range of values stored in the unit's buffer.\n",
      " |  \n",
      " |  get_mp_weights(self, time)\n",
      " |      Returns a list with the weights corresponding to the list obtained with get_mp_inputs.\n",
      " |      \n",
      " |      This method is for units where multiport = True, and that have a port_idx attribute.\n",
      " |      \n",
      " |      The i-th element of the returned list is a numpy array with the weights of the\n",
      " |      synapses where port = i.\n",
      " |  \n",
      " |  get_sc_input_sum(self, time)\n",
      " |      Returns the sum of inputs, each scaled by its synaptic weight and by a gain constant.\n",
      " |      \n",
      " |      The sum accounts for transmission delays. Input ports are ignored.\n",
      " |      The time argument should be within the range of values stored in the unit's buffer.\n",
      " |      \n",
      " |      The extra scaling factor is the 'gain' attribute of the synapses. This is useful when\n",
      " |      different types of inputs have different gains applied to them. You then need a unit\n",
      " |      model that calls get_sc_input_sum instead of get_input_sum.\n",
      " |  \n",
      " |  get_weights(self, time)\n",
      " |      Returns a list with the weights corresponding to the input list obtained with get_inputs.\n",
      " |  \n",
      " |  init_buffers(self)\n",
      " |      This method (re)initializes the buffer variables according to the current parameters.\n",
      " |      \n",
      " |      It is useful because new connections may increase self.delay, and thus the size of the buffers.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AssertionError.\n",
      " |  \n",
      " |  init_pre_syn_update(self)\n",
      " |      Configure the pre_syn_update function according to current synaptic requirements.\n",
      " |      \n",
      " |      Correlational learning rules require the pre- and post-synaptic activity, in this\n",
      " |      case low-pass filtered in order to implement a running average. Moreover, for\n",
      " |      heterosynaptic plasticity individual synapses need information about all the\n",
      " |      other synapses on the unit. It is inefficient for each synapse to maintain\n",
      " |      low-pass filtered versions of pre- and post-synaptic activity, as well as to\n",
      " |      obtain by itself all the values required for its update.\n",
      " |      The function pre_syn_update(), initialized by init_pre_syn_update(), \n",
      " |      is tasked with updating all the 'slow' unit variables, which can be either used by\n",
      " |      the synapses, or by the unit itself.\n",
      " |      pre_syn_update() is called once per simulation step (i.e. every min_delay period).\n",
      " |      \n",
      " |      In addition, for each one of the unit's synapses, init_pre_syn_update will initialize \n",
      " |      its delay value.\n",
      " |      \n",
      " |      An extra task done here is to prepare the 'port_idx' list used by units with multiple \n",
      " |      input ports.\n",
      " |      \n",
      " |      init_pre_syn_update is called for a unit everytime network.connect() connects the unit, \n",
      " |      which may be more than once.\n",
      " |      \n",
      " |      Raises:\n",
      " |          NameError, NotImplementedError, ValueError.\n",
      " |  \n",
      " |  odeint_update(self, time)\n",
      " |      Advance the dynamics from time to time+min_delay.\n",
      " |      \n",
      " |      This update function will replace the values in the activation buffer\n",
      " |      corresponding to the latest \"min_delay\" time units, introducing \"min_buff_size\" new values.\n",
      " |      In addition, all the synapses of the unit are updated.\n",
      " |      source and kwta units override this with shorter update functions.\n",
      " |  \n",
      " |  pre_syn_update(self, time)\n",
      " |      Call the update functions for the requirements added in init_pre_syn_update.\n",
      " |  \n",
      " |  solve_ivp_diff(self, t, y)\n",
      " |      The derivatives function used by solve_ivp_update. \n",
      " |      \n",
      " |      solve_ivp requires that the derivatives function has its parameters in the\n",
      " |      opposite of the order used by odeint. Thus, to make it work you need to change\n",
      " |      the order of the arguments in all the derivatives functions, from \n",
      " |      derivatives(self, y, t) to derivatives(self, t, y).\n",
      " |      Also, make sure that the import command at the top is uncommented for solve_ivp.\n",
      " |      One more thing: to use the stiff solvers the derivatives must return a list or \n",
      " |      array, so the returned value must be enclosed in square brackets.\n",
      " |  \n",
      " |  solve_ivp_update(self, time)\n",
      " |      Advance the dynamics from time to time+min_delay.\n",
      " |      \n",
      " |      This update function will replace the values in the activation buffer\n",
      " |      corresponding to the latest \"min_delay\" time units, introducing \"min_buff_size\" new \n",
      " |      values. In addition, all the synapses of the unit are updated.\n",
      " |      source and kwta units override this with shorter update functions.\n",
      " |  \n",
      " |  upd_balance(self, time)\n",
      " |      Updates two numbers called  below, and above.\n",
      " |      \n",
      " |      below = fraction of inputs with rate lower than this unit.\n",
      " |      above = fraction of inputs with rate higher than this unit.\n",
      " |      \n",
      " |      Those numbers are useful to produce a given firing rate distribtuion.\n",
      " |      \n",
      " |      NOTICE: this version does not restrict inputs to exp_rate_dist synapses.\n",
      " |  \n",
      " |  upd_balance_mp(self, time)\n",
      " |      Updates two numbers called  below, and above. Used in units with multiple input ports.\n",
      " |      \n",
      " |      below = fraction of inputs with rate lower than this unit.\n",
      " |      above = fraction of inputs with rate higher than this unit.\n",
      " |      \n",
      " |      Those numbers are useful to produce a given firing rate distribtuion among\n",
      " |      the population of units that connect to the 'rdc_port'.\n",
      " |      \n",
      " |      This is the same as upd_balance, but ports other than the rdc_port are ignored.\n",
      " |  \n",
      " |  upd_diff_avg(self, time)\n",
      " |      Update the average of derivatives from inputs with diff_hebbsnorm synapses.\n",
      " |      \n",
      " |      The values being averaged are not the actual derivatives, but approximations\n",
      " |      which are roughly proportional to them, coming from the difference \n",
      " |      lpf_fast - lpf_mid .\n",
      " |  \n",
      " |  upd_err_diff(self, time)\n",
      " |      Update an approximate derivative of the error inputs used for input correlation learning. \n",
      " |      \n",
      " |      A very simple approach is taken, where the derivative is approximated as the difference\n",
      " |      between the fast and medium low-pass filtered inputs. Each input arrives with its\n",
      " |      corresponding transmission delay.\n",
      " |  \n",
      " |  upd_exp_scale(self, time)\n",
      " |      Updates the synaptic scaling factor used in exp_dist_sigmoidal units.\n",
      " |      \n",
      " |      The algorithm is a multiplicative version of the  one used in exp_rate_dist synapses.\n",
      " |      It scales all excitatory inputs.\n",
      " |  \n",
      " |  upd_exp_scale_mp(self, time)\n",
      " |      Updates the synaptic scaling factors used in multiport ssrdc units.\n",
      " |      \n",
      " |      The algorithm is the same as upd_exp_scale, but only the inputs at the rdc_port\n",
      " |      are considered.\n",
      " |  \n",
      " |  upd_flat_inp_sum(self, time)\n",
      " |      Updates the vector with input sums for each substep of the current step.\n",
      " |  \n",
      " |  upd_flat_mp_inp_sum(self, time)\n",
      " |      The multiport version of upd_flat_inp_sum.\n",
      " |  \n",
      " |  upd_inp_avg_hsn(self, time)\n",
      " |      Update the inp_avg_hsn variable.\n",
      " |  \n",
      " |  upd_inp_vector(self, time)\n",
      " |      Update the inp_vector variable.\n",
      " |  \n",
      " |  upd_interpolator(self)\n",
      " |      Update the interp1d function used in the get_act method.\n",
      " |  \n",
      " |  upd_lpf_fast(self, time)\n",
      " |      Update the lpf_fast variable.\n",
      " |  \n",
      " |  upd_lpf_mid(self, time)\n",
      " |      Update the lpf_mid variable.\n",
      " |  \n",
      " |  upd_lpf_mid_inp_sum(self, time)\n",
      " |      Update the lpf_mid_inp_sum variable.\n",
      " |  \n",
      " |  upd_lpf_slow(self, time)\n",
      " |      Update the lpf_slow variable.\n",
      " |  \n",
      " |  upd_lpf_slow_mp_inp_sum(self, time)\n",
      " |      Update the slow LPF'd scaled sum of inputs at individual ports, returning them in a list.\n",
      " |  \n",
      " |  upd_mp_inputs(self, time)\n",
      " |      Update the mp_inputs variable.\n",
      " |  \n",
      " |  upd_norm_factor(self, time)\n",
      " |  \n",
      " |  upd_pos_inp_avg_hsn(self, time)\n",
      " |      Update the pos_inp_avg_hsn variable.\n",
      " |  \n",
      " |  upd_reqs_n_syns(self, time)\n",
      " |      Update the unit's requirements and those of its synapses.\n",
      " |      \n",
      " |      This should be called at every min_delay integration step, after the unit's\n",
      " |      buffers have been updated.\n",
      " |  \n",
      " |  upd_sc_inp_sum_sqhsn(self, time)\n",
      " |      Update the sum of the inputs multiplied by their synaptic weights.\n",
      " |      \n",
      " |      The actual value being summed is lpf_fast of the presynaptic units.\n",
      " |  \n",
      " |  upd_slide_thresh(self, time)\n",
      " |      Updates the threshold of exp_dist_sig_thr units and some other 'trdc' units.\n",
      " |      \n",
      " |      The algorithm is an adapted version of the  one used in exp_rate_dist synapses.\n",
      " |  \n",
      " |  upd_slide_thresh_shrp(self, time)\n",
      " |      Updates the threshold of trdc units when input at 'sharpen' port is larger than 0.5 .\n",
      " |      \n",
      " |      The algorithm is based on upd_slide_thresh.\n",
      " |  \n",
      " |  upd_sq_lpf_slow(self, time)\n",
      " |      Update the sq_lpf_slow variable.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from unit:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(units.linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
