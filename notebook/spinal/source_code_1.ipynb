{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# source_code_1.ipynb\n",
    "\n",
    "This Jupyter notebook produces most of the figures for:  \n",
    "Verduzco-Flores S., De Schutter E. (2021) \"Adaptive plasticity in the spinal cord can produce reaching from scratch and reproduces motor cortex directional tuning.\"\n",
    "\n",
    "The figures are produced by executing all the cells below sequentially. Many figures not in the paper are also produced.\n",
    "\n",
    "**Before executing** make sure you adjust the cell below so it contains the root folder of your Draculab installation. This source code file, and `v3ft3p2ph2_net.py` should be in that folder.\n",
    "\n",
    "Also make sure to adjust values in the third cell in order to try different configurations for the simulation.\n",
    "\n",
    "Creation of the Draculab network uses the `v3ft3p2ph2_net.py` file, which contains all parameter dictionaries. \n",
    "Naming conventions in this file a bit different from the paper. The $S_A$ population is called `SF`, $S_{PA}$ is called `SPF`, $\\alpha$ is called `AL`, $CHG$ is called `SP_CHG`.\n",
    "Parameter names may also differ from the names in the paper. When in doubt, please consult the source code documentation for the unit, synapse, and plant models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Please set the Draculab source folder below\n",
    "%cd /home/z/projects/draculab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from draculab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the simulation\n",
    "\n",
    "np.random.seed(123456) # always the same random values\n",
    "#np.random.seed() # arbitrary random seed\n",
    "\n",
    "# The following configuration settings should be clear to readers of\n",
    "# the paper's Supplementary information\n",
    "\n",
    "use_syne = False # whether to use the version of the network with \"synergies\"\n",
    "par_set = 1 # parameter set. Either 1 or 2.\n",
    "rot_SPF = True # whether to use mixed SPF inputs in M\n",
    "new_gain = 1. # gain multiplier during the center-out reaching phase\n",
    "new_noise = 0. # noise during center-out reaching (cf. C_sigma below)\n",
    "\n",
    "n_reaches_l = 16 # number of random targets presented for initial learning\n",
    "t_pres_l = 40. # target presentation time during initial learning\n",
    "r = .1 # distance from target to center during radial reaching\n",
    "t_pres = 5. # target presentation time for center-out reaching\n",
    "n_trgs = 8 # number of targets for center-out reaching\n",
    "n_rounds = 6 # number of times the n_trgs targets will be presented\n",
    "\n",
    "# It's probably best not to play with the settings below\n",
    "par_heter = 0.01 # amplitude of distribution for heterogeneous parameters\n",
    "set_C_delay = False # whether set C_cid using analytical approach\n",
    "rand_targets = True # whether to train using a large number of random targets\n",
    "C_noise = True # whether C units are noisy (use euler_maru integrator)\n",
    "M__C_rand_w = True # whether to randomly intialize weights for the M__C connections\n",
    "permute_targets = True # whether to permute target order during radial reaches\n",
    "M_size = 12 # number of units in the M population\n",
    "SPF_size = 12 # number of units in the SPF population\n",
    "\n",
    "ad = {'new_noise': new_noise,\n",
    "      'new_gain': new_gain }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The two parameter sets\n",
    "ps1={'A__M_lrate': 20.0,\n",
    "     'A__M_w_max_frac': 0.34,\n",
    "     'A__M_w_sum': 1.0,\n",
    "     'AL_thresh': 0.56,\n",
    "     'b_e': 1.,\n",
    "     'C__C_antag': 1.6,\n",
    "     'C__C_p_antag': 0.15,\n",
    "     'C__C_p_syne': 0.26,\n",
    "     'C__C_syne': 1.1,\n",
    "     'C_adapt_amp': 0.0,\n",
    "     'C_cid': 0.17,\n",
    "     'C_sigma': 0.5,\n",
    "     'C_slope': 2.25,\n",
    "     'C_tau': 0.24,\n",
    "     'C_tau_slow': 2.0,\n",
    "     'C_thresh': 1.14,\n",
    "     'CE__CI_w': 0.39,\n",
    "     'CI__CE_w': -1.8,\n",
    "     'g_e_03': 20.,\n",
    "     'CI_slope': 3.9,\n",
    "     'CI_tau': 0.06,\n",
    "     'CI_thresh': 1.37,\n",
    "     'g_e_factor': 3.,\n",
    "     'II_g_03': 2.73,\n",
    "     'M__C_lrate': 500.0,\n",
    "     'M__C_w_sum': 3.28,\n",
    "     'M__M_w': 0.0,\n",
    "     'M_cid': 1.,\n",
    "     'M_des_out_w_abs_sum': 1.87,\n",
    "     'M_tau': 0.012,\n",
    "     'SF_thresh_03': 0.59,\n",
    "     'SPF__SPF_w': -1.6,\n",
    "     'fitness': None,\n",
    "     'n_evals': 0,\n",
    "     't_pres': t_pres_l,\n",
    "     'par_heter': par_heter}\n",
    "\n",
    "ps2={'A__M_lrate': 20.0,\n",
    "     'A__M_w_max_frac': 0.33,\n",
    "     'A__M_w_sum': 1.0,\n",
    "     'AL_thresh': 0.55,\n",
    "     'b_e': 1.1,\n",
    "     'C__C_antag': 1.7,\n",
    "     'C__C_p_antag': 0.27,\n",
    "     'C__C_p_syne': 0.33,\n",
    "     'C__C_syne': 1.13,\n",
    "     'C_adapt_amp': 0.,\n",
    "     'C_cid': 0.15,\n",
    "     'C_sigma': 0.47,\n",
    "     'C_slope': 2.26,\n",
    "     'C_tau': 0.22,\n",
    "     'C_tau_slow': 2.0,\n",
    "     'C_thresh': 1.05,\n",
    "     'CE__CI_w': 0.38,\n",
    "     'CI__CE_w': -1.89,\n",
    "     'g_e_03': 21.1,\n",
    "     'CI_slope': 3.8,\n",
    "     'CI_tau': 0.025,\n",
    "     'CI_thresh': 1.34,\n",
    "     'g_e_factor': 3.07,\n",
    "     'II_g_03': 2.9,\n",
    "     'M__C_lrate': 500.,\n",
    "     'M__C_w_sum': 3.4,\n",
    "     'M__M_w': 0.0,\n",
    "     'M_cid': 1.1,\n",
    "     'M_des_out_w_abs_sum': 2.,\n",
    "     'M_tau': 0.033,\n",
    "     'SF_thresh_03': 0.55,\n",
    "     'SPF__SPF_w': -1.77,\n",
    "     'fitness': None,\n",
    "     'n_evals': 0,\n",
    "     't_pres': t_pres_l,\n",
    "     'par_heter': par_heter}\n",
    "\n",
    "if par_set == 1:\n",
    "    cfg = ps1\n",
    "elif par_set == 2:\n",
    "    cfg = ps2\n",
    "else:\n",
    "    raise ValueError('The value of par_set should be 1 or 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network\n",
    "%cd /home/z/projects/draculab/notebook/spinal/\n",
    "from v3ft3p2ph2_net import *\n",
    "%cd ../..\n",
    "\n",
    "if not use_syne:\n",
    "    net, pops_dict, hand_coords, m_idxs, pds = net_from_cfg(cfg,\n",
    "                                                       t_pres = t_pres_l,\n",
    "                                                       par_heter = par_heter,\n",
    "                                                       set_C_delay = set_C_delay,\n",
    "                                                       rand_targets = rand_targets,\n",
    "                                                       track_weights = True,\n",
    "                                                       track_ips = True,\n",
    "                                                       C_noise = C_noise,\n",
    "                                                       M__C_rand_w = M__C_rand_w,\n",
    "                                                       rot_SPF = rot_SPF)\n",
    "else:\n",
    "    net, pops_dict, hand_coords, m_idxs, pds = syne_net(cfg,\n",
    "                                                   t_pres = t_pres_l,\n",
    "                                                   par_heter = par_heter,\n",
    "                                                   set_C_delay = set_C_delay,\n",
    "                                                   rand_targets = rand_targets,\n",
    "                                                   track_weights = True,\n",
    "                                                   track_ips = True,\n",
    "                                                   C_noise = C_noise,\n",
    "                                                   M__C_rand_w = M__C_rand_w,\n",
    "                                                   rot_SPF = rot_SPF)\n",
    "\n",
    "for name in pops_dict:\n",
    "    exec(\"%s = %s\"% (name, str(pops_dict[name])))\n",
    "\n",
    "# parameter dictionaries used to change targets\n",
    "P__A_syn = pds['P__A_syn']\n",
    "P__A_ws = np.array(P__A_syn['init_w'][12:18])\n",
    "A__SF_syn = pds['A__SF_syn']\n",
    "SF_params = pds['SF_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation for initial learning\n",
    "sim_time_l = t_pres_l * n_reaches_l\n",
    "start_wctime = time.time()\n",
    "times_l, data_l, plant_data_l  = net.flat_run(sim_time_l)\n",
    "\n",
    "data_l = np.array(data_l)\n",
    "print('Execution time is %s seconds' % (time.time() - start_wctime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce figures\n",
    "\n",
    "tic_s = 25 # tick label size\n",
    "tit_s = 25 # title size\n",
    "leg_s = 15 # legend text size\n",
    "lab_s = 25 # axis label font size\n",
    "arm_activs = plant_data_l[P]\n",
    "\n",
    "u_to_disp = [0,1,2,6,8,9] # units to display\n",
    "# SPF\n",
    "redSPF = [SPF[u] for u in u_to_disp] # \"reduced\" SPF\n",
    "fs = (25,6)\n",
    "SPF_fig = plt.figure(figsize=fs)\n",
    "SPF_ax = plt.gca()\n",
    "SPF_ax.tick_params(axis='both', labelsize=tic_s)\n",
    "SPF_data_l = np.array(data_l[redSPF])\n",
    "plt.plot(times_l, SPF_data_l.transpose())\n",
    "for rch in range(n_reaches_l): # plot a line at the onset of new targets\n",
    "    plt.plot([t_pres_l*rch, t_pres_l*rch], [-0.01, 1.], 'y--', linewidth=1)\n",
    "#SPF_legends = ['$S_{PA}$'+str(i) for i in range(len(redSPF))]\n",
    "SPF_legends = ['$S_{PA}$'+str(i) for i in u_to_disp]\n",
    "plt.legend(SPF_legends, fontsize=15)\n",
    "plt.title('$S_{PA}$', fontsize=tit_s)\n",
    "\n",
    "# M\n",
    "redM = [M[u] for u in u_to_disp] # \"reduced\" M\n",
    "M_fig = plt.figure(figsize=fs)\n",
    "M_data_l = np.array(data_l[redM])\n",
    "plt.plot(times_l, M_data_l.transpose())\n",
    "M_legends = ['$M_{'+str(i)+'}$' for i in u_to_disp]\n",
    "for rch in range(n_reaches_l): # plot a line at the onset of new targets\n",
    "    plt.plot([t_pres_l*rch, t_pres_l*rch], [-0.01, 1.], 'y--', linewidth=1)\n",
    "plt.legend(M_legends, fontsize=15)\n",
    "plt.title('M', fontsize=tit_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "\n",
    "if use_syne:\n",
    "    # SYNE, SYNI\n",
    "    n_syn_f = 4 # how many unit pairs to plot\n",
    "    SYN_fig = plt.figure(figsize=fs)\n",
    "    SYNE_data_l = np.array(data_l[SYNE[:n_syn_f]])\n",
    "    SYNI_data_l = np.array(data_l[SYNI[:n_syn_f]])\n",
    "    plt.plot(times_l, SYNE_data_l.transpose(), linewidth=2)\n",
    "    plt.plot(times_l, SYNI_data_l.transpose(), '--')\n",
    "    SYN_legends = ['SYNE'+str(i) for i in range(n_syn_f)]\n",
    "    SYN_legends += ['SYNI'+str(i) for i in range(n_syn_f)]\n",
    "    plt.legend(SYN_legends, fontsize=leg_s)\n",
    "    plt.title('SYN', fontsize=tit_s)\n",
    "    plt.xlabel('time [s]', fontsize=lab_s)\n",
    "    plt.xticks(fontsize=tic_s)\n",
    "    plt.yticks(fontsize=tic_s)\n",
    "    for rch in range(n_reaches_l): # plot a line at the onset of new targets\n",
    "        plt.plot([t_pres_l*rch, t_pres_l*rch], [-0.5, 1.5], 'y--', linewidth=1)\n",
    "    \n",
    "    # M--SYNE0 weights\n",
    "    W_fig1 = plt.figure(figsize=fs)\n",
    "    w_track_data_l = np.array(data_l[M_SYNE0_track])\n",
    "    plt.plot(times_l, w_track_data_l.transpose())\n",
    "    M_SYNE0_legends = ['M'+str(i)+'--SYNE0' for i in range(len(M_SYNE0_track))]\n",
    "    plt.legend(M_SYNE0_legends)\n",
    "    plt.title('M--SYNE0 weights', fontsize=tit_s)\n",
    "    plt.xticks(fontsize=tic_s)\n",
    "    plt.yticks(fontsize=tit_s)\n",
    "    for rch in range(n_reaches_l): # plot a line at the onset of new targets\n",
    "        plt.plot([t_pres_l*rch, t_pres_l*rch], [-0.01, 1.5], 'y--', linewidth=1)\n",
    "else:\n",
    "    # C\n",
    "    cu_to_disp = [0] # units to display\n",
    "    redCE = [CE[u] for u in cu_to_disp]\n",
    "    redCI = [CI[u] for u in cu_to_disp] \n",
    "    C_fig = plt.figure(figsize=fs)\n",
    "    CE_data_l = np.array(data_l[redCE])\n",
    "    CI_data_l = np.array(data_l[redCI])\n",
    "    plt.plot(times_l, CE_data_l.transpose(), linewidth=2)\n",
    "    plt.plot(times_l, CI_data_l.transpose(), '--')\n",
    "    C_legends = ['CE'+str(i) for i in cu_to_disp]\n",
    "    C_legends += ['CI'+str(i) for i in cu_to_disp]\n",
    "    plt.legend(C_legends, fontsize=leg_s)\n",
    "    plt.title('C', fontsize=tit_s)\n",
    "    plt.xlabel('time [s]', fontsize=lab_s)\n",
    "    plt.xticks(fontsize=tic_s)\n",
    "    plt.yticks(fontsize=tic_s)\n",
    "    for rch in range(n_reaches_l): # plot a line at the onset of new targets\n",
    "        plt.plot([t_pres_l*rch, t_pres_l*rch], [-0.5, 1.5], 'y--', linewidth=1)\n",
    "\n",
    "    # M--CE0 weights\n",
    "    W_fig1 = plt.figure(figsize=fs)\n",
    "    w_track_data_l = np.array(data_l[M_CE0_track])\n",
    "    plt.plot(times_l, w_track_data_l.transpose())\n",
    "    M_CE0_legends = ['M'+str(i)+'--C0' for i in range(len(M_CE0_track))]\n",
    "    plt.legend(M_CE0_legends, fontsize=15)\n",
    "    plt.title('M--C0 weights', fontsize=tit_s)\n",
    "    plt.xlabel('time [s]', fontsize=lab_s)\n",
    "    plt.xticks(fontsize=tic_s)\n",
    "    plt.yticks(fontsize=tic_s)\n",
    "    for rch in range(n_reaches_l): # plot a line at the onset of new targets\n",
    "        plt.plot([t_pres_l*rch, t_pres_l*rch], [-0.01, 1.5], 'y--', linewidth=1)\n",
    "\n",
    "# AF--M0 weights\n",
    "W_fig2 = plt.figure(figsize=fs)\n",
    "w_track_data2_l = np.array(data_l[A_M0_track[0:18]])\n",
    "plt.plot(times_l, w_track_data2_l.transpose())\n",
    "A_M0_legends = ['A'+str(i)+'--M0' for i in range(len(A_M0_track[:12]))]\n",
    "plt.legend(A_M0_legends, fontsize=15)\n",
    "plt.title('A--M0 weights exc', fontsize=tit_s)\n",
    "plt.xlabel('time [s]', fontsize=lab_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "for rch in range(n_reaches_l): # plot a line at the onset of new targets\n",
    "    plt.plot([t_pres_l*rch, t_pres_l*rch], [-0.01, .4], 'y--', linewidth=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P\n",
    "P_fig = plt.figure(figsize=fs)\n",
    "P_state = plant_data_l[P][:,0:4:2]\n",
    "plt.plot(times_l, P_state)\n",
    "#plt.legend(['sh ang', 'sh ang vel', 'elb ang', 'elb ang vel'])\n",
    "plt.legend(['sh ang', 'elb ang',], fontsize=leg_s)\n",
    "plt.title('double pendulum state variables', fontsize=tit_s)\n",
    "#plt.xlabel('time [s]', fontsize=lab_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "for rch in range(n_reaches_l): # plot a line at the onset of new targets\n",
    "    plt.plot([t_pres_l*rch, t_pres_l*rch], [-0.5, 2.5], 'y--', linewidth=1)\n",
    "\n",
    "# A\n",
    "A_fig = plt.figure(figsize=fs)\n",
    "A_data_l = np.array(data_l[A[0:18]])\n",
    "plt.plot(times_l, A_data_l.transpose())\n",
    "A_legends = ['Ib' + str(i) for i in range(6)] + \\\n",
    "            ['Ia' + str(i) for i in range(6)] + \\\n",
    "            ['II' + str(i) for i in range(6)]\n",
    "plt.legend(A_legends, fontsize=12)\n",
    "plt.title('A', fontsize=tit_s)\n",
    "#plt.xlabel('time [s]', fontsize=lab_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "\n",
    "#fs = (30,6)\n",
    "# SF, SP\n",
    "SF_fig, axs = plt.subplots(1, 3, figsize=(fs[0], fs[1]))\n",
    "for ax in axs.flatten(): \n",
    "    ax.tick_params(axis='both', labelsize=tic_s)\n",
    "SF_data_l = np.array(data_l[SF])\n",
    "SP_data_l = np.array(data_l[SP])\n",
    "if 'lowpass_SP' in locals() and lowpass_SP is True:\n",
    "    LPF_SP_data_l = np.array(data_l[LPF_SP])\n",
    "for col in range(3):\n",
    "    ax = axs[col]\n",
    "    base = 2*col\n",
    "    ax.plot(times_l, SF_data_l[base:base+2, :].transpose(), linewidth=2)\n",
    "    ax.plot(times_l, SP_data_l[base:base+2, :].transpose(), '--', linewidth=1)\n",
    "    if 'lowpass_SP' in locals() and lowpass_SP is True:\n",
    "        ax.plot(times_l, LPF_SP_data_l[base:base+2, :].transpose(), linewidth=2)\n",
    "    ax.set_title('SF, SP, units %d to %d' % (base, base+1), fontsize=tit_s)\n",
    "    SF_legends = ['SF '+ str(base+i) for i in range(2)]\n",
    "    SP_legends = ['SP '+ str(base+i) for i in range(2)]\n",
    "    ax.legend(SF_legends + SP_legends, fontsize=leg_s)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x,window_len=11,window='hanning'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "    \n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal \n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "    \n",
    "    input:\n",
    "        x: the input signal \n",
    "        window_len: the dimension of the smoothing window; should be an odd integer\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    output:\n",
    "        the smoothed signal\n",
    "        \n",
    "    example:\n",
    "\n",
    "    t=linspace(-2,2,0.1)\n",
    "    x=sin(t)+randn(len(t))*0.1\n",
    "    y=smooth(x)\n",
    "    \n",
    "    see also: \n",
    "    \n",
    "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "    scipy.signal.lfilter\n",
    " \n",
    "    TODO: the window parameter could be the window itself if an array instead of a string\n",
    "    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n",
    "    \"\"\"\n",
    "\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError(\"smooth only accepts 1 dimension arrays.\")\n",
    "    if x.size < window_len:\n",
    "        raise ValueError(\"Input vector needs to be bigger than window size.\")\n",
    "    if window_len<3:\n",
    "        return x\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise ValueError(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('np.'+window+'(window_len)')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n",
    "\n",
    "\n",
    "plant = net.plants[P]\n",
    "# modified copy-paste of plt.upd_ip_impl\n",
    "q1 = arm_activs[:,0]\n",
    "q2 = arm_activs[:,2]\n",
    "q12 = q1+q2\n",
    "c_elbow = np.array((plant.l_arm*np.cos(q1), plant.l_arm*np.sin(q1)))\n",
    "c_hand = np.array((c_elbow[0] + plant.l_farm*np.cos(q12),\n",
    "                   c_elbow[1] + plant.l_farm*np.sin(q12))).transpose()\n",
    "if 'start_t' in locals():\n",
    "    coord_idxs = np.floor((times_l-start_t)/t_pres_l).astype(int) # after resetting the targets\n",
    "    des_coords = np.array([hand_coords[idx] for idx in [m_idxs[cid] for cid in coord_idxs]])\n",
    "else:\n",
    "    coord_idxs = np.floor(times_l/t_pres_l).astype(int)  # before resetting the targets\n",
    "    des_coords = np.array(hand_coords)[m_idxs[coord_idxs],:] # desired coordinates at each moment in time\n",
    "coords_fig = plt.figure(figsize=fs)\n",
    "plt.plot(times_l, c_hand)\n",
    "plt.plot(times_l, des_coords)\n",
    "plt.title('desired vs. actual hand coordinates', fontsize=tit_s)\n",
    "plt.legend(['X', 'Y', 'des_X', 'des_Y'], fontsize=leg_s)\n",
    "#plt.xlabel('time [s]', fontsize=lab_s)\n",
    "plt.ylabel('coordinate [m]', fontsize=lab_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "\n",
    "act_fig = plt.figure(figsize=fs)\n",
    "act_data_l = np.array(data_l[ACT])[0]\n",
    "plt.plot(times_l, act_data_l)\n",
    "plt.plot(times_l, 0.8*np.ones_like(times_l), 'k--')\n",
    "plt.title('ACT', fontsize=tit_s)\n",
    "plt.xlabel('time [s]', fontsize=lab_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "\n",
    "err_fig = plt.figure(figsize=fs)\n",
    "w_len = 1001\n",
    "hand_error = np.linalg.norm(c_hand-des_coords, axis=1)\n",
    "smooth_hand_error = smooth(hand_error, window_len=w_len)[int(np.floor(w_len/2)):-int(np.floor(w_len/2))]\n",
    "#plt.plot(times_l, smooth_hand_error)\n",
    "plt.plot(times_l, hand_error, 'r')\n",
    "plt.plot(times_l, 0.1+np.zeros(smooth_hand_error.size), 'k--')\n",
    "plt.title('distance from target', fontsize=tit_s)\n",
    "for rch in range(n_reaches_l): # plot a line at the onset of new targets\n",
    "    plt.plot([t_pres_l*rch, t_pres_l*rch], [-0.01, 0.6], 'y--', linewidth=1)\n",
    "#plt.xlabel('time [s]', fontsize=lab_s)\n",
    "plt.ylabel('error [m]', fontsize=lab_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "\n",
    "avg_error = hand_error.sum()/hand_error.size\n",
    "print(\"average error: %f\" % (avg_error))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha units\n",
    "fs2 =(25,5)\n",
    "AL_fig = plt.figure(figsize=fs2)\n",
    "AL_data = np.array(data_l[AL])\n",
    "plt.plot(times_l, AL_data.transpose())\n",
    "AL_legends = ['AL'+str(i) for i in range(len(AL))]\n",
    "plt.legend(AL_legends)\n",
    "plt.title('AL')\n",
    "print('AL_data:')\n",
    "print(AL_data[:,-1])\n",
    "\n",
    "# plotting muscle outputs\n",
    "fs2 =(25,5)\n",
    "legs = ['Ib', 'Ia', 'II']\n",
    "\n",
    "for i in range(6):\n",
    "    next_fig = plt.figure(figsize=fs2)\n",
    "    Ib = arm_activs[:,22+i]\n",
    "    Ia = arm_activs[:,28+i]\n",
    "    II = arm_activs[:,34+i]\n",
    "    plt.plot(times_l, Ib, times_l, Ia, times_l, II)\n",
    "    plt.legend(legs)\n",
    "    plt.title('m' + str(i))\n",
    "    print('Ib avg for muscle '+ str(i) + '= ' + str(np.mean(Ib)))\n",
    "    print('Ia avg for muscle '+ str(i) + '= ' + str(np.mean(Ia)))\n",
    "    print('II avg for muscle '+ str(i) + '= ' + str(np.mean(II)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power spectrum\n",
    "pop_id = M[0]\n",
    "init_idx = 20000\n",
    "from spectrum import *\n",
    "fig1 = plt.figure()\n",
    "spec_data = data_l[pop_id][init_idx:init_idx+8192]\n",
    "spec_data = spec_data - np.mean(spec_data)\n",
    "p = Periodogram(spec_data, sampling=(1./net.min_delay))\n",
    "p.plot(marker='o')\n",
    "plt.xlim([0,10])\n",
    "\n",
    "fig2 = plt.figure()\n",
    "res = pmtm(spec_data, NW=2.5, k=4, show=True)\n",
    "plt.xlim([0,800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_new_targets(net,\n",
    "                    pops_dict,\n",
    "                    r,\n",
    "                    t_pres,\n",
    "                    n_trgs,\n",
    "                    n_rounds,\n",
    "                    pds,\n",
    "                    permute_targets=True):\n",
    "    \"\"\" Set new targets for reaching.\n",
    "        \n",
    "        Args:\n",
    "            net: the draculab network\n",
    "            pops_dict: dictionary with unit IDs for each population\n",
    "            r: distance from center to targets\n",
    "            t_pres: new presentation time\n",
    "            n_trgs: number of targets\n",
    "            n_rounds: number of times the n_trgs targets will be presented\n",
    "            pds : parameter dictionaries used to calculate SP values.\n",
    "            permute_targets: (boolean) are targets presented permuted?\n",
    "\n",
    "            \n",
    "        Returns:\n",
    "            hand_coords : list with target coordinates (each a numpy 2-array).\n",
    "            targets : list, only with targets\n",
    "            center : only the center coordinates\n",
    "            trg_ids: target used for each presentation\n",
    "    \"\"\"\n",
    "    \n",
    "    start_t = net.sim_time # starting time for new simulation\n",
    "    # 8 radial targets in sequence, from 0 to 315 degrees\n",
    "    r = 0.1 # distance from center to targets\n",
    "    center = np.array([0.3, 0.3]) # initial hand location\n",
    "    angs = np.linspace(0., 2.*np.pi, n_trgs+1)[:-1]\n",
    "    circle = np.array([np.array([np.cos(ang),np.sin(ang)]) for ang in angs])\n",
    "    targets = center + r*circle # coordinates of the targets\n",
    "\n",
    "    if permute_targets:\n",
    "        # version with permuted targets, all are seen every 8 presentations\n",
    "        trg_ids = np.random.permutation(n_trgs*n_rounds)%n_trgs # target for each presentation\n",
    "        hand_coords = []\n",
    "        for idx in trg_ids:\n",
    "            hand_coords += [center, targets[idx]]\n",
    "        hand_coords += [center] # to avoid indexes out of bounds\n",
    "    else:    \n",
    "        # version with sequential targets\n",
    "        hand_coords = [center, targets[0],\n",
    "                       center, targets[1],\n",
    "                       center, targets[2],\n",
    "                       center, targets[3],\n",
    "                       center, targets[4],\n",
    "                       center, targets[5],\n",
    "                       center, targets[6],\n",
    "                       center, targets[7]]\n",
    "        hand_coords = n_rounds * hand_coords # many repetitions of the same sequence\n",
    "        hand_coords += [center] # to avoid indexes out of bounds\n",
    "        trg_ids = np.arange(len(hand_coords))%n_trgs # target for each presentation\n",
    "\n",
    "    SP = pops_dict['SP']\n",
    "    A = pops_dict['A']\n",
    "    P = pops_dict['P']\n",
    "    #### next is a copy-pasta of the code to set the SP values\n",
    "    # list with muscle lengths corresponding to the hand coordinates\n",
    "    m_lengths = []\n",
    "    for coord in hand_coords:\n",
    "        m_lengths.append(net.plants[P].coords_to_lengths(coord))\n",
    "    m_lengths = np.array(m_lengths)\n",
    "    #(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)\n",
    "    # We need to translate these lengths to corresponding SF activity levels.\n",
    "    # For that it is necessary to recreate all their transformations\n",
    "    # The first transformation is from length to II afferent activity.\n",
    "    ### OUT OF THE 36 AFFERENT SIGNALS, WE TAKE II ###\n",
    "    par = net.plants[P].m_params\n",
    "    # steady state tensions in the static and dynamic bag fibers (no gamma inputs)\n",
    "    Ts_ss = (par['k_se_s']/(par['k_se_s']+par['k_pe_s'])) * (\n",
    "             par['k_pe_s']*(m_lengths - par['l0_s']))\n",
    "    Td_ss = (par['k_se_d']/(par['k_se_d']+par['k_pe_d'])) * (\n",
    "             par['k_pe_d']*(m_lengths - par['l0_d']))\n",
    "    # steady state afferent outputs (no gamma inputs)\n",
    "    #Ia_ss = par['fs']*(Ts_ss/par['k_se_s']) + (1.-par['fs'])*(Td_ss/par['k_se_d'])\n",
    "    II_ss = par['se_II']*(Ts_ss/par['k_se_s']) + ((1.-par['se_II'])/par['k_pe_s'])*Ts_ss\n",
    "    #Ia_ss *= par['Ia_gain']\n",
    "    II_ss *= par['II_gain']\n",
    "    #Ia_II_ss = np.concatenate((Ia_ss, II_ss), axis=1)\n",
    "    # Next transformation is through the afferent units\n",
    "    P__A_ws = np.array(pds['P__A_syn']['init_w'][12:18])\n",
    "    #Ia_II_avgs = np.mean(Ia_II_ss, axis=0)  # when using hundreds of random targets\n",
    "    # target averages\n",
    "    A_thr = np.array([net.units[u].thresh for u in A[12:18]])\n",
    "    A_II = np.log(1. + np.maximum((II_ss)*P__A_ws - A_thr, 0.))\n",
    "    #(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)\n",
    "    # Next is from A to SF\n",
    "    SF_arg = pds['A__SF_syn']['init_w']*A_II\n",
    "    SF_params = pds['SF_params']\n",
    "    SF_out = 1./ (1. + np.exp(-SF_params['slope']*(SF_arg - SF_params['thresh'])))\n",
    "    SF_params['init_val'] = SF_out # this might cause a smooth start\n",
    "    # now we set the values in SP\n",
    "    #m_idxs = np.random.randint(len(hand_coords), size=1000) # index of all targets\n",
    "    m_idxs = list(range(len(hand_coords)+1)) # reach list targets sequentially\n",
    "        #m_idxs[0] = 0 # for testing\n",
    "    A_us = [net.units[u] for u in A]\n",
    "\n",
    "    def SF_sigmo(idx, arg):\n",
    "        \"\"\" The sigmoidal function for SF unit with index SF[idx]. \"\"\"\n",
    "        return 1./ (1. + np.exp(-SF_params['slope'][idx]*(arg - SF_params['thresh'][idx])))\n",
    "\n",
    "    def cur_target(t):\n",
    "        \"\"\" Returns the index of the target at time t. \"\"\"\n",
    "        return m_idxs[int(np.floor((t-start_t)/t_pres))]\n",
    "\n",
    "    def make_fun(idx):\n",
    "        \"\"\" create a function for the SP unit with index 'idx'. \"\"\"\n",
    "        return lambda t: SF_sigmo(idx, \n",
    "                            pds['A__SF_syn']['init_w'][idx] * (\n",
    "                            np.log(1. + max(II_ss[cur_target(t)][idx] * P__A_ws[idx] - \n",
    "                            net.units[A[12+idx]].thresh, 0.))))\n",
    "\n",
    "    for idx, u in enumerate(SP):\n",
    "        net.units[u].set_function(make_fun(idx))\n",
    "        \n",
    "    return hand_coords, targets, center, trg_ids, m_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new targets with the function\n",
    "\n",
    "start_t = net.sim_time # starting time for new simulation\n",
    "hand_coords, targets, center, trg_ids, m_idxs = set_new_targets(net, \n",
    "                                                          pops_dict,\n",
    "                                                                  r, \n",
    "                                                             t_pres,\n",
    "                                                             n_trgs, \n",
    "                                                            n_rounds,\n",
    "                                                            pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove noise from C units\n",
    "if use_syne:\n",
    "    for u in [net.units[c] for c in SYNE+SYNI]:\n",
    "        u.sigma = ad['new_noise']    \n",
    "else:\n",
    "    for u in [net.units[c] for c in CE+CI]:\n",
    "        u.sigma = ad['new_noise']\n",
    "    \n",
    "# increase the muscle gains\n",
    "for idx in range(6):\n",
    "    net.plants[0].inp_syns[idx][0].w = ad['new_gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation for radial reaches\n",
    "sim_time2 = 2 * t_pres * n_trgs * n_rounds\n",
    "start_wctime = time.time()\n",
    "times, data, plant_data  = net.flat_run(sim_time2)\n",
    "data = np.array(data)\n",
    "print('Execution time is %s seconds' % (time.time() - start_wctime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce figures\n",
    "\n",
    "tic_s = 25 # tick label size\n",
    "tit_s = 25 # title size\n",
    "leg_s = 15 # legend text size\n",
    "lab_s = 25 # axis label font size\n",
    "arm_activs = plant_data[P]\n",
    "\n",
    "u_to_disp = [0,1,2,6,8,9] # units to display\n",
    "# SPF\n",
    "redSPF = [SPF[u] for u in u_to_disp] # \"reduced\" SPF\n",
    "fs = (25,6)\n",
    "SPF_fig = plt.figure(figsize=fs)\n",
    "SPF_ax = plt.gca()\n",
    "SPF_ax.tick_params(axis='both', labelsize=tic_s)\n",
    "SPF_data = np.array(data[redSPF])\n",
    "plt.plot(times, SPF_data.transpose())\n",
    "# for rch in range(n_reaches): # plot a line at the onset of new targets\n",
    "#     plt.plot([t_pres*rch, t_pres*rch], [-0.01, 1.], 'y--', linewidth=1)\n",
    "#SPF_legends = ['$S_{PA}$'+str(i) for i in range(len(redSPF))]\n",
    "SPF_legends = ['$S_{PA}$'+str(i) for i in u_to_disp]\n",
    "plt.legend(SPF_legends, fontsize=15)\n",
    "plt.title('$S_{PA}$', fontsize=tit_s)\n",
    "\n",
    "# M\n",
    "redM = [M[u] for u in u_to_disp] # \"reduced\" M\n",
    "M_fig = plt.figure(figsize=fs)\n",
    "M_data = np.array(data[redM])\n",
    "plt.plot(times, M_data.transpose())\n",
    "M_legends = ['$M_{'+str(i)+'}$' for i in u_to_disp]\n",
    "# for rch in range(n_reaches): # plot a line at the onset of new targets\n",
    "#     plt.plot([t_pres*rch, t_pres*rch], [-0.01, 1.], 'y--', linewidth=1)\n",
    "plt.legend(M_legends, fontsize=15)\n",
    "plt.title('M', fontsize=tit_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "\n",
    "if use_syne:\n",
    "    # SYNE, SYNI\n",
    "    n_syn_f = 4 # how many unit pairs to plot\n",
    "    SYN_fig = plt.figure(figsize=fs)\n",
    "    SYNE_data = np.array(data[SYNE[:n_syn_f]])\n",
    "    SYNI_data = np.array(data[SYNI[:n_syn_f]])\n",
    "    plt.plot(times, SYNE_data.transpose(), linewidth=2)\n",
    "    plt.plot(times, SYNI_data.transpose(), '--')\n",
    "    SYN_legends = ['SYNE'+str(i) for i in range(n_syn_f)]\n",
    "    SYN_legends += ['SYNI'+str(i) for i in range(n_syn_f)]\n",
    "    plt.legend(SYN_legends, fontsize=leg_s)\n",
    "    plt.title('SYN', fontsize=tit_s)\n",
    "    plt.xlabel('time [s]', fontsize=lab_s)\n",
    "    plt.xticks(fontsize=tic_s)\n",
    "    plt.yticks(fontsize=tic_s)\n",
    "#     for rch in range(n_reaches): # plot a line at the onset of new targets\n",
    "#         plt.plot([t_pres*rch, t_pres*rch], [-0.5, 1.5], 'y--', linewidth=1)\n",
    "    \n",
    "    # M--SYNE0 weights\n",
    "    W_fig1 = plt.figure(figsize=fs)\n",
    "    w_track_data = np.array(data[M_SYNE0_track])\n",
    "    plt.plot(times, w_track_data.transpose())\n",
    "    M_SYNE0_legends = ['M'+str(i)+'--SYNE0' for i in range(len(M_SYNE0_track))]\n",
    "    plt.legend(M_SYNE0_legends)\n",
    "    plt.title('M--SYNE0 weights', fontsize=tit_s)\n",
    "    plt.xticks(fontsize=tic_s)\n",
    "    plt.yticks(fontsize=tit_s)\n",
    "#     for rch in range(n_reaches): # plot a line at the onset of new targets\n",
    "#         plt.plot([t_pres*rch, t_pres*rch], [-0.01, 1.5], 'y--', linewidth=1)\n",
    "else:\n",
    "    # C\n",
    "    cu_to_disp = [0] # units to display\n",
    "    redCE = [CE[u] for u in cu_to_disp]\n",
    "    redCI = [CI[u] for u in cu_to_disp] \n",
    "    C_fig = plt.figure(figsize=fs)\n",
    "    CE_data = np.array(data[redCE])\n",
    "    CI_data = np.array(data[redCI])\n",
    "    plt.plot(times, CE_data.transpose(), linewidth=2)\n",
    "    plt.plot(times, CI_data.transpose(), '--')\n",
    "    C_legends = ['CE'+str(i) for i in cu_to_disp]\n",
    "    C_legends += ['CI'+str(i) for i in cu_to_disp]\n",
    "    plt.legend(C_legends, fontsize=leg_s)\n",
    "    plt.title('C', fontsize=tit_s)\n",
    "    plt.xlabel('time [s]', fontsize=lab_s)\n",
    "    plt.xticks(fontsize=tic_s)\n",
    "    plt.yticks(fontsize=tic_s)\n",
    "#     for rch in range(n_reaches): # plot a line at the onset of new targets\n",
    "#         plt.plot([t_pres*rch, t_pres*rch], [-0.5, 1.5], 'y--', linewidth=1)\n",
    "\n",
    "    # M--CE0 weights\n",
    "    W_fig1 = plt.figure(figsize=fs)\n",
    "    w_track_data = np.array(data[M_CE0_track])\n",
    "    plt.plot(times, w_track_data.transpose())\n",
    "    M_CE0_legends = ['M'+str(i)+'--C0' for i in range(len(M_CE0_track))]\n",
    "    plt.legend(M_CE0_legends, fontsize=15)\n",
    "    plt.title('M--C0 weights', fontsize=tit_s)\n",
    "    plt.xlabel('time [s]', fontsize=lab_s)\n",
    "    plt.xticks(fontsize=tic_s)\n",
    "    plt.yticks(fontsize=tic_s)\n",
    "#     for rch in range(n_reaches): # plot a line at the onset of new targets\n",
    "#         plt.plot([t_pres*rch, t_pres*rch], [-0.01, 1.5], 'y--', linewidth=1)\n",
    "\n",
    "# AF--M0 weights\n",
    "W_fig2 = plt.figure(figsize=fs)\n",
    "w_track_data2 = np.array(data[A_M0_track[0:18]])\n",
    "plt.plot(times, w_track_data2.transpose())\n",
    "A_M0_legends = ['A'+str(i)+'--M0' for i in range(len(A_M0_track[:12]))]\n",
    "plt.legend(A_M0_legends, fontsize=15)\n",
    "plt.title('A--M0 weights exc', fontsize=tit_s)\n",
    "plt.xlabel('time [s]', fontsize=lab_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "# for rch in range(n_reaches): # plot a line at the onset of new targets\n",
    "#     plt.plot([t_pres*rch, t_pres*rch], [-0.01, .4], 'y--', linewidth=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x,window_len=11,window='hanning'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "    \n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal \n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "    \n",
    "    input:\n",
    "        x: the input signal \n",
    "        window_len: the dimension of the smoothing window; should be an odd integer\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    output:\n",
    "        the smoothed signal\n",
    "        \n",
    "    example:\n",
    "\n",
    "    t=linspace(-2,2,0.1)\n",
    "    x=sin(t)+randn(len(t))*0.1\n",
    "    y=smooth(x)\n",
    "    \n",
    "    see also: \n",
    "    \n",
    "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "    scipy.signal.lfilter\n",
    " \n",
    "    TODO: the window parameter could be the window itself if an array instead of a string\n",
    "    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n",
    "    \"\"\"\n",
    "\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError(\"smooth only accepts 1 dimension arrays.\")\n",
    "    if x.size < window_len:\n",
    "        raise ValueError(\"Input vector needs to be bigger than window size.\")\n",
    "    if window_len<3:\n",
    "        return x\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise ValueError(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('np.'+window+'(window_len)')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n",
    "\n",
    "\n",
    "plant = net.plants[P]\n",
    "# modified copy-paste of plt.upd_ip_impl\n",
    "q1 = arm_activs[:,0]\n",
    "q2 = arm_activs[:,2]\n",
    "q12 = q1+q2\n",
    "c_elbow = np.array((plant.l_arm*np.cos(q1), plant.l_arm*np.sin(q1)))\n",
    "c_hand = np.array((c_elbow[0] + plant.l_farm*np.cos(q12),\n",
    "                   c_elbow[1] + plant.l_farm*np.sin(q12))).transpose()\n",
    "if 'start_t' in locals():\n",
    "    coord_idxs = np.floor((times-start_t+1e-8)/t_pres).astype(int) # after resetting the targets\n",
    "    des_coords = np.array([hand_coords[idx] for idx in [m_idxs[cid] for cid in coord_idxs]])\n",
    "else:\n",
    "    coord_idxs = np.floor(times/t_pres).astype(int)  # before resetting the targets\n",
    "    des_coords = np.array(hand_coords)[m_idxs[coord_idxs],:] # desired coordinates at each moment in time\n",
    "coords_fig = plt.figure(figsize=fs)\n",
    "plt.plot(times, c_hand)\n",
    "plt.plot(times, des_coords)\n",
    "plt.title('desired vs. actual hand coordinates', fontsize=tit_s)\n",
    "plt.legend(['X', 'Y', 'des_X', 'des_Y'], fontsize=leg_s)\n",
    "plt.xlabel('time [s]', fontsize=lab_s)\n",
    "plt.ylabel('coordinate [m]', fontsize=lab_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "\n",
    "act_fig = plt.figure(figsize=fs)\n",
    "act_data = np.array(data[ACT])[0]\n",
    "plt.plot(times, act_data)\n",
    "plt.plot(times, 0.8*np.ones_like(times), 'k--')\n",
    "plt.title('ACT', fontsize=tit_s)\n",
    "plt.xlabel('time [s]', fontsize=lab_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "\n",
    "err_fig = plt.figure(figsize=fs)\n",
    "w_len = 1001\n",
    "hand_error = np.linalg.norm(c_hand-des_coords, axis=1)\n",
    "smooth_hand_error = smooth(hand_error, window_len=w_len)[int(np.floor(w_len/2)):-int(np.floor(w_len/2))]\n",
    "plt.plot(times, smooth_hand_error)\n",
    "plt.plot(times, hand_error, 'r--')\n",
    "plt.plot(times, 0.1+np.zeros(smooth_hand_error.size), 'k--')\n",
    "plt.title('distance from target', fontsize=tit_s)\n",
    "avg_error = hand_error.sum()/hand_error.size\n",
    "print(\"average error: %f\" % (avg_error))\n",
    "plt.xlabel('time [s]', fontsize=lab_s)\n",
    "plt.ylabel('error [m]', fontsize=lab_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to arrange the multiunit data from the various reaches\n",
    "def get_tensor(series, J=n_trgs, K=n_rounds, T=int(round(t_pres / net.min_delay))):\n",
    "    \"\"\" Given a simulation time series, arrange it by reach and repetition.\n",
    "    \n",
    "        Args:\n",
    "            series : a time series, spanning simtime2 seconds, in min_delay steps.\n",
    "            J : number of targets in the simulation.\n",
    "            K : number of repetitions of each target.\n",
    "            T : number of time steps that each target is presented.\n",
    "            \n",
    "        Returns:\n",
    "            tensor : a 3-dimensional array. tensor(j,k,t) is the value of the series\n",
    "                     for target j, on the k-th repetition, at time step t. Time steps\n",
    "                     begin anew for each reach.\n",
    "    \"\"\"\n",
    "    tensor = np.zeros((J, K, T))\n",
    "    print(tensor.shape)\n",
    "    trg_reps = np.zeros(J, dtype=int) # how many repetitions of each target we have filled\n",
    "\n",
    "    for reach, trg in enumerate(trg_ids):\n",
    "        init_tid = (1 + 2 * reach) * T\n",
    "        final_tid = init_tid + T # t_pres seconds later\n",
    "        tensor[trg, trg_reps[trg],:] = series[init_tid:final_tid]\n",
    "        trg_reps[trg] += 1\n",
    "        \n",
    "    return tensor\n",
    "\n",
    "def get_pop_tensor(pop, J=n_trgs, K=n_rounds, t_smp =.5, t_strt=0., trg_ids=trg_ids):\n",
    "    \"\"\" Returns a tensor with the activities in a population arranged by target and repetition.\n",
    "    \n",
    "        Args:\n",
    "            pop : a list with the IDs of the populations units in the 'data' matrix.\n",
    "            J : number of targets in the simulation.\n",
    "            K : number of repetitions of each target.\n",
    "            t_smp : time to sample per reach (in seconds)\n",
    "            t_strt : time after target onset when sample begins.\n",
    "            trg_ids : trg_ids[i] is the target at the i-th reach\n",
    "        Returns:\n",
    "            tensor : a 4-dimensional array. tensor(i,j,k,t) is the activity of the i-th\n",
    "                     unit, when reaching target j, on the k-th repetition, at time step t.\n",
    "    \"\"\"\n",
    "    idx_strt = int(t_strt / net.min_delay)\n",
    "    I = len(pop)\n",
    "    T=int(t_smp / net.min_delay) # number of time steps that each target is presented.\n",
    "    tensor = np.zeros((I,J,K,T), dtype=np.float_)\n",
    "\n",
    "    trg_reps = np.zeros(J, dtype=int) # how many repetitions of each target we have filled\n",
    "    pt_per_pres = int(round(t_pres / net.min_delay)) # t_pres should be an argument!\n",
    "    for reach, trg in enumerate(trg_ids):\n",
    "        init_tid = (1 + 2 * reach) * pt_per_pres + idx_strt\n",
    "        final_tid = init_tid + int(t_smp/net.min_delay) # t_smp seconds later\n",
    "        tensor[:, trg, trg_reps[trg],:] = data[pop, init_tid:final_tid]\n",
    "        trg_reps[trg] += 1\n",
    "        \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange the error data into a tensor\n",
    "# he_tensor[j,k,t] is the hand tensor for target j,\n",
    "# o the k-th presentation, at time t\n",
    "J = n_trgs # number of targets\n",
    "K = n_rounds # number of repetitions per target\n",
    "T = int(round(t_pres / net.min_delay)) # number of time points\n",
    "\n",
    "he_tensor = get_tensor(hand_error, J=J, K=K, T=T)\n",
    "    \n",
    "# we average across repetitions of the same target\n",
    "ahe_trg = he_tensor.sum(axis=1) / K\n",
    "\n",
    "# we average across all reaches\n",
    "ahe = ahe_trg.sum(axis=0) / J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print distance to target for each target\n",
    "ahe_fig = plt.figure(figsize=fs)\n",
    "reach_ts = np.linspace(0., t_pres, T)\n",
    "plt.plot(reach_ts, ahe, linewidth=4)\n",
    "plt.title(\"Distance to target (average across all targets)\", fontsize=tit_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "\n",
    "n_rows = 2\n",
    "n_cols = 4\n",
    "ahe_trg_fig, ahe_trg_axs = plt.subplots(n_rows, n_cols, figsize=(fs[0], 2*fs[1]), sharey=True)\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        ax = ahe_trg_axs[row,col]\n",
    "        trg = row*n_cols + col\n",
    "        ax.plot(reach_ts, ahe_trg[trg, :], linewidth=4)\n",
    "        ax.tick_params(axis='both', labelsize=tic_s)\n",
    "        ax.set_title(\"target \" + str(trg), fontsize=tit_s)\n",
    "        for rep in range(K):\n",
    "            ax.plot(reach_ts, he_tensor[trg,rep,:], '--', linewidth=1, color='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain hand coordinates through time\n",
    "from numpy import cos, sin\n",
    "if not 'targets' in locals():\n",
    "    targets = np.array([[0.3, 0.3]])\n",
    "\n",
    "# angles of shoulder and elbow\n",
    "theta_s = arm_activs[:,0]\n",
    "theta_e = arm_activs[:,2]\n",
    "phi = theta_s + theta_e # elbow angle wrt x axis\n",
    "# data from tracking units\n",
    "ipx = data[ipx_track,:]\n",
    "ipy = data[ipy_track,:]\n",
    "ten = arm_activs[:, np.array(range(4,10))].transpose()\n",
    "# coordinates of hand and elbow\n",
    "l1 = net.plants[P].l_arm\n",
    "l2 = net.plants[P].l_farm\n",
    "xe = cos(theta_s)*l1\n",
    "ye = sin(theta_s)*l1\n",
    "xh = xe + cos(phi)*l2\n",
    "yh = ye + sin(phi)*l2\n",
    "\n",
    "# placing hand coordinates in tensors (arrange by target, repetition)\n",
    "xh_tensor = get_tensor(xh, J=J, K=K, T=T)\n",
    "yh_tensor = get_tensor(yh, J=J, K=K, T=T)\n",
    "    \n",
    "# average across reptitions of the same target\n",
    "axh_trg = xh_tensor.sum(axis=1) / K\n",
    "ayh_trg = yh_tensor.sum(axis=1) / K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain velocity profile for the reaches\n",
    "xph = np.concatenate(([0], (xh[1:] - xh[:-1]) / net.min_delay))\n",
    "yph = np.concatenate(([0], (yh[1:] - yh[:-1]) / net.min_delay))\n",
    "hv = np.sqrt(xph*xph + yph*yph)\n",
    "\n",
    "hv_tensor = get_tensor(hv)\n",
    "\n",
    "# we average across repetitions of the same target\n",
    "ahv_trg = hv_tensor.sum(axis=1) / K\n",
    "\n",
    "# we average across all reaches\n",
    "ahv = ahv_trg.sum(axis=0) / J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print velocity for each target\n",
    "ahv_fig = plt.figure(figsize=fs)\n",
    "reach_ts = np.linspace(0., t_pres, T)\n",
    "plt.plot(reach_ts, ahe, linewidth=4)\n",
    "plt.plot(reach_ts, ahv,  'r', linewidth=4)\n",
    "#plt.title(\"hand velocity (average across all targets)\", fontsize=tit_s)\n",
    "plt.title(\"Average across all targets\", fontsize=tit_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "#plt.ylabel('velocity [m/s]', fontsize=lab_s)\n",
    "plt.xlabel('time [s]', fontsize=lab_s)\n",
    "plt.legend(['error [m]', 'speed [m/s]'], fontsize=leg_s)\n",
    "\n",
    "n_rows = 2\n",
    "n_cols = 4\n",
    "ahv_trg_fig, ahv_trg_axs = plt.subplots(n_rows, n_cols, figsize=(fs[0], 2*fs[1]), sharey=True)\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        ax = ahv_trg_axs[row,col]\n",
    "        trg = row*n_cols + col\n",
    "        ax.plot(reach_ts, ahv_trg[trg, :], 'r', linewidth=4)\n",
    "        ax.tick_params(axis='both', labelsize=tic_s)\n",
    "        ax.set_title(\"target \" + str(trg), fontsize=tit_s)\n",
    "        for rep in range(K):\n",
    "            ax.plot(reach_ts, hv_tensor[trg,rep,:], '--', linewidth=1, color='red')\n",
    "        if col==0:\n",
    "            ax.set_ylabel('velocity [m/s]', fontsize=lab_s)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average reach trajectories and some individual reaches\n",
    "n_ind_reaches = 6 # number of example reaches to plot\n",
    "reach_fig = plt.figure(figsize=(10,10))\n",
    "reach_ax = plt.gca()\n",
    "trial = 0\n",
    "reach_ax.scatter(targets[:,0], targets[:,1], s=1800, c='cyan')\n",
    "# reach_ax.scatter(center[0]+.8*(targets[:,0]-center[0]), \n",
    "#                 center[1]+.8*(targets[:,1]-center[1]), s=1800, c='k', alpha=0.3)\n",
    "#reach_ax.scatter(.6*(targets[:,0]+center[0]), .6*(targets[:,1]+center[1]), s=1000, c='cyan', alpha=0.4)\n",
    "reach_ax.scatter(center[0], center[1], s=2000, c='blue')\n",
    "reach_ax.tick_params(axis='both', labelsize=tic_s)\n",
    "reach_ax.set_xlabel('X [m]', fontsize=lab_s)\n",
    "reach_ax.set_ylabel('Y [m]', fontsize=lab_s)\n",
    "reach_ax.set_xticks([0.2, 0.25, 0.3, 0.35, 0.4])\n",
    "reach_ax.set_xticks([0.2, 0.25, 0.3, 0.35, 0.4])\n",
    "plt.axis('equal')\n",
    "reach_ax.grid()\n",
    "cmap = [[0.1, 0.4, 0.8, 0.5],\n",
    "        [0.9, 0.7, 0.2, 0.8],\n",
    "        [0.1, 0.7, 0.1, 0.6],\n",
    "        [0.9, 0.1, 0.1, 0.5],\n",
    "        [0.6, 0.2, 0.6, 0.5],\n",
    "        [0.8, 0.4, 0.1, 0.5],\n",
    "        [0.7, 0.1, 0.7, 0.5],\n",
    "        [0.3, 0.3, 0.3, 0.5]]\n",
    "for trg in range(J):\n",
    "    reach_ax.plot(axh_trg[trg,:], ayh_trg[trg,:], linewidth=3)\n",
    "    for rep in range(min(n_ind_reaches, K)):\n",
    "        reach_ax.plot(xh_tensor[trg, rep, :], yh_tensor[trg, rep, :], '--', linewidth=1, color=cmap[trg])\n",
    "#from IPython.display import Image\n",
    "#Image(filename='temp_fig')\n",
    "#plt.savefig('temp_fig2')\n",
    "reach_ax.set_xlim([0.16, .44])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power spectrum\n",
    "pop_id = M[0]\n",
    "from spectrum import *\n",
    "fig1 = plt.figure()\n",
    "spec_data = data[pop_id][0:8192]\n",
    "spec_data = spec_data - np.mean(spec_data)\n",
    "p = Periodogram(spec_data, sampling=(1./net.min_delay))\n",
    "p.plot(marker='o')\n",
    "plt.xlim([0,10])\n",
    "\n",
    "fig2 = plt.figure()\n",
    "res = pmtm(spec_data, NW=2.5, k=4, show=True)\n",
    "plt.xlim([0,800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Direction tuning analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the prefered directions for the units in M\n",
    "# Find the mean rate for each target\n",
    "t_smp = 4. # time to sample M (in seconds)\n",
    "I = 12 # number of units to consider in M\n",
    "m_tensor = get_pop_tensor(M[:I], t_smp=t_smp)\n",
    "# m_tensor[i,j,k,t] is the activity of the i-th M \n",
    "# unit for target j, on the k-th repetition, at time point t.\n",
    "\n",
    "# Now we average across repetitions for the same target\n",
    "m_tensor_trg_avg = m_tensor.sum(axis=2) / K\n",
    "# m_tensor_trg_avg[i,j,t]: average activity of i-th M unit when\n",
    "# reaching for target j, at time point t\n",
    "\n",
    "m_avg_rates = np.zeros((I,J)) # average rate at each unit for each target\n",
    "for trg in range(J):\n",
    "    m_avg_rates[:, trg] = np.mean(m_tensor_trg_avg[:, trg, :], axis=1)\n",
    "\n",
    "m_means = np.mean(m_avg_rates, axis=1) # mean rate for each unit\n",
    "    \n",
    "# Obtaining preferred directions by fitting the rates using a plane, and using\n",
    "# the angle of the projection of this plane's normal vector onto the XY plane\n",
    "# The coefficients of the normal vector can be calculated using the least-squares\n",
    "# method, which leads to a 3x3 linear system that is readily reduced to a 2x2 system.\n",
    "trgs = targets - center # targets centered at the origin\n",
    "xs = trgs[:,0]\n",
    "ys = trgs[:,1]\n",
    "cxs = xs - np.mean(xs) # \"centered\" x coordinates\n",
    "cys = ys - np.mean(ys) #  \"centered\" Y coordinates\n",
    "\n",
    "X11 = (xs * cxs).sum()\n",
    "X12 = (xs * cys).sum()\n",
    "X21 = (ys * cxs).sum()\n",
    "X22 = (ys * cys).sum()\n",
    "\n",
    "Amat = np.array([[X11, X12], [X21, X22]])\n",
    "detA = np.linalg.det(Amat) # determinant of Amat\n",
    "if detA == 0.:\n",
    "    raise ValueError('Indeterminate system found!')\n",
    "invA = np.linalg.inv(Amat)\n",
    "\n",
    "prf_angs = np.zeros(len(M)) # preferred angles, in radians\n",
    "normal_vecs = [] # list with the vectors normal to the plane fitting the rates\n",
    "\n",
    "print(\"Coeffs. of determination for PD vectors.\")\n",
    "for uid in range(I):\n",
    "    r1 = (xs * (m_avg_rates[uid, :] - m_means[uid])).sum()\n",
    "    r2 = (ys * (m_avg_rates[uid, :] - m_means[uid])).sum()\n",
    "    n = np.matmul(invA, np.array([r1,r2]))\n",
    "    # boils down to\n",
    "    #n = [a,b] where b = r2/X22, a = r1/X11\n",
    "    #normal_vecs.append(n / np.linalg.norm(n)) # appending normalized vector\n",
    "    normal_vecs.append(n)\n",
    "    prf_angs[uid] = np.arctan2(n[1], n[0]) # preferred angle\n",
    "    #print(\"n1=%f, n0=%f, prf_ang=%f\"%(n[1],n[0]))\n",
    "\n",
    "    c = np.mean(m_avg_rates[uid,:] - n[0]*xs - n[1]*ys)\n",
    "    \n",
    "    # obtaining residuals, coefficient of determination, R^2\n",
    "    residuals = m_avg_rates[uid,:] - n[0]*xs - n[1]*ys - c\n",
    "    devs = m_avg_rates[uid,:] - m_means[uid]\n",
    "    SSr = (residuals * residuals).sum()\n",
    "    SSt = (devs * devs).sum()\n",
    "    R = 1. - (SSr/SSt)\n",
    "    print(R)\n",
    "\n",
    "normal_vecs = np.array(normal_vecs)\n",
    "\n",
    "# Get the lengths of the preferred direction vectors\n",
    "pd_norms = np.linalg.norm(normal_vecs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining predicted PDs\n",
    "\n",
    "def ang_diff(a1, a2):\n",
    "    \"\"\" Difference between two angles in the range [-pi, pi]. \"\"\"\n",
    "    big_a = max(a1,a2)\n",
    "    lil_a = min(a1,a2)\n",
    "    if lil_a < 0 and big_a > 0:\n",
    "        diff = min(np.pi-big_a - lil_a, big_a-lil_a)\n",
    "    else:\n",
    "        diff = big_a - lil_a\n",
    "    return diff\n",
    "\n",
    "# len_diffs[i,j] is the required length of contraction for muscle i, target j, divided by the length in the rest position\n",
    "# This is obtained in 'source_code_2'\n",
    "len_diffs = np.array( [[0.        , 0.        , 0.00512814, 0.02957183, 0.03340439, 0.01043197, 0.        , 0.        ],\n",
    "                       [0.02868621, 0.13750184, 0.16861731, 0.12856412, 0.02810964, 0.        , 0.        , 0.        ],\n",
    "                       [0.        , 0.        , 0.        , 0.        , 0.        , 0.10604558, 0.16349133, 0.10088526],\n",
    "                       [0.0308563 , 0.01576455, 0.        , 0.        , 0.        , 0.        , 0.01655006, 0.03257554],\n",
    "                       [0.        , 0.        , 0.        , 0.        , 0.09134384, 0.13319637, 0.09134384, 0.        ],\n",
    "                       [0.11777032, 0.16048272, 0.11777032, 0.0165468 , 0.        , 0.        , 0.        , 0.0165468 ]])\n",
    "\n",
    "ldiff_vecs = np.zeros((6,2))\n",
    "ldiff_angs = np.zeros(6)\n",
    "angs = np.linspace(0., 2.*np.pi, J+1)[:-1]\n",
    "for idx, lds in enumerate(len_diffs):\n",
    "    ldiff_vecs[idx,0] = (lds*np.cos(angs)).sum()\n",
    "    ldiff_vecs[idx,1] = (lds*np.sin(angs)).sum()\n",
    "    ldiff_angs[idx] = np.arctan2(ldiff_vecs[idx,1], ldiff_vecs[idx,0])\n",
    "\n",
    "# obtain the connection matrix\n",
    "# SPF__M_ws[i,j]: weight from j-th SPF unit to i-th M unit\n",
    "SPF__M_ws = np.zeros((len(M), len(SPF)))\n",
    "if rot_SPF:\n",
    "    for m_idx, m in enumerate(M):\n",
    "        w_list = [syn.w for syn in net.syns[m] if syn.preID in SPF]\n",
    "        SPF__M_ws[m_idx, :] = w_list\n",
    "else:\n",
    "    SPF__M_ws = np.eye(12)\n",
    "    \n",
    "# Obtain predicted PD vectors\n",
    "pred_pds = np.zeros((12,2)) # predicted PD vectors for the 12 M units\n",
    "for m_idx, m_ws in enumerate(SPF__M_ws):\n",
    "    for idx, vec in enumerate(ldiff_vecs):\n",
    "        pred_pds[m_idx,:] += (m_ws[idx]-m_ws[idx+6]) * vec\n",
    "        \n",
    "# angle and norm of the PD vectors\n",
    "pred_angs = np.zeros(12)\n",
    "pred_norms = np.zeros(12)\n",
    "for idx, pd in enumerate(pred_pds):\n",
    "    pred_angs[idx] = np.arctan2(pd[1], pd[0])\n",
    "    pred_norms[idx] = np.linalg.norm(pd)\n",
    "    \n",
    "# Coefficients of determination for the predicted angles (\"unweighted\" version)\n",
    "pred_residuals1 = np.array([ang_diff(a1,a2) for a1,a2 in zip(pred_angs, prf_angs)])\n",
    "ang_devs1 = np.array([ang_diff(a1, np.mean(prf_angs)) for a1 in prf_angs])\n",
    "SSr1 = (pred_residuals1 * pred_residuals1).sum()\n",
    "SSt1 = (ang_devs1 * ang_devs1).sum()\n",
    "R1 = 1. - (SSr1/SSt1)\n",
    "\n",
    "# Coefficients of determination for the predicted angles (\"weighted\" version)\n",
    "pred_residuals2 = np.array([ang_diff(a1,a2) for a1,a2 in zip(pred_angs, prf_angs)])\n",
    "pred_residuals2 = pred_residuals2 * pd_norms\n",
    "ang_devs2 = np.array([ang_diff(a1, np.mean(prf_angs)) for a1 in prf_angs])\n",
    "ang_devs2 = ang_devs2 * pd_norms\n",
    "SSr2 = (pred_residuals2 * pred_residuals2).sum()\n",
    "SSt2 = (ang_devs2 * ang_devs2).sum()\n",
    "R2 = 1. - (SSr2/SSt2)\n",
    "\n",
    "print(\"unweighted R: %f, weighted R: %f\" % (R1, R2))\n",
    "\n",
    "# Plot direction tuning for all M units\n",
    "n_rows = 2\n",
    "n_cols = 6\n",
    "dir_fig, dir_axs = plt.subplots(n_rows, n_cols, figsize=(1.7*fs[0], 2.4*fs[1]), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "# m_avg_rates[i,j]: average rate of i-th M unit \n",
    "# when reaching for target j\n",
    "span = max(m_avg_rates.flatten()) * max(trgs.flatten())\n",
    "theta = np.linspace(0.0, 2 * np.pi, J, endpoint=False)\n",
    "width = np.pi / J\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        ax = dir_axs[row][col]\n",
    "        m_id = n_cols*row + col\n",
    "        ax.set_title(\"M = %d\" % (m_id), fontsize=20) \n",
    "        ax.bar(theta, m_avg_rates[m_id, :], width=width, bottom=0.0, color='b', alpha=0.3)\n",
    "        #ax.bar(prf_angs[m_id], .5*pd_norms[m_id], width=np.pi/32, bottom=0.0, color='r')\n",
    "        ax.arrow(prf_angs[m_id],.01, 0., .35*pd_norms[m_id], width=0.07,\n",
    "             head_width=0.15, head_length=0.1, length_includes_head=True, color='r')\n",
    "        ax.arrow(pred_angs[m_id],.01, 0., .35*pred_norms[m_id], width=0.03,\n",
    "                 head_width=0.1, head_length=0.07, length_includes_head=True, color='k')\n",
    "        ax.tick_params(axis='x', labelsize=22)\n",
    "        ax.tick_params(axis='y', labelsize=18)\n",
    "        if use_syne:\n",
    "            ax.set_yticks([.1, .3, .5])\n",
    "        else:\n",
    "            ax.set_yticks([.1, .25, .5])\n",
    "                    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot per-target mean activity for first A units\n",
    "\n",
    "at_smp = 2. # time to sample M (in seconds)\n",
    "at_strt =1.\n",
    "aI = 6 # number of units to consider in A\n",
    "a_tensor = get_pop_tensor(A[:aI], J=J, K=K, t_smp=at_smp, t_strt=at_strt)\n",
    "a_tensor_trg_avg = a_tensor.sum(axis=2) / K\n",
    "angs = np.linspace(0., 2.*np.pi, J+1)[:-1]\n",
    "\n",
    "a_avg_rates = np.zeros((aI,J)) # average rate at each unit for each target\n",
    "for trg in range(J):\n",
    "    a_avg_rates[:, trg] = np.mean(a_tensor_trg_avg[:, trg, :], axis=1)\n",
    "\n",
    "# obtain average vector\n",
    "a_vecs = np.zeros((6,2))\n",
    "a_angs = np.zeros(6)\n",
    "for idx, arat in enumerate(a_avg_rates):\n",
    "    a_vecs[idx,0] = (arat*np.cos(angs)).sum()\n",
    "    a_vecs[idx,1] = (arat*np.sin(angs)).sum()\n",
    "    a_angs[idx] = np.arctan2(a_vecs[idx,1], a_vecs[idx,0])\n",
    "a_norms = np.linalg.norm(a_vecs, axis=1)\n",
    "\n",
    "dir_fig, dir_axs = plt.subplots(1, 6, figsize=(1.7*fs[0], fs[1]), subplot_kw=dict(projection='polar'), sharey=True)\n",
    "\n",
    "# a_avg_rates[i,j]: average rate of i-th M unit \n",
    "# when reaching for target j\n",
    "span = max(a_avg_rates.flatten()) * max(trgs.flatten())\n",
    "theta = np.linspace(0.0, 2 * np.pi, J, endpoint=False)\n",
    "width = np.pi / J\n",
    "for col in range(aI):\n",
    "    ax = dir_axs[col]\n",
    "    a_id = col\n",
    "    ax.set_title(\"A = %d\" % (a_id), fontsize=20) \n",
    "    ax.bar(theta, a_avg_rates[a_id, :], width=width, bottom=0.0, color='r', alpha=0.3)\n",
    "    ax.arrow(a_angs[a_id],.01, 0., 0.5*a_norms[a_id], width=0.07,\n",
    "         head_width=0.15, head_length=0.1, length_includes_head=True, color='k')\n",
    "    ax.tick_params(axis='x', labelsize=22)\n",
    "    ax.tick_params(axis='y', labelsize=18)\n",
    "    ax.set_yticks([.2, .4, .6])\n",
    "                     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess how many units are \"significantly tuned\" to reach direction we can use a bootstrap method. Basically, you shuffle the identities of the targets used (the `trg_ids` array), and calculate the length of the preferred direction (PD) vector (`normal_vecs`) for each cell. After producing $N$ different permutations of the targets, you have $N$ PD vectors for each unit. A cell is significantly tuned if the length of its PD vector is larger than $.999N$ of the PD vectors.\n",
    "\n",
    "This is based on [Scott and Kalaska 1997](https://journals.physiology.org/doi/full/10.1152/jn.1997.77.2.826)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess if significantly tuned to direction\n",
    "\n",
    "N_shuffles = 10000 # number of target permutations to produce\n",
    "sh_pd_norms = np.zeros((I, N_shuffles)) # magnitude of PD vector for each cell, all shuffles\n",
    "#m_rates_tensor = np.mean(m_tensor, axis=3)\n",
    "# m_rates_tensor[i,j,k]: mean firing rate for cell i on k-th presentation of target j\n",
    "for n_idx in range(N_shuffles):\n",
    "    sh_trg_ids = np.random.permutation(trg_ids)\n",
    "    sh_m_tensor = get_pop_tensor(M[:I], J=J, K=K, t_smp=t_smp, trg_ids=sh_trg_ids)\n",
    "    sh_m_tensor_trg_avg = sh_m_tensor.sum(axis=2) / K\n",
    "    sh_m_avg_rates = np.zeros((I,J)) # average rate at each unit for each target\n",
    "    for trg in range(J):\n",
    "        sh_m_avg_rates[:, trg] = np.mean(sh_m_tensor_trg_avg[:, trg, :], axis=1)\n",
    "    sh_m_means = np.mean(sh_m_avg_rates, axis=1) # mean rate for each unit\n",
    "    sh_normal_vecs = np.zeros((I,2))\n",
    "    for uid in range(I):\n",
    "        r1 = (xs * (sh_m_avg_rates[uid, :] - sh_m_means[uid])).sum()\n",
    "        r2 = (ys * (sh_m_avg_rates[uid, :] - sh_m_means[uid])).sum()\n",
    "        n = np.matmul(invA, np.array([r1,r2]))\n",
    "        sh_normal_vecs[uid,:] = n\n",
    "    sh_pd_norms[:, n_idx] = np.linalg.norm(sh_normal_vecs, axis=1)\n",
    "    \n",
    "# Now, for each unit, find vlue of sh_pd_norms that is larger than 99%\n",
    "sig_threshs = np.percentile(sh_pd_norms, 99.9, axis=1)\n",
    "\n",
    "# For each unit, check if it is significantly tuned\n",
    "tuned = pd_norms >= sig_threshs\n",
    "print(tuned)\n",
    "n_tuned = tuned.sum()\n",
    "print(n_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of preferred directions for the 12 cells\n",
    "\n",
    "pd_scaling = True # whether to scale angle contributions by length of PD vector\n",
    "# Find the angle of the dominant axis of the skew (bimodal version)\n",
    "mod_prf_angs = [ang if ang > 0. else ang+np.pi for ang in prf_angs]\n",
    "dom_ang = np.arctan2(np.sin(mod_prf_angs).sum(), np.cos(mod_prf_angs).sum())\n",
    "# if the contribution of each angle is scaled by the norm of its PD vector we get sc_dom_ang\n",
    "sc_dom_ang = np.arctan2((np.sin(mod_prf_angs)*pd_norms).sum(), (np.cos(mod_prf_angs)*pd_norms).sum())\n",
    "dom_ang_deg = dom_ang * 180./np.pi # angle of dominant axis in degrees\n",
    "sc_dom_ang_deg = sc_dom_ang * 180. / np.pi\n",
    "\n",
    "if pd_scaling:\n",
    "    d_a = sc_dom_ang\n",
    "    d_a_deg = sc_dom_ang_deg\n",
    "else:\n",
    "    d_a = dom_ang\n",
    "    d_a_deg = dom_ang_deg\n",
    "    \n",
    "print(\"Angle of dominant axis: %f\" %(d_a_deg))\n",
    "\n",
    "#sig_prf_angs = prf_angs\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=fs)\n",
    "#ax.plot(prf_angs, np.ones(len(prf_angs)), '*')\n",
    "#ax.plot(prf_angs, pd_norms, '^')\n",
    "for uid in range(len(prf_angs)):\n",
    "    ax.arrow(prf_angs[uid],.001, 0., pd_norms[uid], width=0.01,\n",
    "             head_width=0.1, head_length=0.2, length_includes_head=True)\n",
    "#ax.bar(prf_angs, np.ones(len(prf_angs)), width=np.pi/40, color='b', alpha=0.3)\n",
    "#ax.bar(prf_angs, pd_norms, width=np.pi/40, alpha=0.3)\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.set_yticks([.5, 1., 1.5])\n",
    "ax.set_rmax(1.1*max(pd_norms))\n",
    "ax.plot([d_a, d_a], [0., 1.05*max(pd_norms)], 'k--', alpha=0.5)\n",
    "ax.plot([d_a+np.pi, d_a+np.pi], [0., 1.05*max(pd_norms)], 'k--', alpha=0.5)\n",
    "ax.plot([d_a+np.pi/4., d_a+np.pi/4.], [0., 1.05*max(pd_norms)], 'r--')\n",
    "ax.plot([d_a+np.pi+np.pi/4., d_a+np.pi+np.pi/4.], [0., 1.05*max(pd_norms)], 'r--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of preferred directions for the 12 cells, only ones with large norm\n",
    "big_norms_idx = np.arange(len(pd_norms))[pd_norms > np.mean(pd_norms)]\n",
    "sig_prf_angs = prf_angs[big_norms_idx]\n",
    "#sig_prf_angs = prf_angs[tuned]\n",
    "mod_sig_prf_angs = [ang if ang > 0. else ang+np.pi for ang in sig_prf_angs]\n",
    "# Find the angle of the dominant axis of the skew (bimodal version)\n",
    "sig_dom_ang = np.arctan2(np.sin(mod_sig_prf_angs).sum(), np.cos(mod_sig_prf_angs).sum())\n",
    "sig_dom_ang_deg = sig_dom_ang * 180./np.pi # angle of dominant axis in degrees\n",
    "print(\"Angle of dominant axis: %f\" %(sig_dom_ang_deg))\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.plot(sig_prf_angs, np.ones(len(sig_prf_angs)), '*')\n",
    "ax.bar(sig_prf_angs, np.ones(len(sig_prf_angs)), width=np.pi/40, color='b', alpha=0.3)\n",
    "ax.set_rmax(1.1*max(pd_norms))\n",
    "ax.plot([sig_dom_ang, sig_dom_ang], [0., 1.1], 'k--', alpha=0.5)\n",
    "ax.plot([sig_dom_ang+np.pi, sig_dom_ang+np.pi], [0., 1.1], 'k--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining unimodal and bimodal Rayleigh r statistics\n",
    "# These are twice the value of those in Lillicrap and Scott 2013 for the unimodal case\n",
    "r_unimod = 2. * ((np.sin(prf_angs).sum())**2 + (np.cos(prf_angs).sum())**2) / I\n",
    "r_bimod =  ((np.sin(2.*prf_angs).sum())**2 + (np.cos(2.*prf_angs).sum())**2) / I\n",
    "\n",
    "# Significance threshold for unimodal r\n",
    "a = .99\n",
    "x_c = np.sqrt(-2.*np.log(1 - a))\n",
    "\n",
    "# Significance threshold for bimodal r\n",
    "n_samples = 100000 # how many times the r statistic is randomly produced\n",
    "rnd_angles = 2.*np.pi*np.random.random((n_samples, I)) # 10000 random angles sets in (0,2pi)\n",
    "rnd_r_bim = (np.sin(2.*rnd_angles).sum(axis=1)**2 + \n",
    "             np.cos(2.*rnd_angles).sum(axis=1)**2) / I\n",
    "\n",
    "sig_r_thresh = np.percentile(rnd_r_bim, 99.)\n",
    "\n",
    "print(\"r_unimod=%f, r_bimod=%f, x_c=%f, x_c_bim=%f\" % (r_unimod, r_bimod, x_c, sig_r_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining unimodal and bimodal Rayleigh r statistics, big norms\n",
    "# These are twice the value of those in Lillicrap and Scott 2013\n",
    "r_unimod = 2. * ((np.sin(sig_prf_angs).sum())**2 + (np.cos(sig_prf_angs).sum())**2) / sig_prf_angs.size\n",
    "r_bimod = ((np.sin(2.*sig_prf_angs).sum())**2 + (np.cos(2.*sig_prf_angs).sum())**2) / sig_prf_angs.size\n",
    "\n",
    "# Significance threshold\n",
    "a = .99\n",
    "x_c = np.sqrt(-2.*np.log(1 - a))\n",
    "\n",
    "# Significance threshold for bimodal r\n",
    "n_samples = 100000 # how many times the r statistic is randomly produced\n",
    "rnd_angles = 2.*np.pi*np.random.random((n_samples, sig_prf_angs.size))\n",
    "rnd_r_bim = (np.sin(2.*rnd_angles).sum(axis=1)**2 + \n",
    "             np.cos(2.*rnd_angles).sum(axis=1)**2) / sig_prf_angs.size\n",
    "\n",
    "sig_r_thresh = np.percentile(rnd_r_bim, 99.)\n",
    "\n",
    "print(\"r_unimod=%f, r_bimod=%f, x_c=%f, x_c_bim=%f\" % (r_unimod, r_bimod, x_c, sig_r_thresh))\n",
    "bimodal = r_bimod > x_c\n",
    "print(bimodal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Circular dynamics analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jPCA analysis part 1\n",
    "\n",
    "# the first step is to obtain m_tensor\n",
    "t_smp = 1. # time to sample M (in seconds) t_smp=.6, t_strt=1.\n",
    "t_strt = 1.1 # time after target onset when sample begins\n",
    "normalize=False\n",
    "idx_strt = int(t_strt / net.min_delay)\n",
    "\n",
    "I = 12 #12 # number of dimensions to consider in M\n",
    "# J = n_trgs # number of targets\n",
    "# K = n_rounds # number of repetitions per target\n",
    "T = int(t_smp / net.min_delay) # number of time points\n",
    "\n",
    "m_tensor = get_pop_tensor(M[:I], J=J, K=K, t_smp=t_smp, t_strt=t_strt)\n",
    "\n",
    "# Normalize responses in m_tensor\n",
    "if normalize:\n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            for k in range(K):\n",
    "                norm = np.linalg.norm(m_tensor[i,j,k,:])\n",
    "                m_tensor[i,j,k,:] = m_tensor[i,j,k,:] / norm\n",
    "    \n",
    "# Now we average across repetitions for the same target\n",
    "p_tensor = m_tensor.sum(axis=2) / K\n",
    "\n",
    "# We obtain the across-condition average\n",
    "a_tensor = p_tensor.sum(axis=1) / J\n",
    "\n",
    "# Obtained a normalized average trace per condition\n",
    "c_tensor = np.zeros_like(p_tensor)\n",
    "for trg in range(J):\n",
    "    c_tensor[:, trg, :] = p_tensor[:, trg, :] - a_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "munit = 0\n",
    "# trg_fig = plt.figure(figsize=fs)\n",
    "# plt.plot(times[:T], m_tensor[munit,5,0,:])\n",
    "\n",
    "M_fig = plt.figure(figsize=fs)\n",
    "# M_data = np.array(data[M])\n",
    "initl = int(4.*6./net.min_delay)\n",
    "plt_strt = initl + int(t_strt / net.min_delay)\n",
    "plt_stop = initl + int(t_strt / net.min_delay) + T\n",
    "plt.plot(times[initl:plt_stop+50], M_data[:, initl:plt_stop+50].transpose(), linewidth=2)\n",
    "plt.plot([times[plt_strt], times[plt_strt]], [0.1, .7], 'k--')\n",
    "plt.plot([times[plt_stop], times[plt_stop]], [0.1, .7], 'k--')\n",
    "plt.title(\"M firing rates\", fontsize=tit_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "plt.xlabel('Simulation time [s]', fontsize=lab_s)\n",
    "#plt.plot(times[0:T], data[M[0], 0:T])\n",
    "\n",
    "c_fig = plt.figure(figsize=fs)\n",
    "plt.plot(np.linspace(0., t_smp, T), c_tensor[:,6,:].transpose())\n",
    "#plt.plot([times[plt_strt], times[plt_strt]], [-0.015, .02], 'k--')\n",
    "#plt.plot([times[plt_stop], times[plt_stop]], [-0.015, .02], 'k--')\n",
    "plt.title(\"Normalized average M traces\", fontsize=tit_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "plt.xlabel('Sample time [s]', fontsize=lab_s)\n",
    "\n",
    "p_fig = plt.figure(figsize=fs)\n",
    "plt.plot(times[:T], p_tensor[:,6,:].transpose())\n",
    "plt.title(\"p\")\n",
    "\n",
    "a_fig = plt.figure(figsize=fs)\n",
    "plt.plot(times[:T], a_tensor[:,:].transpose())\n",
    "plt.title(\"a\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jPCA analysis part 2\n",
    "\n",
    "import scipy as sp\n",
    "# Obtain the plane of strongest rotation\n",
    "\n",
    "X = np.zeros((J*T,I))\n",
    "for j in range(J):\n",
    "    X[j*T:(j+1)*T, :] = c_tensor[:,j,:].transpose()\n",
    "\n",
    "# create the block-matrix version of X\n",
    "Xtilde = sp.linalg.block_diag(*([X]*I))\n",
    "\n",
    "# Create the H matrix\n",
    "n = X.shape[1]\n",
    "ct = X.shape[0]\n",
    "L = np.zeros((n,n), dtype=int)\n",
    "c = 0\n",
    "for row in range(n):\n",
    "    for col in range(row+1, n):\n",
    "        L[row, col] = c\n",
    "        L[col, row] = c\n",
    "        c += 1\n",
    "        \n",
    "H = np.zeros((n*n, int(0.5*n*(n-1))))\n",
    "for col in range(n):\n",
    "    for row in range(n):\n",
    "        if col > row:\n",
    "            H[n*col+row, L[col,row]] = 1.\n",
    "        elif row > col:\n",
    "            H[n*col+row, L[col,row]] = -1.\n",
    "            \n",
    "# Approximate the derivatives of X\n",
    "Xp = np.zeros_like(X)\n",
    "t_bit = times[1] - times[0]\n",
    "Xp[1:,:] = (X[1:,:] - X[:-1,:]) / t_bit\n",
    "\n",
    "xp = Xp.flatten('F')\n",
    "\n",
    "kstar = np.matmul(np.linalg.pinv(np.matmul(Xtilde, H)), xp)\n",
    "\n",
    "# reconstruct the matrix that generated the data\n",
    "Mstar = np.matmul(H, kstar).reshape(n,n)\n",
    "\n",
    "# Next,extract the eigenvalues of M.\n",
    "eig_vals, eig_vecs = np.linalg.eig(Mstar)\n",
    "# print(Mstar)\n",
    "# print(\"Eigenvalues: \")\n",
    "# print(eig_vals)\n",
    "# print(\"Eigenvectors: \")\n",
    "# print(eig_vecs)\n",
    "\n",
    "eig_vals_norms = np.sqrt((eig_vals * eig_vals.conj()).real)\n",
    "ev_sum = eig_vals_norms.sum()/2.\n",
    "var_percentages = eig_vals_norms[np.array([0,2,4,6,8,10])] / ev_sum\n",
    "print(\"Variance percentages by each conjugate eigenvalue pair\")\n",
    "print(var_percentages)\n",
    "\n",
    "# We obtain the plane of strongest rotations\n",
    "srt_idxs = np.argsort(-eig_vals_norms) # indexes for sorting in decreasing order\n",
    "srt_eig_vecs = eig_vecs[:, srt_idxs]\n",
    "u1 = (srt_eig_vecs[:,0] + srt_eig_vecs[:,1]).real\n",
    "u2 = (1j * (srt_eig_vecs[:,0] - srt_eig_vecs[:,1])).real\n",
    "u1 = u1 / np.linalg.norm(u1)\n",
    "u2 = u2 / np.linalg.norm(u2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jPCA analysis part 3\n",
    "\n",
    "#n_pts = int(t_smp / net.min_delay)\n",
    "n_pts = min(100, T-1) # number of points in the trace to plot\n",
    "# project activities into the plane of strongest rotations\n",
    "jPCA1_traces = np.zeros((J, T), dtype=np.float_)\n",
    "jPCA2_traces = np.zeros((J, T), dtype=np.float_)\n",
    "u1 = u1.reshape(1,I)\n",
    "u2 = u2.reshape(1,I)\n",
    "\n",
    "for target in range(J):\n",
    "    jPCA1_traces[target, :] = np.matmul(u1, c_tensor[:,target,:])\n",
    "    jPCA2_traces[target, :] = np.matmul(u2, c_tensor[:,target,:])\n",
    "\n",
    "    \n",
    "# RGB colormap. First entry is greenest, last is reddest\n",
    "cmap = [[0., .9, 0.],\n",
    "        [0., .7, 0.],\n",
    "        [0., .5, 0.],\n",
    "        [0., .2, 0.],\n",
    "        [.4, 0., 0.],\n",
    "        [.5, 0., 0.],\n",
    "        [.7, 0., 0.],\n",
    "        [.9, 0., 0.]]\n",
    "t0_jPC1s = [jPCA1_traces[target,0] for target in range(J)]\n",
    "jPC1_sortr = list(np.argsort(t0_jPC1s))\n",
    "#t0_jPC1s.sort() # sorting according to initial jPC1 component\n",
    "jpca_fig =  plt.figure(figsize=(12,12))\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "y_span = [min(jPCA2_traces.flatten()), max(jPCA2_traces.flatten())]\n",
    "x_span = [min(jPCA1_traces.flatten()), max(jPCA1_traces.flatten())]\n",
    "plt.plot([0.,0.], y_span, 'k', linewidth=1)\n",
    "plt.plot(x_span, [0., 0.], 'k', linewidth=1)\n",
    "plt.xlabel('$jPCA_1$', fontsize=lab_s)\n",
    "plt.ylabel('$jPCA_2$', fontsize=lab_s)\n",
    "for target in range(J):\n",
    "    c = cmap[jPC1_sortr.index(target)]\n",
    "    plt.plot(jPCA1_traces[target,:n_pts], jPCA2_traces[target,:n_pts], color=c, linewidth=4)\n",
    "    plt.scatter(jPCA1_traces[target,0], jPCA2_traces[target,0], s=200, color=c)\n",
    "    dx = jPCA1_traces[target,n_pts] - jPCA1_traces[target,n_pts-5]\n",
    "    dy = jPCA2_traces[target,n_pts] - jPCA2_traces[target,n_pts-5]\n",
    "    plt.arrow(jPCA1_traces[target,n_pts-5],jPCA2_traces[target,n_pts-5],\n",
    "         dx, dy, color=c, width=0.001, head_width=0.005)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jPCA part 4\n",
    "# Other measures of rotation\n",
    "\n",
    "# 1) average angle between X and Xp\n",
    "X_norms = np.linalg.norm(X, axis=1)\n",
    "Xp_norms = np.linalg.norm(Xp, axis=1)\n",
    "X_cos = (X * Xp).sum(axis=1) / (X_norms * Xp_norms + 1e-10)\n",
    "off = 0\n",
    "#X_cos = (np.roll(X,off,axis=0)[off:] * Xp[:-off]).sum(axis=1) / (np.roll(X_norms,off,axis=0)[off:] * Xp_norms[:-off] + 1e-10)\n",
    "#X_cos = (X[off:] * Xp[:-off]).sum(axis=1) / (X_norms[off:] * Xp_norms[:-off] + 1e-10)\n",
    "X_angs = np.arccos(X_cos)\n",
    "\n",
    "wid = 0.4 # widgth of window around pi/2 where X,Xp are \"orthogonal\"\n",
    "orth_fr = ((X_angs < np.pi/2+wid) & (X_angs > np.pi/2-wid)).sum() / len(X_angs)\n",
    "print(\"orthogonal fraction:%f\" % (orth_fr))\n",
    "n_bins = 30\n",
    "hist_fig = plt.figure(figsize=fs)\n",
    "plt.hist(X_angs, bins=n_bins)\n",
    "plt.xticks(ticks=[0., np.pi/4, np.pi/2, 3.*np.pi/4., np.pi],\n",
    "          labels=['0', '$\\pi/4$', '$\\pi/2$', '$3 \\pi/4$', '$\\pi$'], fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "plt.xlabel('angle [rads]', fontsize=lab_s)\n",
    "plt.ylabel('count', fontsize=lab_s)\n",
    "plt.show()\n",
    "\n",
    "# 2) Coefficients of determination\n",
    "# 2.1) Obtain unconstrained M matrix\n",
    "M_uncons = np.matmul(np.linalg.pinv(X), Xp)\n",
    "# 2.2) Reconstruct Xp with M_uncons\n",
    "Xp_uncons = np.matmul(X, M_uncons)\n",
    "# 2.3) Reconstruct Xp with Mstar\n",
    "Xp_skew = np.matmul(X, Mstar)\n",
    "# 2.4) Calculate residual sums of squares\n",
    "SSres_uncons = ((Xp - Xp_uncons) * (Xp - Xp_uncons)).sum()\n",
    "SSres_skew = ((Xp - Xp_skew) * (Xp - Xp_skew)).sum()\n",
    "# 2.5) Calculate the total sum of squares\n",
    "SStot = ((Xp-Xp.mean())*(Xp-Xp.mean())).sum()\n",
    "# 2.6) Calculate coefficients of determination\n",
    "R2_uncons = 1. - (SSres_uncons / SStot)\n",
    "R2_skew = 1. - (SSres_skew / SStot)\n",
    "\n",
    "print(\"R2 unconstrained: %f\" % (R2_uncons))\n",
    "print(\"R2 skew symmetric: %f\" % (R2_skew))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Second direction tuning analysis (PD drift)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: depending on your computer, this simulation may take several hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new targets with the function\n",
    "\n",
    "n_rounds = 40\n",
    "n_trgs = 10 # more targets!\n",
    "\n",
    "start_t = net.sim_time # starting time for new simulation\n",
    "hand_coords, targets, center, trg_ids, m_idxs = set_new_targets(net, \n",
    "                                                          pops_dict,\n",
    "                                                                  r, \n",
    "                                                             t_pres,\n",
    "                                                             n_trgs, \n",
    "                                                           n_rounds,\n",
    "                                                                pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation for radial reaches\n",
    "sim_time2 = 2 * t_pres * n_trgs * n_rounds\n",
    "start_wctime = time.time()\n",
    "times, data, plant_data  = net.flat_run(sim_time2)\n",
    "\n",
    "data = np.array(data)\n",
    "print('Execution time is %s seconds' % (time.time() - start_wctime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain hand error\n",
    "arm_activs = plant_data[P]\n",
    "q1 = arm_activs[:,0]\n",
    "q2 = arm_activs[:,2]\n",
    "q12 = q1+q2\n",
    "c_elbow = np.array((plant.l_arm*np.cos(q1), plant.l_arm*np.sin(q1)))\n",
    "c_hand = np.array((c_elbow[0] + plant.l_farm*np.cos(q12),\n",
    "                   c_elbow[1] + plant.l_farm*np.sin(q12))).transpose()\n",
    "if 'start_t' in locals():\n",
    "    coord_idxs = np.floor((times-start_t+1e-8)/t_pres).astype(int) # after resetting the targets\n",
    "    des_coords = np.array([hand_coords[idx] for idx in [m_idxs[cid] for cid in coord_idxs]])\n",
    "else:\n",
    "    coord_idxs = np.floor(times/t_pres).astype(int)  # before resetting the targets\n",
    "    des_coords = np.array(hand_coords)[m_idxs[coord_idxs],:] # desired coordinates at each moment in time\n",
    "    \n",
    "hand_error = np.linalg.norm(c_hand-des_coords, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange the error data into a tensor\n",
    "# he_tensor[j,k,t] is the hand tensor for target j,\n",
    "# o the k-th presentation, at time t\n",
    "J = n_trgs # number of targets\n",
    "K = n_rounds # number of repetitions per target\n",
    "T = int(round(t_pres / net.min_delay)) # number of time points\n",
    "\n",
    "he_tensor = get_tensor(hand_error, J=J, K=K, T=T)\n",
    "# he_tensor = np.zeros((J, K, T))\n",
    "# trg_reps = np.zeros(J, dtype=int) # how many repetitions of each target we have filled\n",
    "# #pt_per_pres = int(round(t_pres / net.min_delay))\n",
    "# for reach, trg in enumerate(trg_ids):\n",
    "#     init_tid = (1 + 2 * reach) * T\n",
    "#     final_tid = init_tid + T # t_pres seconds later\n",
    "#     he_tensor[trg, trg_reps[trg],:] = hand_error[init_tid:final_tid]\n",
    "#     trg_reps[trg] += 1\n",
    "    \n",
    "# we average across repetitions of the same target\n",
    "ahe_trg = he_tensor.sum(axis=1) / K\n",
    "\n",
    "# we average across all reaches\n",
    "ahe = ahe_trg.sum(axis=0) / J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print distance to target for each target\n",
    "ahe_fig = plt.figure(figsize=fs)\n",
    "reach_ts = np.linspace(0., t_pres, T)\n",
    "plt.plot(reach_ts, ahe, linewidth=4)\n",
    "plt.title(\"Distance to target (average across all targets)\", fontsize=tit_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "\n",
    "n_rows = 2\n",
    "n_cols = 4\n",
    "ahe_trg_fig, ahe_trg_axs = plt.subplots(n_rows, n_cols, figsize=(fs[0], 2*fs[1]), sharey=True)\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        ax = ahe_trg_axs[row,col]\n",
    "        trg = row*n_cols + col\n",
    "        ax.plot(reach_ts, ahe_trg[trg, :], linewidth=4)\n",
    "        ax.tick_params(axis='both', labelsize=tic_s)\n",
    "        ax.set_title(\"target \" + str(trg), fontsize=tit_s)\n",
    "        for rep in range(K):\n",
    "            ax.plot(reach_ts, he_tensor[trg,rep,:], '--', linewidth=1, color='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain hand coordinates through time\n",
    "from numpy import cos, sin\n",
    "if not 'targets' in locals():\n",
    "    targets = np.array([[0.3, 0.3]])\n",
    "\n",
    "# angles of shoulder and elbow\n",
    "theta_s = arm_activs[:,0]\n",
    "theta_e = arm_activs[:,2]\n",
    "phi = theta_s + theta_e # elbow angle wrt x axis\n",
    "# data from tracking units\n",
    "ipx = data[ipx_track,:]\n",
    "ipy = data[ipy_track,:]\n",
    "ten = arm_activs[:, np.array(range(4,10))].transpose()\n",
    "# coordinates of hand and elbow\n",
    "l1 = net.plants[P].l_arm\n",
    "l2 = net.plants[P].l_farm\n",
    "xe = cos(theta_s)*l1\n",
    "ye = sin(theta_s)*l1\n",
    "xh = xe + cos(phi)*l2\n",
    "yh = ye + sin(phi)*l2\n",
    "\n",
    "# placing hand coordinates in tensors (arrange by target, repetition)\n",
    "xh_tensor = get_tensor(xh, J=J, K=K, T=T)\n",
    "yh_tensor = get_tensor(yh, J=J, K=K, T=T)\n",
    "\n",
    "# xh_tensor = np.zeros((J, K, T))\n",
    "# yh_tensor = np.zeros((J, K, T))\n",
    "# trg_reps = np.zeros(J, dtype=int) # how many repetitions of each target we have filled\n",
    "# for reach, trg in enumerate(trg_ids):\n",
    "#     init_tid = (1 + 2 * reach) * T\n",
    "#     final_tid = init_tid + T\n",
    "#     xh_tensor[trg, trg_reps[trg], :] = xh[init_tid:final_tid]\n",
    "#     yh_tensor[trg, trg_reps[trg], :] = yh[init_tid:final_tid]\n",
    "#     trg_reps[trg] += 1\n",
    "    \n",
    "# average across reptitions of the same target\n",
    "axh_trg = xh_tensor.sum(axis=1) / K\n",
    "ayh_trg = yh_tensor.sum(axis=1) / K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain velocity profile for the reaches\n",
    "xph = np.concatenate(([0], (xh[1:] - xh[:-1]) / net.min_delay))\n",
    "yph = np.concatenate(([0], (yh[1:] - yh[:-1]) / net.min_delay))\n",
    "hv = np.sqrt(xph*xph + yph*yph)\n",
    "\n",
    "hv_tensor = get_tensor(hv, J=J, K=K, T=T)\n",
    "\n",
    "# we average across repetitions of the same target\n",
    "ahv_trg = hv_tensor.sum(axis=1) / K\n",
    "\n",
    "# we average across all reaches\n",
    "ahv = ahv_trg.sum(axis=0) / J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print velocity for each target\n",
    "ahv_fig = plt.figure(figsize=fs)\n",
    "reach_ts = np.linspace(0., t_pres, T)\n",
    "plt.plot(reach_ts, ahv, linewidth=4)\n",
    "plt.title(\"hand velocity (average across all targets)\", fontsize=tit_s)\n",
    "plt.xticks(fontsize=tic_s)\n",
    "plt.yticks(fontsize=tic_s)\n",
    "plt.ylabel('velocity [m/s]', fontsize=lab_s)\n",
    "plt.xlabel('time [s]', fontsize=lab_s)\n",
    "\n",
    "\n",
    "n_rows = 2\n",
    "n_cols = 4\n",
    "ahv_trg_fig, ahv_trg_axs = plt.subplots(n_rows, n_cols, figsize=(fs[0], 2*fs[1]), sharey=True)\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        ax = ahv_trg_axs[row,col]\n",
    "        trg = row*n_cols + col\n",
    "        ax.plot(reach_ts, ahv_trg[trg, :], linewidth=4)\n",
    "        ax.tick_params(axis='both', labelsize=tic_s)\n",
    "        ax.set_title(\"target \" + str(trg), fontsize=tit_s)\n",
    "        for rep in range(K):\n",
    "            ax.plot(reach_ts, hv_tensor[trg,rep,:], '--', linewidth=1, color='b')\n",
    "        if col==0:\n",
    "            ax.set_ylabel('velocity [m/s]', fontsize=lab_s)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average reach trajectories and some individual reaches\n",
    "n_ind_reaches = 4 # number of example reaches to plot\n",
    "reach_fig = plt.figure(figsize=(10,10))\n",
    "reach_ax = plt.gca()\n",
    "trial = 0\n",
    "#reach_ax.scatter(targets[:,0], targets[:,1], s=1000, c='cyan')\n",
    "reach_ax.scatter(center[0]+.8*(targets[:,0]-center[0]), \n",
    "                 center[1]+.8*(targets[:,1]-center[1]), s=1000, c='k', alpha=0.3)\n",
    "#reach_ax.scatter(.6*(targets[:,0]+center[0]), .6*(targets[:,1]+center[1]), s=1000, c='cyan', alpha=0.4)\n",
    "reach_ax.scatter(center[0], center[1], s=2000, c='blue')\n",
    "plt.axis('equal')\n",
    "reach_ax.grid()\n",
    "cmap = [[0.1, 0.4, 0.8, 0.5],\n",
    "        [0.2, 0.2, 0.2, 0.8],\n",
    "        [0.9, 0.7, 0.2, 0.8],\n",
    "        [0.1, 0.7, 0.1, 0.6],\n",
    "        [0.9, 0.1, 0.1, 0.5],\n",
    "        [0.6, 0.2, 0.6, 0.5],\n",
    "        [0.8, 0.4, 0.1, 0.5],\n",
    "        [0.7, 0.1, 0.7, 0.5],\n",
    "        [0.5, 0.5, 0.2, 0.8],\n",
    "        [0.3, 0.3, 0.3, 0.5]]\n",
    "for trg in range(J):\n",
    "    reach_ax.plot(axh_trg[trg,:], ayh_trg[trg,:], linewidth=3, color=cmap[trg])\n",
    "    for rep in range(min(n_ind_reaches, K)):\n",
    "        reach_ax.plot(xh_tensor[trg, rep, :], yh_tensor[trg, rep, :], '--', linewidth=1, color=cmap[trg])\n",
    "#from IPython.display import Image\n",
    "#Image(filename='temp_fig')\n",
    "#plt.savefig('temp_fig2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the prefered directions for the units in M\n",
    "# Find the mean rate for each target\n",
    "t_smp = 1. # time to sample M (in seconds)\n",
    "I = 12 # number of units to consider in M\n",
    "m_tensor = get_pop_tensor(M[:I], J=J, K=K, t_smp=t_smp, trg_ids=trg_ids)\n",
    "# m_tensor[i,j,k,t] is the activity of the i-th M \n",
    "# unit for target j, on the k-th repetition, at time point t.\n",
    "\n",
    "# Now we average across repetitions for the same target\n",
    "m_tensor_trg_avg = m_tensor.sum(axis=2) / K\n",
    "# m_tensor_trg_avg[i,j,t]: average activity of i-th M unit when\n",
    "# reaching for target j, at time point t\n",
    "\n",
    "m_avg_rates = np.zeros((I,J)) # average rate at each unit for each target\n",
    "for trg in range(J):\n",
    "    m_avg_rates[:, trg] = np.mean(m_tensor_trg_avg[:, trg, :], axis=1)\n",
    "\n",
    "m_means = np.mean(m_avg_rates, axis=1) # mean rate for each unit\n",
    "    \n",
    "# Obtaining preferred directions by fitting the rates using a plane, and using\n",
    "# the angle of the projection of this plane's normal vector onto the XY plane\n",
    "# The coefficients of the normal vector can be calculated using the least-squares\n",
    "# method, which leads to a 3x3 linear system that is readily reduced to a 2x2 system.\n",
    "trgs = targets - center # targets centered at the origin\n",
    "xs = trgs[:,0]\n",
    "ys = trgs[:,1]\n",
    "cxs = xs - np.mean(xs) # \"centered\" x coordinates\n",
    "cys = ys - np.mean(ys) #  \"centered\" Y coordinates\n",
    "\n",
    "X11 = (xs * cxs).sum()\n",
    "X12 = (xs * cys).sum()\n",
    "X21 = (ys * cxs).sum()\n",
    "X22 = (ys * cys).sum()\n",
    "\n",
    "Amat = np.array([[X11, X12], [X21, X22]])\n",
    "detA = np.linalg.det(Amat) # determinant of Amat\n",
    "if detA == 0.:\n",
    "    raise ValueError('Indeterminate system found!')\n",
    "invA = np.linalg.inv(Amat)\n",
    "\n",
    "prf_angsB = np.zeros(len(M)) # preferred angles, in radians\n",
    "normal_vecsB = [] # list with the vectors normal to the plane fitting the rates\n",
    "\n",
    "for uid in range(I):\n",
    "    r1 = (xs * (m_avg_rates[uid, :] - m_means[uid])).sum()\n",
    "    r2 = (ys * (m_avg_rates[uid, :] - m_means[uid])).sum()\n",
    "    n = np.matmul(invA, np.array([r1,r2]))\n",
    "    # boils down to\n",
    "    #n = [a,b] where b = r2/X22, a = r1/X11\n",
    "    #normal_vecsB.append(n / np.linalg.norm(n)) # appending normalized vector\n",
    "    normal_vecsB.append(n)\n",
    "    prf_angsB[uid] = np.arctan2(n[1], n[0]) # preferred angle\n",
    "    #print(\"n1=%f, n0=%f, prf_ang=%f\"%(n[1],n[0]))\n",
    "\n",
    "    c = np.mean(m_avg_rates[uid,:] - n[0]*xs - n[1]*ys)\n",
    "    \n",
    "    # obtaining residuals, coefficient of determination, R^2\n",
    "    residuals = m_avg_rates[uid,:] - n[0]*xs - n[1]*ys - c\n",
    "    devs = m_avg_rates[uid,:] - m_means[uid]\n",
    "    SSr = (residuals * residuals).sum()\n",
    "    SSt = (devs * devs).sum()\n",
    "    R = 1. - (SSr/SSt)\n",
    "    print(R)\n",
    "\n",
    "normal_vecsB = np.array(normal_vecsB)\n",
    "\n",
    "# Get the lengths of the preferred direction vectors\n",
    "pd_normsB = np.linalg.norm(normal_vecsB, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot direction tuning for all M units\n",
    "\n",
    "dir_fig, dir_axs = plt.subplots(3, 4, figsize=(fs[0], 3.3*fs[1]))\n",
    "\n",
    "\n",
    "for row in range(3):\n",
    "    for col in range(4):\n",
    "        ax = dir_axs[row][col]\n",
    "        m_id = 4*row + col\n",
    "        span = max(np.linalg.norm(normal_vecs[m_id]), np.linalg.norm(normal_vecsB[m_id]))\n",
    "        ax.set_xlim([-1.1*span, 1.1*span])\n",
    "        ax.set_ylim([-1.1*span, 1.1*span])\n",
    "        ax.grid()\n",
    "        ax.set_title(\"M = %d\" % (m_id), fontsize=tit_s)\n",
    "        ax.tick_params(axis='both', labelsize=tic_s)\n",
    "        mod_trgs = m_avg_rates[m_id,:].reshape(n_trgs,1) * trgs \n",
    "        #for trg in range(J):\n",
    "            #ax.plot([trgs[trg][0]], [trgs[trg][1]], '*')\n",
    "            #ax.plot([0., mod_trgs[trg, 0]], [0., mod_trgs[trg, 1]], linewidth=5, color='b')\n",
    "        #nrms = np.linalg.norm(mod_trgs, axis=1)\n",
    "#         ax.plot([0., normal_vecs[m_id, 0]], [0., normal_vecs[m_id, 1]], linewidth=3, color='r')\n",
    "#         ax.plot([0., normal_vecsB[m_id, 0]], [0., normal_vecsB[m_id, 1]], linewidth=3, color='b')\n",
    "        nrm = np.linalg.norm(normal_vecs[m_id,:])\n",
    "        ax.arrow(0., 0., normal_vecs[m_id, 0], normal_vecs[m_id, 1],\n",
    "                 width=.03*nrm, color='r', length_includes_head=True)\n",
    "        ax.arrow(0., 0., normal_vecsB[m_id, 0], normal_vecsB[m_id, 1],\n",
    "                 width=.03*nrm, color='b', length_includes_head=True)\n",
    "            \n",
    "plt.show()\n",
    "\n",
    "# plt.arrow(jPCA1_traces[target,n_pts-10],jPCA2_traces[target,n_pts-10],\n",
    "#              dx, dy, color=c, width=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find average absolute value for deviations in the preferred directions\n",
    "sig_indexes = [1,2,4,5,7,8,10,11]\n",
    "mean_abs_sig_ang_dev = np.mean(np.abs(prf_angs[sig_indexes] - prf_angsB[sig_indexes]))\n",
    "print(\"Mean PD deviation for largest PDs (degrees): %f\" % (mean_abs_sig_ang_dev*180./np.pi))\n",
    "\n",
    "mean_abs_ang_dev = np.mean(np.abs(prf_angs - prf_angsB))\n",
    "print(\"Mean PD deviation for all PDs (degrees): %f\" % (mean_abs_ang_dev*180./np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below are used to produce videos from the simulation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for animation\n",
    "from numpy import cos, sin\n",
    "if not 'targets' in locals():\n",
    "    targets = np.array([[0.3, 0.3]])\n",
    "    times = times_l\n",
    "    data = data_l\n",
    "    t_pres = t_pres_l\n",
    "start_time = 0.\n",
    "start_idx = int(start_time/net.min_delay)\n",
    "fdelay = 2000 # number of frames to plot for hand trajectory\n",
    "# angles of shoulder and elbow\n",
    "theta_s = arm_activs[start_idx:,0]\n",
    "theta_e = arm_activs[start_idx:,2]\n",
    "phi = theta_s + theta_e # elbow angle wrt x axis\n",
    "# data from tracking units\n",
    "#acts = np.array(data[1])\n",
    "ipx = data[ipx_track,start_idx:]\n",
    "ipy = data[ipy_track,start_idx:]\n",
    "ten = arm_activs[start_idx:, np.array(range(4,10))].transpose()\n",
    "# coordinates of hand and elbow\n",
    "l1 = net.plants[P].l_arm\n",
    "l2 = net.plants[P].l_farm\n",
    "xe = cos(theta_s)*l1\n",
    "ye = sin(theta_s)*l1\n",
    "xh = xe + cos(phi)*l2\n",
    "yh = ye + sin(phi)*l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Animation of the arm and muscles\n",
    "%matplotlib widget\n",
    "from matplotlib.animation import FuncAnimation\n",
    "# creating the figure and axis\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis('equal')\n",
    "ax = plt.gca()\n",
    "lim = l1 + l2\n",
    "ax.set_xlim([-.2, lim])\n",
    "ax.set_ylim([-.2, lim])\n",
    "ax.grid()\n",
    "ax.scatter(targets[:,0], targets[:,1], s=150, c='cyan')\n",
    "# creating lines and points\n",
    "line, = ax.plot([], [], 'o-k', lw=2)\n",
    "points, = ax.plot([], [], '+k')\n",
    "target, = ax.plot([], [], 'gD')\n",
    "traj, = ax.plot([], [], 'tab:gray', lw=1)\n",
    "pred_vel, = ax.plot([], [], 'r-o')\n",
    "ax.scatter([0.3], [0.3], s=200, c='cyan')\n",
    "# preparing a colormap for the tensions\n",
    "ten_max = np.mean(np.max(ten, axis=1))\n",
    "ten_min = np.mean(np.min(ten, axis=1))\n",
    "for row_idx, row in enumerate(ten):\n",
    "    for ent_idx, entry in enumerate(row):\n",
    "        if entry > 0:\n",
    "            ten[row_idx, ent_idx] = entry/ten_max\n",
    "        else:\n",
    "            ten[row_idx, ent_idx] = entry/abs(ten_min)\n",
    "#ten = (ten / 2.) + 0.5 # we'll have only positive tensions\n",
    "mus_lines = []\n",
    "#cmap=plt.get_cmap('Reds')\n",
    "#cmap=plt.get_cmap('coolwarm')\n",
    "cmap=plt.get_cmap('bwr')\n",
    "for i in range(6):\n",
    "    mus_lines.append(ax.plot([], [], color=cmap(0.5))[0])\n",
    "# stuff used to plot the target\n",
    "#strt_idx = int(np.round(times[0]/t_pres)) # initial index in m_idxs\n",
    "strt_idx = int(np.round((times[0]+start_time)/t_pres)) # initial index in m_idxs\n",
    "\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    points.set_data([], [])\n",
    "    traj.set_data([], [])\n",
    "    pred_vel.set_data([], [])\n",
    "    for i in range(6):\n",
    "        mus_lines = []\n",
    "        mus_lines.append(ax.plot([], [], color=cmap(0.5))[0])\n",
    "    return line, points, mus_lines\n",
    "\n",
    "def update(frame):\n",
    "    coord_x = [0, xe[frame], xh[frame]]\n",
    "    coord_y = [0, ye[frame], yh[frame]]\n",
    "    ip_x = ipx[:,frame]\n",
    "    ip_y = ipy[:,frame]\n",
    "    tens = ten[:, frame]\n",
    "    line.set_data(coord_x, coord_y)\n",
    "    points.set_data(ip_x, ip_y)\n",
    "    #traj.set_data(xh[0:frame], yh[0:frame])\n",
    "    #traj.set_data(xh[frame-max(0,frame-fdelay):frame], yh[frame-max(0,frame-fdelay):frame])\n",
    "    if frame > fdelay:\n",
    "        traj.set_data(xh[frame-fdelay:frame], yh[frame-fdelay:frame])\n",
    "    for i, ml in enumerate(mus_lines):\n",
    "        idx = 2*i\n",
    "        ml.set_data(ip_x[idx:idx+2], ip_y[idx:idx+2])\n",
    "        ml.set_color(cmap(tens[i]))\n",
    "    \n",
    "    cur_time = (frame+start_idx)*net.min_delay\n",
    "    fig.suptitle('time: ' + '{:f}'.format(cur_time))\n",
    "    # plotting target\n",
    "    #cur_idx = int(cur_time/t_pres) + strt_idx\n",
    "    #cur_idx = int(frame*net.min_delay/t_pres) + strt_idx\n",
    "    cur_idx = int(frame*net.min_delay/t_pres)  # if using new targets\n",
    "    x_coord, y_coord = hand_coords[m_idxs[cur_idx]]\n",
    "    target.set_data([x_coord], [y_coord])\n",
    "    # plotting predicted velocity\n",
    "    #pred_vel.set_data([xh[frame], xh[frame]+0.3*pred_v[0][frame]], [yh[frame], yh[frame]+0.3*pred_v[1][frame]])\n",
    "    #pred_vel.set_data([xh[frame], xh[frame]+5.*pred_v2[0][frame]], [yh[frame], yh[frame]+5.*pred_v2[1][frame]])\n",
    "    \n",
    "    return line, points, mus_lines #muscle1\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=np.arange(0, len(theta_s), 20), init_func=init, blit=True, interval=20)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate way to display the animation\n",
    "from IPython.display import HTML\n",
    "#HTML(ani.to_jshtml(fps=20))\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# save the animation\n",
    "import matplotlib.animation as animation\n",
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=24, metadata=dict(artist='Mr. X'), bitrate=2000)\n",
    "ani.save('/file-path/file_name.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
