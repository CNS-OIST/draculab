{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v3t3p2ph2_pso_gene.ipynb\n",
    "\n",
    "Hyperparameter search on the v3_from_t3p2_ph2 model using either Particle Swarm Optimization, a genetic algorithm, or a combinatin of both using two machines.\n",
    "\n",
    "When running both algorithms, one machine maintains a population evolved through the PSO algorithm, whereas the second machine uses a genetic algorithm. They share their configurations through a shared file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/z/projects/draculab\n"
     ]
    }
   ],
   "source": [
    "%cd ../..\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from draculab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/z/projects/draculab/notebook/spinal\n",
      "/home/z/projects/draculab\n"
     ]
    }
   ],
   "source": [
    "%cd /home/z/projects/draculab/notebook/spinal/\n",
    "from v3ft3p2ph2_net import *\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility methods, ranges, search configuration parameters\n",
    "\n",
    "focus_params = True # whether to focus mutations on a specific set of parameters\n",
    "max_evals = 8 # maximum number of times to evaluate a configuration\n",
    "target_fitness = 0.02 # stop if fitness reaches this value\n",
    "\n",
    "# Specify paramters and ranges\n",
    "# defaults are based on incumbent 9 of smac_pars in v3_normal_smac_test.ipynb\n",
    "ranges = {\"A__M_lrate\" : {\"low\": 0.1, \"high\": 20., \"default\":8.},\n",
    "          \"A__M_w_max_frac\" : {\"low\": .05, \"high\": 1., \"default\":.33},\n",
    "          \"A__M_w_sum\" : {\"low\": 1., \"high\": 40., \"default\":2.},\n",
    "          \"AL_thresh\" : {\"low\": -.1, \"high\": 1., \"default\":.4},\n",
    "          \"b_e\": {\"low\": .5, \"high\": 10., \"default\":2.},\n",
    "          \"C__C_antag\": {\"low\": 0.1, \"high\": 3., \"default\":1.5},\n",
    "          \"C__C_p_antag\": {\"low\": 0., \"high\": 1.5, \"default\":.25},\n",
    "          \"C__C_p_syne\": {\"low\": 0., \"high\": 1., \"default\":.3},\n",
    "          \"C__C_syne\": {\"low\": 0., \"high\": 2., \"default\":.5},\n",
    "          \"C_adapt_amp\": {\"low\": 0., \"high\": 15., \"default\":5.},\n",
    "          \"C_cid\" : {\"low\": 0.1, \"high\": 2., \"default\":.15},\n",
    "          \"C_sigma\" : {\"low\": 0., \"high\": 1., \"default\":.3},\n",
    "          \"C_slope\" : {\"low\": 0.5, \"high\": 4., \"default\":2.5},\n",
    "          \"C_tau\" : {\"low\": 0.01, \"high\": .3, \"default\":.05},\n",
    "          \"C_tau_slow\" : {\"low\": 2., \"high\": 40., \"default\":10.},\n",
    "          \"C_thresh\" : {\"low\": -0.2, \"high\": 1.5, \"default\":.7},\n",
    "          \"CE__CI_w\": {\"low\": 0., \"high\": 2.5, \"default\":.5},\n",
    "          \"CI__CE_w\": {\"low\": -2.5, \"high\": 0, \"default\":-1.5},\n",
    "          \"g_e_factor\": {\"low\": 0.5, \"high\": 4., \"default\":2.},\n",
    "          \"M__C_lrate\" : {\"low\": 5., \"high\": 500., \"default\":300.},\n",
    "          \"M__C_w_sum\": {\"low\": 0.5, \"high\": 8., \"default\": 2.5},\n",
    "          \"M__M_w\": {\"low\": 0., \"high\": -3., \"default\":-.5},\n",
    "          \"M_cid\": {\"low\": 0.05, \"high\": 2., \"default\": .3},\n",
    "          \"M_des_out_w_abs_sum\": {\"low\": 0.5, \"high\": 4., \"default\": 2.},\n",
    "          \"SPF__SPF_w\": {\"low\": -3., \"high\": 0., \"default\":-.5}\n",
    "         }\n",
    "\n",
    "\n",
    "#par_list = [name for name in ranges] # ordered list with names of the parameters\n",
    "par_list = list(ranges.keys())\n",
    "# parameters to focus on\n",
    "main_pars = [\"A__M_w_max_frac\", \"A__M_w_sum\",  \"C_adapt_amp\", \"C_cid\",\n",
    "             \"C_sigma\", \"M_cid\", \"M_des_out_w_abs_sum\",\n",
    "             \"g_e_factor\", \"C_slope\", \"C_thresh\", \"C_tau\", \"C_tau_slow\"]\n",
    "if focus_params:\n",
    "    par_list = main_pars\n",
    "\n",
    "def mutate(cfg, name_list=par_list):\n",
    "    \"\"\" Mutate a single parameter of the given configuration. \n",
    "    \n",
    "        Args:\n",
    "            name_list: list with names of candidate parameters.\n",
    "    \"\"\"\n",
    "    n = np.random.randint(len(name_list))\n",
    "    par_name = name_list[n]\n",
    "    l = ranges[par_name]['low']\n",
    "    h = ranges[par_name]['high']\n",
    "    cfg[par_name] =  l + (h-l)*np.random.random()\n",
    "    \n",
    "def soft_mutate(cfg, ma, name_list=par_list):\n",
    "    \"\"\" Soft-mutate a single parameter of the given configuration.\n",
    "    \n",
    "        A 'soft mutation' keeps the mutated value close to the original value.\n",
    "        The maximum amplitude of the mutation is given by the 'ma' argument.\n",
    "        \n",
    "        Args:\n",
    "            ma : float in (0,1]. Max. amplitude as fraction of the parameter's range \n",
    "            name_list: list with names of candidate parameters.\n",
    "    \"\"\"\n",
    "    n = np.random.randint(len(name_list))\n",
    "    par_name = name_list[n]\n",
    "    l = ranges[par_name]['low']\n",
    "    h = ranges[par_name]['high']\n",
    "    cfg[par_name] = max(l, min(h, cfg[par_name] + ma * (h-l) * (np.random.random()-0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the initial population: method 1\n",
    "\n",
    "# create variations of the parameters we want to investigtate\n",
    "pop_size = 90 # number of configurations in the population\n",
    "pop = [{} for _ in range(pop_size)]\n",
    "# first fill the default values in n_def elements\n",
    "n_def = 3\n",
    "for ind in range(n_def):\n",
    "    for name in par_list:\n",
    "        pop[ind][name] = ranges[name]['default']\n",
    "        \n",
    "# fill the rest with variations in both directions\n",
    "chg_name = [\"low\", \"default\", \"high\"] # auxiliary list\n",
    "for ind in range(n_def, pop_size):\n",
    "    chg_dirs = [chg_name[i] for i in np.random.randint(3, size=len(par_list))]\n",
    "    for idx, name in enumerate(par_list):\n",
    "        pop[ind][name] = 0.5 * (ranges[name][chg_dirs[idx]] + ranges[name][\"default\"])\n",
    "        \n",
    "# Throw n_muts mutations, and n_soft_muts soft mutations\n",
    "n_muts = 20\n",
    "n_soft_muts = 10 # must have n_muts + n_soft_muts < pop_size-1\n",
    "perm = np.random.permutation(range(1,pop_size)) # don't mutate the first element\n",
    "for i in range(n_muts):\n",
    "    mutate(pop[perm[i]])\n",
    "for i in range(n_muts,n_muts+n_soft_muts):\n",
    "    soft_mutate(pop[perm[i]], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the initial population: method 2\n",
    "\n",
    "# Load the results from a previous run\n",
    "fname = '/home/z/projects/draculab/saves/v3ft3p2ph2_pop_2021-05-28__10_53'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    prev_pop = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "# If the results are from a run with fewer parameters\n",
    "# fill it with the default values.\n",
    "for cfg in prev_pop:\n",
    "    for name in ranges:\n",
    "        if not name in cfg:\n",
    "            cfg[name] = ranges[name]['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mix configurations from the two methods\n",
    "pop[50:] = prev_pop[:40]\n",
    "\n",
    "# If configurations have fewer parameters\n",
    "# fill them with the default values.\n",
    "for cfg in pop:\n",
    "    for name in ranges:\n",
    "        if not name in cfg:\n",
    "            cfg[name] = ranges[name]['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset fitness and number of evaluations\n",
    "for dic in pop:\n",
    "    dic['fitness'] = None # average fitness value\n",
    "    dic['n_evals'] = 0  # number of times fitness has been evaluated\n",
    "    \n",
    "# Set search parameters present in the configurations\n",
    "for cfg in pop:\n",
    "    cfg['t_pres'] = 40\n",
    "    cfg['par_heter'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A__M_lrate':6.0, 'A__M_w_max_frac':0.33, 'A__M_w_sum':2.0, 'C_adapt_amp':5.0, 'C_cid':0.15, 'C_sigma':0.3, 'M__C_lrate':300.0, 'M__C_w_sum':3.0, 'M_cid':0.3, 'M_des_out_w_abs_sum':2.0, 'g_e_factor':2.0, 'C_slope':2.5, 'C_thresh':0.7, 'AL_thresh':0.4, 'b_e':2.0, 'C__C_antag':1.5, 'C__C_p_antag':0.25, 'C__C_p_syne':0.3, 'C__C_syne':0.5, 'CE__CI_w':0.5, 'CI__CE_w':-1.5, 'M__M_w':-0.5, 'SPF__SPF_w':-0.5, 'fitness':None, 'n_evals':0, 't_pres':40, 'par_heter':0.01, }\n",
      "\n",
      "{'A__M_lrate':6.0, 'A__M_w_max_frac':0.33, 'A__M_w_sum':2.0, 'C_adapt_amp':5.0, 'C_cid':0.15, 'C_sigma':0.3, 'M__C_lrate':300.0, 'M__C_w_sum':3.0, 'M_cid':0.3, 'M_des_out_w_abs_sum':2.0, 'g_e_factor':2.0, 'C_slope':2.245900063549469, 'C_thresh':0.7, 'AL_thresh':0.4, 'b_e':2.0, 'C__C_antag':1.5, 'C__C_p_antag':0.25, 'C__C_p_syne':0.3, 'C__C_syne':0.5, 'CE__CI_w':0.5, 'CI__CE_w':-1.5, 'M__M_w':-0.5, 'SPF__SPF_w':-0.5, 'fitness':None, 'n_evals':0, 't_pres':40, 'par_heter':0.01, }\n",
      "\n",
      "{'A__M_lrate':6.0, 'A__M_w_max_frac':0.33, 'A__M_w_sum':2.0, 'C_adapt_amp':5.0, 'C_cid':0.15, 'C_sigma':0.3, 'M__C_lrate':300.0, 'M__C_w_sum':3.0, 'M_cid':0.3, 'M_des_out_w_abs_sum':2.0, 'g_e_factor':2.0, 'C_slope':2.5, 'C_thresh':0.7, 'AL_thresh':0.4, 'b_e':2.0, 'C__C_antag':1.5, 'C__C_p_antag':0.25, 'C__C_p_syne':0.3, 'C__C_syne':0.5, 'CE__CI_w':0.5, 'CI__CE_w':-1.5, 'M__M_w':-0.5, 'SPF__SPF_w':-0.5, 'fitness':None, 'n_evals':0, 't_pres':40, 'par_heter':0.01, }\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A__M_lrate': 6.0,\n",
       " 'A__M_w_max_frac': 0.33,\n",
       " 'A__M_w_sum': 2.0,\n",
       " 'C_adapt_amp': 5.0,\n",
       " 'C_cid': 0.15,\n",
       " 'C_sigma': 0.3,\n",
       " 'M__C_lrate': 300.0,\n",
       " 'M__C_w_sum': 3.0,\n",
       " 'M_cid': 0.3,\n",
       " 'M_des_out_w_abs_sum': 2.0,\n",
       " 'g_e_factor': 2.0,\n",
       " 'C_slope': 2.5,\n",
       " 'C_thresh': 0.7,\n",
       " 'AL_thresh': 0.4,\n",
       " 'b_e': 2.0,\n",
       " 'C__C_antag': 1.5,\n",
       " 'C__C_p_antag': 0.25,\n",
       " 'C__C_p_syne': 0.3,\n",
       " 'C__C_syne': 0.5,\n",
       " 'CE__CI_w': 0.5,\n",
       " 'CI__CE_w': -1.5,\n",
       " 'M__M_w': -0.5,\n",
       " 'SPF__SPF_w': -0.5,\n",
       " 'fitness': None,\n",
       " 'n_evals': 0,\n",
       " 't_pres': 40,\n",
       " 'par_heter': 0.01}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print used configuration\n",
    "for dic in pop[0:3]:\n",
    "    print('{',end='')\n",
    "    for name in dic.keys():\n",
    "        print(\"\\'%s\\':%s, \"%(name, dic[name]), end='')\n",
    "#         if name in net_conf:\n",
    "#             print(\"\\'%s\\':%s, \"%(name, dic[name]), end='')\n",
    "#         if name != 'fitness' or dic['fitness'] != None:\n",
    "#             print(\"\\'%s\\':%.2f, \" % (name, dic[name]), end='')\n",
    "    print('}\\n')\n",
    "\n",
    "pop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that evaluates the fitness of a given configuration\n",
    "def eval_config(cfg):\n",
    "    \"\"\" Returns the error for a network with a given configuration.\n",
    "\n",
    "        Args:\n",
    "            cfg : a configuration dictionary.\n",
    "        Returns:\n",
    "            error : A float calculated from the sum of activities in the SPF layer.\n",
    "    \"\"\"\n",
    "    np.random.seed() # will try to get a seed from /dev/urandom\n",
    "    if cfg['n_evals'] > max_evals: # if the fitness has been evaluated \"enough\" times. See cell below...\n",
    "        return cfg['fitness']\n",
    "    t_pres = cfg['t_pres']\n",
    "    \n",
    "    # obtain a network with the given configuration\n",
    "    net, pops_dict, hand_coords, m_idxs = net_from_cfg(cfg,\n",
    "               t_pres = cfg['t_pres'], \n",
    "               par_heter = cfg['par_heter'],\n",
    "               set_C_delay = False,\n",
    "               rand_targets = True,\n",
    "               C_noise = True,\n",
    "               track_weights = False,\n",
    "               track_ips = False)\n",
    "    # run the network\n",
    "    run_time = 700.\n",
    "    #start_time = time.time()\n",
    "    times, data, plant_data  = net.flat_run(run_time)\n",
    "    #print('Execution time is %s seconds' % (time.time() - start_time))\n",
    "\n",
    "    # calculate average error in last half of reaching\n",
    "    P = pops_dict['P']\n",
    "    arm_activs = plant_data[P]\n",
    "    plant = net.plants[P]\n",
    "    # modified copy-paste of plt.upd_ip_impl\n",
    "    q1 = arm_activs[:,0]\n",
    "    q2 = arm_activs[:,2]\n",
    "    q12 = q1+q2\n",
    "    c_elbow = np.array((plant.l_arm*np.cos(q1), plant.l_arm*np.sin(q1)))\n",
    "    c_hand = np.array((c_elbow[0] + plant.l_farm*np.cos(q12),\n",
    "                    c_elbow[1] + plant.l_farm*np.sin(q12))).transpose()\n",
    "    coord_idxs = np.floor(times/t_pres).astype(int)\n",
    "    des_coords = np.array(hand_coords)[m_idxs[coord_idxs],:] # desired coordinates at each moment in time\n",
    "\n",
    "    error_time = run_time - round(run_time/2.)\n",
    "    error_idx = int(round(error_time/net.min_delay))\n",
    "    hand_error = np.linalg.norm(c_hand-des_coords, axis=1)\n",
    "    hand_error_integ = hand_error[error_idx:].sum()\n",
    "    avg_hand_error = hand_error_integ / (hand_error.size - error_idx)\n",
    "\n",
    "    #return hand_error_integ\n",
    "    return avg_hand_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Genetic algorithm  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to produce offspring by crossing individuals\n",
    "par_names = list(pop[0].keys()) # list with all parameter names\n",
    "\n",
    "def create_offspring(cfg1, cfg2, par_list=par_names):\n",
    "    \"\"\" Given 2 configurations, return 2 offspring from random swapping.\n",
    "    \n",
    "        To produce offspring, first we choose one split point in the\n",
    "        dictionary. The first offspring has the values of cfg1 up to that\n",
    "        point, and cfg2 afterwards. The second offspring has the cfg2 values\n",
    "        up to the split point, and cfg1 afterwards. Since the dictionaries are\n",
    "        not ordered, we use a parameter list to set the split point.\n",
    "    \n",
    "        Args:\n",
    "            cfg1, cfg2: parameter dictionaries\n",
    "            par_list: list with the keys in cfg1, cfg2\n",
    "        Returns:\n",
    "            cfg3, cfg4: dictionaries from swapping values in cfg1, cfg2\n",
    "    \"\"\"\n",
    "    if focus_params:\n",
    "        par_list = main_pars\n",
    "    sp = np.random.randint(len(par_list))# split point as an index to par_list\n",
    "    cfg3 = cfg1.copy()\n",
    "    cfg4 = cfg2.copy()\n",
    "    for i in range(sp, len(par_list)):\n",
    "        cfg3[par_list[i]] = cfg2[par_list[i]]\n",
    "        cfg4[par_list[i]] = cfg1[par_list[i]]\n",
    "    return cfg3, cfg4\n",
    "\n",
    "# visualize\n",
    "# cfg3, cfg4 = create_offspring(pop[10], pop[11])\n",
    "# for dic in (pop[10], pop[11], cfg3, cfg4):\n",
    "#     print('{',end='')\n",
    "#     for name in par_names:\n",
    "#         if name != \"fitness\":\n",
    "#             print(\"\\'%s\\':%.2f, \" % (name, dic[name]), end='')\n",
    "#     print('}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 evaluated. Best fitness: 0.068\n",
      "Mean fitness = 0.241\n",
      "to replace: [69, 85, 65, 74, 61, 62, 67, 80, 56, 4, 70, 31, 50, 84, 34, 59, 46, 29, 81, 73, 60, 5, 38, 75, 51, 66, 58, 83, 87, 78]\n",
      "to mutate: [81, 42, 70, 71, 79, 46, 47, 87]\n",
      "generation 0 finished in 6583.3664219379425 seconds\n",
      "Mixed pso and gene pops!!!\n",
      "Generation 1 evaluated. Best fitness: 0.073\n",
      "Mean fitness = 0.173\n",
      "to replace: [65, 23, 77, 11, 75, 19, 52, 88, 27, 48, 22, 71, 57, 45, 83, 44, 73, 80, 56, 62, 55, 76, 33, 67, 89, 31, 68, 58, 12, 14]\n",
      "to mutate: [69, 55, 76, 60, 80, 86, 71, 73]\n",
      "generation 1 finished in 6744.355035543442 seconds\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'b_e'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/z/programs/anaconda3/envs/draculab/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/z/programs/anaconda3/envs/draculab/lib/python3.9/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-11-224505ccf562>\", line 16, in eval_config\n    net, pops_dict, hand_coords, m_idxs = net_from_cfg(cfg,\n  File \"/home/z/projects/draculab/notebook/spinal/v3ft3p2ph2_net.py\", line 76, in net_from_cfg\n    'b_e' : cfg['b_e'],\nKeyError: 'b_e'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9dfffeae3e3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m######## parallel version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_procs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mfits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/draculab/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/draculab/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'b_e'"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "###### The genetic algorithm ######\n",
    "####################################\n",
    "\n",
    "#pop = pop[0:15] # limit pop size for debugging\n",
    "n_mates = 30 # number of individuals to mate at each generation (even number)\n",
    "max_gens = 80 # maximum number of generations\n",
    "n_soft_mut = 10 # numbef of individuals to soft-mutate per generation\n",
    "r_soft_mut = 0.2 # relative amplitude of soft mutations\n",
    "n_mut = 8 # number of individuals to mutate per generation\n",
    "n_procs = 28 # number of processes to use for fitness evaluation\n",
    "n_save = 3 # number of individuals to protect from replacement and mutation\n",
    "use_pso = True # whether to insert configurations from the PSO algorithm\n",
    "\n",
    "# setting name for file where parameters will be stored\n",
    "path = \"/home/z/Dropbox (OIST)/saves/\"\n",
    "#path = \"/home/z/projects/draculab/saves/\"\n",
    "fname1 = \"gene\"\n",
    "fname2 = datetime.now().strftime('%Y-%m-%d')\n",
    "fname = path + fname1 + \"_\" + fname2\n",
    "\n",
    "pop_len = len(pop)\n",
    "\n",
    "for gen in range(max_gens):\n",
    "    start_time = time.time()\n",
    "    # 1) Evaluate fitness\n",
    "    # 1.1) Do the evaluation\n",
    "    ######### Single process version\n",
    "    #fits = list(map(eval_config, pop))\n",
    "    ######## parallel version\n",
    "    with Pool(n_procs) as p:\n",
    "        fits = list(p.map(eval_config, pop))\n",
    "        p.close()\n",
    "        p.join()\n",
    "    #print(fits)\n",
    "    # 1.2) update the average fitness values\n",
    "    for idx, cfg in enumerate(pop):\n",
    "        nr = cfg['n_evals'] # n_evals is not updated yet...\n",
    "        #print(nr)\n",
    "        #print(fits[idx])\n",
    "        #print(cfg['fitness'])\n",
    "        if nr > 0:\n",
    "            if nr <= max_evals:\n",
    "                cfg['fitness'] = (cfg['fitness']*nr + fits[idx])/(nr+1)\n",
    "        else:\n",
    "            cfg['fitness'] = fits[idx]\n",
    "        cfg['n_evals'] = cfg['n_evals'] + 1\n",
    "    #---------------------------------------------------------------------------------\n",
    "    # 1.3) Inserting configurations from the PSO algorithm\n",
    "    if use_pso:\n",
    "        pso_name = path + \"pso_\" + fname2\n",
    "        try:\n",
    "            with open(pso_name, 'rb') as f:\n",
    "                pso_pop = pickle.load(f)\n",
    "                f.close()\n",
    "            ext_pop = pop + pso_pop\n",
    "            print(\"Mixed pso and gene pops!!!\")\n",
    "        except IOError:\n",
    "            if gen > 2: # if the pso algorithm should likely be done\n",
    "                from warnings import warn\n",
    "                warn('population ' + pso_name + 'could not be imported',\n",
    "                     UserWarning)\n",
    "            ext_pop = pop\n",
    "    #---------------------------------------------------------------------------------\n",
    "    # 2) Sort according to fitness. Lowest error first.\n",
    "    if use_pso:\n",
    "        pop = sorted(ext_pop, key=lambda d: d['fitness'])[:pop_len]\n",
    "    else:\n",
    "        pop = sorted(pop, key=lambda d: d['fitness'])\n",
    "    # 2.1) Save current generation\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(pop, f)\n",
    "        f.close()\n",
    "    # 2.2) A quick message\n",
    "    print(\"Generation %d evaluated. Best fitness: %.3f\"%(gen,pop[0]['fitness']))\n",
    "    print(\"Mean fitness = %.3f\"%(np.mean(np.array(fits))))\n",
    "    # 2.3) If best fitness good enough, break\n",
    "    if pop[0]['fitness'] < target_fitness:\n",
    "        print(\"Good enough parameters found. Stopping search.\")\n",
    "        break\n",
    "    # 3) mate and replace\n",
    "    # 3.1) Select individuals to be replaced with probability proportional to error\n",
    "    fits.sort() # sort the fitnesses (now in the same order as pop)\n",
    "    fits = np.array(fits)\n",
    "    fits = fits/fits.sum() # normalize fitnesses so they add to 1\n",
    "    cumsum_fits = fits[:] # cumsum_fits[i] = sum(fits[:i])\n",
    "    for i in range(1,len(cumsum_fits)):\n",
    "        cumsum_fits[i] = cumsum_fits[i-1] + cumsum_fits[i]\n",
    "    repl_list = [] # list with indexes of individuals to be replaced\n",
    "    while len(repl_list) < n_mates:\n",
    "        min_r = cumsum_fits[n_save] # don't replace the first n_save individuals\n",
    "        r = min_r + (1.-min_r) * np.random.random()\n",
    "        candidate = n_save\n",
    "        for i in range(n_save, len(fits)):\n",
    "            if cumsum_fits[i] > r:\n",
    "                break\n",
    "            candidate += 1\n",
    "        if candidate in repl_list:\n",
    "            continue\n",
    "        else:\n",
    "            repl_list.append(candidate)\n",
    "    print(\"to replace: \", end='')\n",
    "    print(repl_list)\n",
    "    # 3.2) Arrange individuals in random pairs\n",
    "    perm = np.random.permutation(n_mates) # this will do \n",
    "    # 3.3) mate\n",
    "    new_pops = []\n",
    "    for i in range(int(np.floor(n_mates/2))):\n",
    "        off1, off2 = create_offspring(pop[perm[2*i]], pop[perm[2*i+1]])\n",
    "        new_pops.append(off1)\n",
    "        new_pops.append(off2)\n",
    "    # 3.4) replace\n",
    "    for i, cfg in enumerate(new_pops):\n",
    "        pop[repl_list[i]] = cfg\n",
    "    # 4) mutate\n",
    "    # 4.1) soft mutations\n",
    "    for _ in range(n_soft_mut):\n",
    "        idx = np.random.randint(len(pop))\n",
    "        if idx < n_save:\n",
    "            copy = pop[idx].copy()\n",
    "            soft_mutate(copy, r_soft_mut)\n",
    "            pop[-idx-1] = copy\n",
    "            pop[-idx-1]['fitness'] = None\n",
    "            pop[-idx-1]['n_evals'] = 0\n",
    "        else:\n",
    "            soft_mutate(pop[idx], r_soft_mut)\n",
    "            pop[idx]['fitness'] = None\n",
    "            pop[idx]['n_evals'] = 0\n",
    "    # 4.2) mutations\n",
    "    # 4.2.1) select individuals to mutate\n",
    "    # sq_fits = fits*fits\n",
    "    #cumsum_sq_fits = fits * fits # cumsum_sq_fits[i] = sum(sq_fits[:i])\n",
    "    cumsum_sq_fits = fits # proportional to fits, rather than its square\n",
    "    cumsum_sq_fits = cumsum_sq_fits / cumsum_sq_fits.sum()\n",
    "    for i in range(1,len(cumsum_sq_fits)):\n",
    "        cumsum_sq_fits[i] = cumsum_sq_fits[i-1] + cumsum_sq_fits[i]\n",
    "    mut_list = [] # list with indexes of individuals to be mutate\n",
    "    while len(mut_list) < n_mut:\n",
    "        r = np.random.random()\n",
    "        candidate = 0\n",
    "        for i in range(len(fits)):\n",
    "            if cumsum_sq_fits[i] > r:\n",
    "                break\n",
    "            candidate += 1\n",
    "        if candidate in mut_list:\n",
    "            continue\n",
    "        else:\n",
    "            mut_list.append(candidate)\n",
    "    print(\"to mutate: \", end='')\n",
    "    print(mut_list)\n",
    "    for idx in mut_list:\n",
    "        if idx < n_save:\n",
    "            copy = pop[idx].copy()\n",
    "            mutate(copy)\n",
    "            pop[-idx-1] = copy\n",
    "            pop[-idx-1]['fitness'] = None\n",
    "            pop[-idx-1]['n_evals'] = 0\n",
    "        else:\n",
    "            mutate(pop[idx])\n",
    "            pop[idx]['fitness'] = None\n",
    "            pop[idx]['n_evals'] = 0\n",
    "            \n",
    "    print('generation %d finished in %s seconds' % (gen, time.time() - start_time))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n",
      "17\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "for cfg in pop:\n",
    "    if not 'b_e' in cfg:\n",
    "        print(len(cfg))\n",
    "        \n",
    "print(len(pop[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Particle Swarm Optimization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for the PSO algorithm\n",
    "# These methods assume that 'par_list' and 'ranges' have been defined.\n",
    "ref_cfg = pop[0] # a configuration with all values, including those that\n",
    "                 # are not in par_list\n",
    "    \n",
    "def add_to_cfg(cfg, vel):\n",
    "    \"\"\" Add a vector to the values of a configuration.\n",
    "    \n",
    "        Args:\n",
    "            cfg : a configuration dictionary\n",
    "            vel : Numpy array of values to be added\n",
    "            \n",
    "        The values in 'vel' are in the order of 'par_list'.\n",
    "        Each entry in vel is a value in the [-mv, mv] interval, where mv\n",
    "        is a parameter indicating the maximum velocity.\n",
    "        \n",
    "        For each parameter 'par_name' in 'par_list', the corresponding\n",
    "        value in vel will be multiplied times\n",
    "        (ranges[par_name]['high'] - ranges[par_name]['low'])\n",
    "        before being added.\n",
    "        \n",
    "        If a value exceeds the limits set in 'ranges' it will be clipped.\n",
    "    \"\"\"\n",
    "    for idx, name in enumerate(par_list):\n",
    "        cfg[name] += vel[idx] * (\n",
    "                       ranges[name]['high'] - ranges[name]['low'])\n",
    "        cfg[name] = max( min(ranges[name]['high'], cfg[name]),\n",
    "                           ranges[name]['low'])\n",
    "        \n",
    "def add_vel(vel, acc, mv=0.5):\n",
    "    \"\"\" Add an acceleration to a velocity vector.\n",
    "    \n",
    "        Args:\n",
    "            vel : velocity vector (numpy array).\n",
    "            acc : acceleration vector (numpy array).\n",
    "            mv : maximum velocity.\n",
    "        Returns:\n",
    "            vel + acc\n",
    "            \n",
    "        The entries of 'vel' and 'acc' are in the order of 'par_list'.\n",
    "        If vel[i] + acc[i] > mv, or vel[i] + acc[i] < -mv, values will be\n",
    "        clipped.\n",
    "    \"\"\"\n",
    "    return np.maximum(np.minimum(vel + acc, mv), -mv)\n",
    "    \n",
    "def cfg_to_vec(cfg):\n",
    "    \"\"\" Convert a configuration dictionary to a vector.\n",
    "    \n",
    "        Args:\n",
    "            cfg: configuration dictionary.\n",
    "        Returns:\n",
    "            vec: a numpy array with the values of the configuration.\n",
    "            \n",
    "        The order of the values in 'vec' is that of 'par_list'.\n",
    "        The 'cfg' entries for 'fitness', 'n_evals', 't_pres', and\n",
    "        'par_heter' will be omitted in 'vec'.\n",
    "    \"\"\"\n",
    "    vec = np.zeros(len(par_list))\n",
    "    for idx, name in enumerate(par_list):\n",
    "        vec[idx] = cfg[name]\n",
    "    return vec\n",
    "\n",
    "def vec_to_cfg(vec, fitness=None, n_evals=0, t_pres=None, par_heter=0.01):\n",
    "    \"\"\" Convert a vector to a configuration dictionary.\n",
    "    \n",
    "        Args:\n",
    "            vec: array-like with the values for the configuration.\n",
    "            'fitness', 'n_evals', 't_pres', 'par_heter': values not present\n",
    "                in 'vec' that will be appendend to the configuration dict.\n",
    "        Returns:\n",
    "            cfg: a configuration dictionary with the values in vec.\n",
    "            \n",
    "        The order of the values in vec should be that of 'par_list'.\n",
    "    \"\"\"\n",
    "    cfg = ref_cfg\n",
    "    for val, name in zip(vec, par_list):\n",
    "        cfg[name] = val\n",
    "    cfg['fitness'] = fitness\n",
    "    cfg['n_evals'] = n_evals\n",
    "    cfg['t_pres'] = t_pres\n",
    "    cfg['par_heter'] = par_heter\n",
    "    return cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 evaluated. Best fitness: 0.116\n",
      "Mean fitness = 0.222\n",
      "Iteration 0 finished in 27.140151500701904 seconds\n",
      "Iteration 1 evaluated. Best fitness: 0.116\n",
      "Mean fitness = 0.229\n",
      "Iteration 1 finished in 27.320566415786743 seconds\n",
      "Iteration 2 evaluated. Best fitness: 0.043\n",
      "Mean fitness = 0.198\n",
      "Iteration 2 finished in 26.635707139968872 seconds\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "###### The PSO algorithm ######\n",
    "###############################\n",
    "\n",
    "W = 0.4 # inertia weight\n",
    "c1 = 0.6 # weight of accel towards personal best\n",
    "c2 = 0.2 # weight of accel towards global best\n",
    "mv = 0.4 # maximum velocity (relative to range witdth of paramter)\n",
    "\n",
    "use_gene = False # insert particles from a concomitant genetic algorithm\n",
    "sig = lambda f: 1./(1. + np.exp(4.*(f + 0.1))) # to set probability of insertion\n",
    "\n",
    "max_iters = 80 # maximum number of iterations\n",
    "n_procs = 15 # number of processes to use for fitness evaluation\n",
    "\n",
    "g_best_f = 1e10 # best fitness so far\n",
    "p_best_fs = [1e10] * len(pop) # best personal fitnesses\n",
    "t_pres = pop[0]['t_pres'] # assuming all presentation times are equal\n",
    "vels = np.random.random((len(pop), len(par_list))) - 0.5 # initial velocities\n",
    "\n",
    "g_best = cfg_to_vec(pop[0]) # arbitrary initialization of global best\n",
    "p_bests = np.zeros((len(pop), len(par_list)))\n",
    "for idx, cfg in enumerate(pop):\n",
    "    p_bests[idx,:] = cfg_to_vec(cfg)\n",
    "\n",
    "# setting name for file where parameters will be stored\n",
    "#path = \"/home/z/projects/draculab/saves/\"\n",
    "path = \"/home/z/Dropbox (OIST)/saves/\"\n",
    "fname1 = \"pso\"\n",
    "fname2 = datetime.now().strftime('%Y-%m-%d')\n",
    "fname = path + fname1 + \"_\" + fname2\n",
    "\n",
    "for itr in range(max_iters):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 1) Evaluate fitness\n",
    "    # 1.1) Do the evaluation\n",
    "    ######### Single process version\n",
    "    #fits = list(map(eval_config, pop))\n",
    "    ######## parallel version\n",
    "    with Pool(n_procs) as p:\n",
    "        fits = list(p.map(eval_config, pop))\n",
    "        p.close()\n",
    "        p.join()\n",
    "    #print(fits)\n",
    "    # 1.2) update the average fitness values\n",
    "    # In PSO configurations change every iteration, so n_evals is \n",
    "    # either 0 or 1. However, some configuration may have come from the\n",
    "    # genetic algorithm, so we consider the case n_evals > 0\n",
    "    for idx, cfg in enumerate(pop):\n",
    "        nr = cfg['n_evals'] # n_evals is not updated yet...\n",
    "        if nr > 0:\n",
    "            if nr <= max_evals: \n",
    "                cfg['fitness'] = (cfg['fitness']*nr + fits[idx])/(nr+1)\n",
    "        else:\n",
    "            cfg['fitness'] = fits[idx]\n",
    "        cfg['n_evals'] = cfg['n_evals'] + 1\n",
    "        \n",
    "    # 2) Find indexes that sort according to fitness. Lowest error first.\n",
    "    srt_idx = np.argsort(fits)\n",
    "    \n",
    "    # 3.1) Update g_best\n",
    "    if fits[srt_idx[0]] < g_best_f:\n",
    "        g_best_f = fits[srt_idx[0]]\n",
    "        g_best = cfg_to_vec(pop[srt_idx[0]])\n",
    "        \n",
    "    for idx, cfg in enumerate(pop):\n",
    "        cfg_vec = cfg_to_vec(cfg)\n",
    "        # 3.2) Update p_bests\n",
    "        if cfg['fitness'] < p_best_fs[idx]:\n",
    "            p_best_fs[idx] = cfg['fitness']\n",
    "            p_bests[idx] = cfg_vec\n",
    "            \n",
    "        # 4) Update velocities\n",
    "        r1, r2 = np.random.random(2)\n",
    "        vels[idx] = add_vel(W * vels[idx], c1 * r1 * (p_bests[idx] - cfg_vec))\n",
    "        vels[idx] = add_vel(vels[idx], c2 * r2 * (g_best - cfg_vec))\n",
    "    \n",
    "    # 5) Save current iteration\n",
    "    best_pop = [vec_to_cfg(g_best, fitness=g_best_f, n_evals=1, t_pres=t_pres)] + pop\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(best_pop, f)\n",
    "        f.close()\n",
    "    \n",
    "    # A quick message\n",
    "    print(\"Iteration %d evaluated. Best fitness: %.3f\"%(itr, g_best_f))\n",
    "    print(\"Mean fitness = %.3f\"%(np.mean(np.array(fits))))\n",
    "    # 2.3) If best fitness good enough, break\n",
    "    if g_best_f < target_fitness:\n",
    "        print(\"Good enough parameters found. Stopping search.\")\n",
    "        break\n",
    "    \n",
    "    # 6) Update particles\n",
    "    for idx, cfg in enumerate(pop):\n",
    "        add_to_cfg(cfg, vels[idx])\n",
    "        \n",
    "    #---------------------------------------------------------------------------------\n",
    "    # 7) Inserting a configuration from the genetic algorithm\n",
    "    if use_gene:\n",
    "        g_name = path + \"gene_\" + fname2\n",
    "        try:\n",
    "            with open(g_name, 'rb') as f:\n",
    "                gene_pop = pickle.load(f)\n",
    "                f.close()\n",
    "            gene_cfg = gene_pop[0]\n",
    "            in_prob = sig(g_best_f - gene_cfg['fitness']) # insertion probability\n",
    "            if np.random.random() < in_prob:\n",
    "                rem_idx = np.random.randint(len(pop))\n",
    "                pop[rem_idx] = gene_cfg\n",
    "                fits[rem_idx] = gene_cfg['fitness']\n",
    "                print(\"inserted pop \" + str(rem_idx) + \"!!!\")    \n",
    "        except IOError:\n",
    "            if itr > 2: # if the genetic algorithm should likely be done\n",
    "                from warnings import warn\n",
    "                warn('population ' + g_name + 'could not be imported',\n",
    "                     UserWarning)\n",
    "                \n",
    "    print('Iteration %d finished in %s seconds' % (itr, time.time() - start_time))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A__M_lrate':2.73, 'A__M_w_max_frac':0.21, 'A__M_w_sum':21.50, 'AL_thresh':-0.08, 'b_e':3.88, 'C__C_antag':1.42, 'C__C_p_antag':0.74, 'C__C_p_syne':0.35, 'C__C_syne':0.33, 'C_adapt_amp':11.41, 'C_cid':0.10, 'C_sigma':0.48, 'C_slope':1.77, 'C_thresh':0.35, 'CE__CI_w':0.71, 'CI__CE_w':-1.83, 'g_e_factor':1.71, 'M__C_lrate':343.75, 'M__C_w_sum':5.47, 'M__M_w':0.00, 'M_cid':0.93, 'M_des_out_w_abs_sum':1.46, 'SPF__SPF_w':-0.07, 'fitness':0.34, 'n_evals':1.00, 't_pres':40.00, 'par_heter':0.01, }\n",
      "\n",
      "{'A__M_lrate':5.76, 'A__M_w_max_frac':0.50, 'A__M_w_sum':21.50, 'AL_thresh':0.25, 'b_e':1.44, 'C__C_antag':1.51, 'C__C_p_antag':0.54, 'C__C_p_syne':0.38, 'C__C_syne':0.84, 'C_adapt_amp':15.00, 'C_cid':0.12, 'C_sigma':0.12, 'C_slope':2.84, 'C_thresh':0.80, 'CE__CI_w':1.10, 'CI__CE_w':-1.93, 'g_e_factor':1.96, 'M__C_lrate':337.44, 'M__C_w_sum':5.45, 'M__M_w':0.00, 'M_cid':0.99, 'M_des_out_w_abs_sum':2.15, 'SPF__SPF_w':-0.40, 'fitness':0.13, 'n_evals':1.00, 't_pres':40.00, 'par_heter':0.01, }\n",
      "\n",
      "{'A__M_lrate':4.83, 'A__M_w_max_frac':0.23, 'A__M_w_sum':21.50, 'AL_thresh':0.30, 'b_e':0.90, 'C__C_antag':1.42, 'C__C_p_antag':0.53, 'C__C_p_syne':0.47, 'C__C_syne':0.80, 'C_adapt_amp':13.15, 'C_cid':0.43, 'C_sigma':0.38, 'C_slope':2.57, 'C_thresh':0.87, 'CE__CI_w':0.98, 'CI__CE_w':-2.03, 'g_e_factor':2.22, 'M__C_lrate':307.47, 'M__C_w_sum':5.48, 'M__M_w':0.00, 'M_cid':0.84, 'M_des_out_w_abs_sum':2.20, 'SPF__SPF_w':0.00, 'fitness':0.13, 'n_evals':1.00, 't_pres':40.00, 'par_heter':0.01, }\n",
      "\n",
      "{'A__M_lrate':0.10, 'A__M_w_max_frac':0.12, 'A__M_w_sum':17.70, 'AL_thresh':0.14, 'b_e':2.13, 'C__C_antag':0.52, 'C__C_p_antag':0.45, 'C__C_p_syne':0.45, 'C__C_syne':0.58, 'C_adapt_amp':4.48, 'C_cid':0.24, 'C_sigma':0.12, 'C_slope':2.62, 'C_thresh':0.76, 'CE__CI_w':0.03, 'CI__CE_w':-1.96, 'g_e_factor':0.76, 'M__C_lrate':394.82, 'M__C_w_sum':5.29, 'M__M_w':0.00, 'M_cid':0.74, 'M_des_out_w_abs_sum':0.68, 'SPF__SPF_w':-1.49, 'fitness':0.17, 'n_evals':1.00, 't_pres':40.00, 'par_heter':0.01, }\n",
      "\n",
      "{'A__M_lrate':1.78, 'A__M_w_max_frac':0.46, 'A__M_w_sum':18.80, 'AL_thresh':-0.08, 'b_e':3.95, 'C__C_antag':0.79, 'C__C_p_antag':0.41, 'C__C_p_syne':0.79, 'C__C_syne':0.51, 'C_adapt_amp':15.00, 'C_cid':0.23, 'C_sigma':0.59, 'C_slope':3.04, 'C_thresh':0.92, 'CE__CI_w':0.41, 'CI__CE_w':-1.48, 'g_e_factor':2.69, 'M__C_lrate':152.50, 'M__C_w_sum':4.05, 'M__M_w':0.00, 'M_cid':1.40, 'M_des_out_w_abs_sum':1.57, 'SPF__SPF_w':-0.05, 'fitness':0.38, 'n_evals':1.00, 't_pres':40.00, 'par_heter':0.01, }\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A__M_lrate': 2.7341357230234973,\n",
       " 'A__M_w_max_frac': 0.20605804471513278,\n",
       " 'A__M_w_sum': 21.5,\n",
       " 'AL_thresh': -0.08179848000533585,\n",
       " 'b_e': 3.8828035128252716,\n",
       " 'C__C_antag': 1.4228292992516052,\n",
       " 'C__C_p_antag': 0.7397524146335008,\n",
       " 'C__C_p_syne': 0.3516800011288286,\n",
       " 'C__C_syne': 0.325460593028586,\n",
       " 'C_adapt_amp': 11.410677400994746,\n",
       " 'C_cid': 0.1,\n",
       " 'C_sigma': 0.48150726198995586,\n",
       " 'C_slope': 1.7696225876919747,\n",
       " 'C_thresh': 0.3455782249196093,\n",
       " 'CE__CI_w': 0.7102217806543719,\n",
       " 'CI__CE_w': -1.828816851437376,\n",
       " 'g_e_factor': 1.7114423657602078,\n",
       " 'M__C_lrate': 343.7463363436077,\n",
       " 'M__C_w_sum': 5.470939880845892,\n",
       " 'M__M_w': 0.0,\n",
       " 'M_cid': 0.9325076280660229,\n",
       " 'M_des_out_w_abs_sum': 1.4606924993186237,\n",
       " 'SPF__SPF_w': -0.06690836645601457,\n",
       " 'fitness': 0.3389436976213204,\n",
       " 'n_evals': 1,\n",
       " 't_pres': 40,\n",
       " 'par_heter': 0.01}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print final population\n",
    "for dic in pop[:5]:\n",
    "    print('{',end='')\n",
    "    for name in dic.keys():\n",
    "        if name != 'fitness' or dic['fitness'] != None:\n",
    "            print(\"\\'%s\\':%.2f, \" % (name, dic[name]), end='')\n",
    "    print('}\\n')\n",
    "\n",
    "pop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final population\n",
    "fname = \"v3_nst_afx_pop\"\n",
    "fname += \"_\" + datetime.now().strftime('%Y-%m-%d__%H_%M')\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(pop, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved population\n",
    "import pickle\n",
    "fname = 'v3_nst_afx_pop'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    results = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a configuation\n",
    "cfg_id = 0 # index in the population for the configuration\n",
    "net, pops_dict, hand_coords, m_idxs, t_pres, _  = net_from_cfg(pop[cfg_id])\n",
    "pops_names = ['SF', 'SP', 'SPF', 'AL', 'AF', 'SP_CHG', 'CE', 'CI', 'M', 'ACT', 'P']\n",
    "for name in pops_names:\n",
    "    exec(\"%s = %s\"% (name, str(pops_dict[name])))\n",
    "\n",
    "start_time = time.time()\n",
    "times, data, plant_data  = net.flat_run(600.)\n",
    "#times, data, plant_data  = net.run(40.)\n",
    "print('Execution time is %s seconds' % (time.time() - start_time))\n",
    "data = np.array(data)\n",
    "#Execution time is 8.687349319458008 seconds  << before sc_inp_sum_mp, flat_run(5.)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# reducing the scope of the plots\n",
    "data_back = data\n",
    "times_back = times\n",
    "plant_data_back = [np.array([])]\n",
    "plant_data_back[0] = plant_data[0]\n",
    "\n",
    "first_idx=100*200\n",
    "second_idx=115*200\n",
    "times = times[first_idx:second_idx]\n",
    "data = data[:, first_idx:second_idx]\n",
    "plant_data[0] = plant_data[0][first_idx:second_idx,:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# recover the data\n",
    "data = data_back\n",
    "plant_data[0] = plant_data_back[0]\n",
    "times = times_back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same history as `v3_nst_afx`\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
