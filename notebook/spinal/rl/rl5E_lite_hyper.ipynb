{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rl5E_lite_hyper.ipynb\n",
    "\n",
    "Hyperparamter search of the `rl5E.ipynb` model using a genetic algorithm.\n",
    "\n",
    "Regarding `rl5E`:\n",
    "This notebook contains the fifth step in the 5-step process outlined in November 13th, 2020, in order to produce an actor-critic architecture for pendulum control. \n",
    "\n",
    "In step 1 we create a network with N units that takes the activity of 1 unit and transforms it into a bell-shaped representation.  \n",
    "In step 2 we put 2 of those as the inputs to a (N/2)x(N/2) grid, and visualized.  \n",
    "In step 3 we took the network from step 2 and connected it to the current SP and SD units in `test3p2` to see if the angle is being tracked.  \n",
    "In step 4 we will connect a $V$ neuron to the L (RBF) layer, and tweak TD learning so its output starts to reflect the angular error.  \n",
    "In step 5 the output of $V$ is used to configure a controller. There are three basic options outlined in the November 20th, 2020 entry of the log, and a fourth option in Nov. 30th. This fifth option was introduced in December 1st, 2020.\n",
    "\n",
    "This started as a clone of `rl5C-Copy1`, which means it is setup for `rga_sig` units in C.\n",
    "\n",
    "Currently transforming it into `rl5E_lite_hyper`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/z/projects/draculab\n"
     ]
    }
   ],
   "source": [
    "%cd /home/z/projects/draculab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from draculab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "#from tools.visualization import plotter\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/z/projects/draculab/notebook/spinal/rl\n"
     ]
    }
   ],
   "source": [
    "%cd /home/z/projects/draculab/notebook/spinal/rl\n",
    "# Move to the folder with the rl5E_lite_from_cfg file is\n",
    "from rl5E_lite_from_cfg import rl5E_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying parameters and ranges in the configuration\n",
    "focus_params = True # whether to focus mutations on a specific set of parameters\n",
    "\n",
    "# Specify paramters and ranges\n",
    "# defaults are based on incumbent 9 of smac_pars in v3_normal_smac_test.ipynb\n",
    "ranges = {\"C_sigma\": {\"low\": 0.01, \"high\": 1., \"default\": 0.4 }, # yes\n",
    "          \"C_slope\": {\"low\": 1., \"high\": 3., \"default\": 2. },\n",
    "          \"C_thresh\": {\"low\": 0.0, \"high\": .2, \"default\":0.2},\n",
    "          \"C_integ_amp\": {\"low\": 0.0, \"high\": 1.5, \"default\": 0.0},\n",
    "          \"C_custom_inp_del\": {\"low\": 10, \"high\": 300, \"default\": 150}, # seemingly replaced in the code\n",
    "          \"M_des_out_w_abs_sum\": {\"low\": 0.5, \"high\": 3., \"default\":1.6},\n",
    "          \"P_mu\": {\"low\": .1, \"high\": 2., \"default\":1.},\n",
    "          \"P_inp_gain\": {\"low\": 0.5, \"high\": 4., \"default\":2.},\n",
    "          \"SF_slope\": {'low':0.5, \"high\":3., \"default\":2.},\n",
    "          \"V_slope\": {\"low\": 0.3, \"high\": 2.5, \"default\":1.5}, #yes\n",
    "          \"V_delta\": {\"low\": .2, \"high\": 4., \"default\":1.}, #yes\n",
    "          \"V_thresh\": {\"low\": -0.1, \"high\": 2., \"default\":0.}, # no\n",
    "          \"V_td_lrate\": {\"low\": 0.2, \"high\": 7., \"default\": 1.5}, # yes\n",
    "          \"V_td_gamma\": {\"low\": 0.1, \"high\": .95, \"default\": .6}, # yes\n",
    "          \"V_w_sum\": {\"low\": 10., \"high\": 100., \"default\": 60.}, # yes\n",
    "          \"X_slope\": {\"low\": 2., \"high\": 10., \"default\":5.}, #yes\n",
    "          \"X_thresh\": {\"low\": -0.2, \"high\": 2., \"default\":1.}, # no\n",
    "          \"X_del\": {\"low\": 0., \"high\": 1.5, \"default\":0.3},\n",
    "          \"X_lrate\": {\"low\": 50., \"high\": 400., \"default\":200.},\n",
    "          \"X_w_sum\": {\"low\": 10., \"high\": 80., \"default\": 30.}, # yes\n",
    "          \"X_refr_per\": {\"low\": 0.5, \"high\": 4., \"default\":2.}, # yes\n",
    "          \"X_tau_slow\": {\"low\": 25., \"high\": 500., \"default\":50.}, # yes\n",
    "          \"A__M_lrate\": {\"low\": 0.05, \"high\": 10., \"default\":5.},\n",
    "          \"A__M_w_sum\": {\"low\": 0.3, \"high\": 2., \"default\":.4},\n",
    "          \"A__M_w_max\": {\"low\": 0.2, \"high\": .4, \"default\":.3},\n",
    "          \"M__C_lrate\": {\"low\": 1., \"high\": 400., \"default\":100.},\n",
    "          \"r_thr\": {\"low\": np.pi/10., \"high\": np.pi/4., \"default\":np.pi/6.}\n",
    "         }\n",
    "\n",
    "# if focus_params == True, ignore the other parameters\n",
    "if focus_params:\n",
    "    main_pars = [\"V_delta\", \"V_td_gamma\", \n",
    "                 \"X_refr_per\", \"X_tau_slow\", \"X_del\", \"X_lrate\", \"X_w_sum\"]\n",
    "    par_list = main_pars\n",
    "else:\n",
    "    par_list = list(ranges.keys())\n",
    "    \n",
    "def mutate(cfg, name_list=par_list):\n",
    "    \"\"\" Mutate a single parameter of the given configuration. \n",
    "    \n",
    "        Args:\n",
    "            name_list: list with names of candidate parameters.\n",
    "    \"\"\"\n",
    "    n = np.random.randint(len(name_list))\n",
    "    par_name = name_list[n]\n",
    "    l = ranges[par_name]['low']\n",
    "    h = ranges[par_name]['high']\n",
    "    cfg[par_name] =  l + (h-l)*np.random.random()\n",
    "    \n",
    "def soft_mutate(cfg, ma, name_list=par_list):\n",
    "    \"\"\" Soft-mutate a single parameter of the given configuration.\n",
    "    \n",
    "        A 'soft mutation' keeps the mutated value close to the original value.\n",
    "        The maximum amplitude of the mutation is given by the 'ma' argument.\n",
    "        \n",
    "        Args:\n",
    "            ma : float in (0,1]. Max. amplitude as fraction of the parameter's range \n",
    "            name_list: list with names of candidate parameters.\n",
    "    \"\"\"\n",
    "    n = np.random.randint(len(name_list))\n",
    "    par_name = name_list[n]\n",
    "    l = ranges[par_name]['low']\n",
    "    h = ranges[par_name]['high']\n",
    "    cfg[par_name] = max(l, min(h, cfg[par_name] + ma * (h-l) * (np.random.random()-0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_config(cfg):\n",
    "    \"\"\" Returns the change in mean reward after training with a given configuration. \n",
    "    \n",
    "        Two simulations are run, one with switching X for cfg['sim_time1'] seconds,\n",
    "        and one without switching X for cfg['sim_time2'] seconds.\n",
    "        \n",
    "        Args:\n",
    "            cfg : parameter dictionary to initialze rl5E_net. \n",
    "            \n",
    "        Returns:\n",
    "            An error value equal to (mean_R1 - mean_R2)\n",
    "                'mean_R1' : mean reward in the first (X switch) simulation.\n",
    "                'mean_R2' : mean reward in the second (X free) simulation.\n",
    "    \"\"\"\n",
    "    net, pops_dict = rl5E_net(cfg, \n",
    "                          pres_interv=cfg['pres_interv'],\n",
    "                          rand_w=False,\n",
    "                          par_heter=0.1,\n",
    "                          x_switch=True,\n",
    "                          V_normalize=True,\n",
    "                          X_normalize=True)\n",
    "    \n",
    "    R = pops_dict['R']\n",
    "    \n",
    "    times1, data1, plant_data1 = net.run(cfg['sim_time1'])\n",
    "    mean_R1 = np.mean(data1[R[0]])\n",
    "    \n",
    "    net.units[pops_dict['X'][0]].switch = False # stop swtiching\n",
    "    \n",
    "    times2, data2, plant_data2 = net.run(cfg['sim_time2'])\n",
    "    mean_R2 = np.mean(data2[R[0]])\n",
    "    \n",
    "    error = mean_R1 - mean_R2\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an initial population from random range variations\n",
    "pop_size = 60 # population size\n",
    "n_def = 2 # number of individuals with default values\n",
    "n_muts = 25 # number of mutations\n",
    "n_soft_muts = 25 # number of soft mutations\n",
    "pop = []\n",
    "\n",
    "# first fill the population with default values\n",
    "def_vals = {name : ranges[name]['default'] for name in par_list}\n",
    "for ind in range(pop_size):\n",
    "    pop.append(def_vals.copy())\n",
    "        \n",
    "# fill the rest with variations in both directions\n",
    "chg_name = [\"low\", \"default\", \"high\"] # auxiliary list\n",
    "for ind in range(n_def, pop_size):\n",
    "    chg_dirs = [chg_name[i] for i in np.random.randint(3, size=len(par_list))]\n",
    "    for idx, name in enumerate(par_list):\n",
    "        pop[ind][name] = 0.5 * (ranges[name][chg_dirs[idx]] + ranges[name][\"default\"])\n",
    "        \n",
    "# Throw n_muts mutations, and n_soft_muts soft mutations\n",
    "perm = np.random.permutation(range(n_def,pop_size))\n",
    "for i in range(n_muts):\n",
    "    mutate(pop[perm[i]])\n",
    "for i in range(n_muts,n_muts+n_soft_muts):\n",
    "    soft_mutate(pop[perm[i]], 0.2)\n",
    "\n",
    "# reset fitness and number of evaluations\n",
    "for dic in pop:\n",
    "    dic['fitness'] = None # average fitness value\n",
    "    dic['n_evals'] = 0  # number of times fitness has been evaluated\n",
    "    \n",
    "# For all the parameters not in main_pars, \n",
    "# fill cfg with the default values.\n",
    "for cfg in pop:\n",
    "    for name in ranges:\n",
    "        if not name in cfg:\n",
    "            cfg[name] = ranges[name]['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/z/projects/draculab/saves\n"
     ]
    }
   ],
   "source": [
    "# Create an initial population based on a run of rl5E_lite_par\n",
    "pop = []\n",
    "# load the results file\n",
    "%cd /home/z/projects/draculab/saves\n",
    "fname = 'rl5E_lite_par_2021-03-17__22_28'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    res_dict = pickle.load(f)\n",
    "    f.close()\n",
    "configs = res_dict['configs']\n",
    "for idx in range(16): # configs only contains N unique configurations\n",
    "    pop.append(configs[idx])\n",
    "    \n",
    "# Also include parameters used for the case of gravity, but with lower gain\n",
    "cf = {'C_sigma': 0.4,\n",
    "     'C_slope': 2.0,\n",
    "     'C_thresh': 0.2,\n",
    "     'C_integ_amp': 0.0,\n",
    "     'C_custom_inp_del': 150,\n",
    "     'M_des_out_w_abs_sum': 1.6,\n",
    "     'P_mu': 1.0,\n",
    "     'P_inp_gain': 2.,\n",
    "     'SF_slope': 1.5,\n",
    "     'V_slope': 1.5,\n",
    "     'V_delta': 1.0,\n",
    "     'V_thresh': 0.0,\n",
    "     'V_td_lrate': 1.0,\n",
    "     'V_td_gamma': 0.6,\n",
    "     'V_w_sum': 40.0,\n",
    "     'X_slope': 5.0,\n",
    "     'X_thresh': 1.1,\n",
    "     'X_del': 0.3,\n",
    "     'X_lrate': 30.0,\n",
    "     'X_w_sum': 40.0,\n",
    "     'X_refr_per' : 2.,\n",
    "     'X_tau_slow' : 200.,\n",
    "     'A__M_lrate': 5.0,\n",
    "     'A__M_w_sum': 0.4,\n",
    "     'A__M_w_max': 0.3,\n",
    "     'M__C_lrate': 100.0,\n",
    "     'pres_interv': 5.0,\n",
    "     'X_type': unit_types.x_netB,\n",
    "     'r_thr': 0.5235987755982988}\n",
    "\n",
    "# For all the parameters not in main_pars, \n",
    "# fill cfg with the default values.\n",
    "for cfg in pop:\n",
    "    for name in ranges:\n",
    "        if not name in cfg:\n",
    "            cfg[name] = ranges[name]['default']\n",
    "\n",
    "# so far there are 17 unique configurations. The rest\n",
    "# of the population will be mutations of these\n",
    "pop.append(cf)\n",
    "pop = pop*3 # 51 individuals\n",
    "pop_size = len(pop)\n",
    "\n",
    "# Throw n_muts mutations, and n_soft_muts soft mutations\n",
    "n_muts = 100 # number of mutations\n",
    "n_soft_muts = 100 # number of soft mutations\n",
    "n_def = 17 # the initial n_def populations are not changed\n",
    "perm = np.tile(np.random.permutation(range(n_def,pop_size)), 10)\n",
    "for i in range(n_muts):\n",
    "    mutate(pop[perm[i]])\n",
    "for i in range(n_muts,n_muts+n_soft_muts):\n",
    "    soft_mutate(pop[perm[i]], 0.2)\n",
    "\n",
    "# reset fitness and number of evaluations\n",
    "for dic in pop:\n",
    "    dic['fitness'] = None # average fitness value\n",
    "    dic['n_evals'] = 0  # number of times fitness has been evaluated\n",
    "    \n",
    "# some extra entries in the configurations\n",
    "for cfg in pop:\n",
    "    if not 'X_type' in cfg:\n",
    "        cfg['X_type'] = unit_types.x_netB\n",
    "    cfg['sim_time1'] = 1800.  # simulation time with switching X\n",
    "    cfg['sim_time2'] = 400.  # simulation time with free X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results from a previous run of rl5E_hyper\n",
    "#%cd /home/z/projects/draculab/saves\n",
    "%cd /home/sergio/projects/draculab/notebook/spinal/rl\n",
    "fname = 'rl5E_lite_hyper_2021-01-22__12_47'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    pop = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "# If the results are form a run with fewer parameters\n",
    "# fill it with the default values.\n",
    "for cfg in pop:\n",
    "    for name in ranges:\n",
    "        if not name in cfg:\n",
    "            cfg[name] = ranges[name]['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg in pop:\n",
    "    cfg['V_td_gamma'] = min(cfg['V_td_gamma'], 0.95)\n",
    "    if 'X_l_rate' in cfg:\n",
    "        cfg['X_lrate'] = cfg['X_l_rate']\n",
    "        cfg.pop('X_l_rate')\n",
    "        print('fixing', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print used configuration\n",
    "for dic in pop[0:4]:\n",
    "    print('{',end='')\n",
    "    for name in dic.keys():\n",
    "        if name != 'fitness' or dic['fitness'] != None:\n",
    "            print(\"\\'%s\\':%.2f, \" % (name, dic[name]), end='')\n",
    "    print('}\\n')\n",
    "\n",
    "pop[0]\n",
    "\n",
    "{'V_slope': 2.0, \n",
    " 'V_delta': 1.9351772436025465, \n",
    " 'V_td_lrate': 4.25, \n",
    " 'V_td_gamma': 0.95, \n",
    " 'V_w_sum': 35.0, \n",
    " 'X_slope': 3.5, \n",
    " 'X_del': 0.9, 'X_lrate': 200.0, 'X_w_sum': 62.666806463642374, 'fitness': 0.2863618487384629, 'n_evals': 2, 'C_sigma': 0.4, 'C_slope': 2.0, 'C_thresh': 0.2, 'C_integ_amp': 0.0, 'C_custom_inp_del': 150, 'M_des_out_w_abs_sum': 1.6, 'P_mu': 1.0, 'P_inp_gain': 2.0, 'V_thresh': 0.0, 'X_thresh': 0.0, 'A__M_lrate': 5.0, 'A__M_w_sum': 0.4, 'A__M_w_max': 0.3, 'M__C_lrate': 100.0, 'SF_slope': 2.0, 'X_lrate': 200.0}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load the results from a previous run\n",
    "fname = 'v3_nst_afx_pop_2020-10-06__13_05'\n",
    "with (open(fname, \"rb\")) as f:\n",
    "    pop = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "# If the results are form a run with fewer parameters\n",
    "# fill it with the default values.\n",
    "for cfg in pop:\n",
    "    for name in ranges:\n",
    "        if not name in cfg:\n",
    "            cfg[name] = ranges[name]['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to produce offspring by crossing individuals\n",
    "par_names = list(pop[0].keys()) # list with all parameter names\n",
    "\n",
    "def create_offspring(cfg1, cfg2, par_list=par_names):\n",
    "    \"\"\" Given 2 configurations, return 2 offspring from random swapping.\n",
    "    \n",
    "        To produce offspring, first we choose one split point in the\n",
    "        dictionary. The first offspring has the values of cfg1 up to that\n",
    "        point, and cfg2 afterwards. The second offspring has the cfg2 values\n",
    "        up to the split point, and cfg1 afterwards. Since the dictionaries are\n",
    "        not ordered, we use a parameter list to set the split point.\n",
    "    \n",
    "        Args:\n",
    "            cfg1, cfg2: parameter dictionaries\n",
    "            par_list: list with the keys in cfg1, cfg2\n",
    "        Returns:\n",
    "            cfg3, cfg4: dictionaries from swapping values in cfg1, cfg2\n",
    "    \"\"\"\n",
    "    if focus_params:\n",
    "        par_list = main_pars\n",
    "    sp = np.random.randint(len(par_list))# split point as an index to par_list\n",
    "    cfg3 = cfg1.copy()\n",
    "    cfg4 = cfg2.copy()\n",
    "    for i in range(sp, len(par_list)):\n",
    "        cfg3[par_list[i]] = cfg2[par_list[i]]\n",
    "        cfg4[par_list[i]] = cfg1[par_list[i]]\n",
    "    return cfg3, cfg4\n",
    "\n",
    "# visualize\n",
    "# cfg3, cfg4 = create_offspring(pop[10], pop[11])\n",
    "# for dic in (pop[10], pop[11], cfg3, cfg4):\n",
    "#     print('{',end='')\n",
    "#     for name in par_names:\n",
    "#         if name != \"fitness\":\n",
    "#             print(\"\\'%s\\':%.2f, \" % (name, dic[name]), end='')\n",
    "#     print('}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 evaluated. Best fitness: -0.130\n",
      "Mean fitness = -0.048\n",
      "to replace: [10, 8, 12, 23, 26, 24, 18, 17, 6, 14, 7, 21]\n",
      "to mutate: [36, 27, 49, 40, 41]\n",
      "generation 0 finished in 11223.508806705475 seconds\n",
      "Generation 1 evaluated. Best fitness: -0.150\n",
      "Mean fitness = -0.058\n",
      "to replace: [9, 14, 15, 16, 6, 5, 8, 18, 24, 21, 13, 10]\n",
      "to mutate: [12, 43, 49, 39, 21]\n",
      "generation 1 finished in 11015.036080598831 seconds\n",
      "Generation 2 evaluated. Best fitness: -0.135\n",
      "Mean fitness = -0.062\n",
      "to replace: [15, 27, 8, 24, 22, 20, 12, 9, 5, 19, 13, 18]\n",
      "to mutate: [20, 34, 28, 9, 19]\n",
      "generation 2 finished in 11092.594983100891 seconds\n",
      "Generation 3 evaluated. Best fitness: -0.168\n",
      "Mean fitness = -0.063\n",
      "to replace: [12, 18, 15, 27, 26, 4, 10, 16, 9, 11, 7, 25]\n",
      "to mutate: [36, 12, 40, 23, 19]\n",
      "generation 3 finished in 11200.46119761467 seconds\n",
      "Generation 4 evaluated. Best fitness: -0.179\n",
      "Mean fitness = -0.070\n",
      "to replace: [18, 15, 9, 12, 13, 20, 14, 4, 7, 16, 23, 24]\n",
      "to mutate: [23, 48, 46, 16, 32]\n",
      "generation 4 finished in 10937.717689752579 seconds\n",
      "Generation 5 evaluated. Best fitness: -0.173\n",
      "Mean fitness = -0.070\n",
      "to replace: [4, 11, 7, 17, 8, 13, 10, 12, 26, 20, 24, 28]\n",
      "to mutate: [50, 35, 19, 23, 12]\n",
      "generation 5 finished in 10987.040393352509 seconds\n",
      "Generation 6 evaluated. Best fitness: -0.166\n",
      "Mean fitness = -0.078\n",
      "to replace: [13, 19, 17, 10, 5, 26, 23, 16, 9, 8, 4, 15]\n",
      "to mutate: [28, 42, 15, 46, 32]\n",
      "generation 6 finished in 10993.291724681854 seconds\n",
      "Generation 7 evaluated. Best fitness: -0.160\n",
      "Mean fitness = -0.084\n",
      "to replace: [25, 11, 8, 4, 16, 10, 18, 13, 14, 28, 27, 5]\n",
      "to mutate: [37, 40, 26, 22, 31]\n",
      "generation 7 finished in 11186.0882730484 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-234:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2b0ee6236826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m######## parallel version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_procs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mfits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fits is a misnomer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/draculab/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/draculab/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/draculab/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/draculab/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/draculab/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################\n",
    "###### The genetic algorithm ######\n",
    "####################################\n",
    "\n",
    "# pop = pop[0:6] # limit pop size for debugging\n",
    "n_mates = 12 # number of individuals to mate at each generation (even number)\n",
    "max_gens = 20 # maximum number of generations\n",
    "n_soft_mut = 10 # numbef of individuals to soft-mutate per generation\n",
    "r_soft_mut = 0.2 # relative amplitude of soft mutations\n",
    "n_mut = 5 # number of individuals to mutate per generation\n",
    "n_procs = 26 # number of processes to use for fitness evaluation\n",
    "n_save = 3 # number of individuals to protect from replacement and mutation\n",
    "# setting name for file where parameters will be stored\n",
    "fname = \"rl5E_lite_hyper\"\n",
    "fname += \"_\" + datetime.now().strftime('%Y-%m-%d__%H_%M')\n",
    "\n",
    "for gen in range(max_gens):\n",
    "    start_time = time.time()\n",
    "    # 1) Evaluate fitness\n",
    "    # 1.1) Do the evaluation\n",
    "    ######### Single process version\n",
    "    #fits = list(map(eval_config, pop))\n",
    "    ######## parallel version\n",
    "    with Pool(n_procs) as p:\n",
    "        fits = list(p.map(eval_config, pop)) #fits is a misnomer\n",
    "        p.close()\n",
    "        p.join()\n",
    "    #print(fits)\n",
    "    # 1.2) update the average fitness values\n",
    "    for idx, cfg in enumerate(pop):\n",
    "        nr = cfg['n_evals'] # n_evals is not updated yet...\n",
    "        #print(nr)\n",
    "        #print(fits[idx])\n",
    "        #print(cfg['fitness'])\n",
    "        if nr > 0:\n",
    "            if nr < 9: # horrible arbitrary number that might be different in eval_config :( \n",
    "                cfg['fitness'] = (cfg['fitness']*nr + fits[idx])/(nr+1)\n",
    "        else:\n",
    "            cfg['fitness'] = fits[idx]\n",
    "        cfg['n_evals'] = cfg['n_evals'] + 1\n",
    "    # 2) Sort according to fitness. Lowest error first.\n",
    "    pop = sorted(pop, key=lambda d: d['fitness'])\n",
    "    #print('Top cfg this generation: ')\n",
    "    #print(pop[0])\n",
    "    # 2.1) Save current generation\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(pop, f)\n",
    "        f.close()\n",
    "    # 2.2) A quick message\n",
    "    print(\"Generation %d evaluated. Best fitness: %.3f\"%(gen,pop[0]['fitness']))\n",
    "    print(\"Mean fitness = %.3f\"%(np.mean(np.array(fits))))\n",
    "    # 2.3) If best fitness good enough, break\n",
    "#     if pop[0]['fitness'] < 0.02:\n",
    "#         print(\"Good enough parameters found. Stopping search.\")\n",
    "#         break\n",
    "    # 3) mate and replace\n",
    "    # 3.1) Select individuals to be replaced with probability proportional to error\n",
    "    fits.sort() # sort the fitnesses (now in the same order as pop)\n",
    "    fits = np.array(fits)\n",
    "    fits = fits/fits.sum() # normalize fitnesses so they add to 1\n",
    "    cumsum_fits = fits[:] # cumsum_fits[i] = sum(fits[:i])\n",
    "    for i in range(1,len(cumsum_fits)):\n",
    "        cumsum_fits[i] = cumsum_fits[i-1] + cumsum_fits[i]\n",
    "    repl_list = [] # list with indexes of individuals to be replaced\n",
    "    while len(repl_list) < n_mates:\n",
    "        min_r = cumsum_fits[n_save] # don't replace the first n_save individuals\n",
    "        r = min_r + (1.-min_r) * np.random.random()\n",
    "        candidate = n_save\n",
    "        for i in range(n_save, len(fits)):\n",
    "            if cumsum_fits[i] > r:\n",
    "                break\n",
    "            candidate += 1\n",
    "        if candidate in repl_list:\n",
    "            continue\n",
    "        else:\n",
    "            repl_list.append(candidate)\n",
    "    print(\"to replace: \", end='')\n",
    "    print(repl_list)\n",
    "    # 3.2) Arrange individuals in random pairs\n",
    "    perm = np.random.permutation(n_mates) # this will do \n",
    "    # 3.3) mate\n",
    "    new_pops = []\n",
    "    for i in range(int(np.floor(n_mates/2))):\n",
    "        off1, off2 = create_offspring(pop[perm[2*i]], pop[perm[2*i+1]])\n",
    "        new_pops.append(off1)\n",
    "        new_pops.append(off2)\n",
    "    # 3.4) replace\n",
    "    for i, cfg in enumerate(new_pops):\n",
    "        pop[repl_list[i]] = cfg\n",
    "    # 4) mutate\n",
    "    # 4.1) soft mutations\n",
    "    for _ in range(n_soft_mut):\n",
    "        idx = np.random.randint(len(pop))\n",
    "        if idx < n_save:\n",
    "            copy = pop[idx].copy()\n",
    "            soft_mutate(copy, r_soft_mut)\n",
    "            pop[-idx-1] = copy\n",
    "            pop[-idx-1]['fitness'] = None\n",
    "            pop[-idx-1]['n_evals'] = 0\n",
    "        else:\n",
    "            soft_mutate(pop[idx], r_soft_mut)\n",
    "            pop[idx]['fitness'] = None\n",
    "            pop[idx]['n_evals'] = 0\n",
    "    # 4.2) mutations\n",
    "    # 4.2.1) select individuals to mutate\n",
    "    # sq_fits = fits*fits\n",
    "    #cumsum_sq_fits = fits * fits # cumsum_sq_fits[i] = sum(sq_fits[:i])\n",
    "    cumsum_sq_fits = fits # proportional to fits, rather than its square\n",
    "    cumsum_sq_fits = cumsum_sq_fits / cumsum_sq_fits.sum()\n",
    "    for i in range(1,len(cumsum_sq_fits)):\n",
    "        cumsum_sq_fits[i] = cumsum_sq_fits[i-1] + cumsum_sq_fits[i]\n",
    "    mut_list = [] # list with indexes of individuals to be mutate\n",
    "    while len(mut_list) < n_mut:\n",
    "        r = np.random.random()\n",
    "        candidate = 0\n",
    "        for i in range(len(fits)):\n",
    "            if cumsum_sq_fits[i] > r:\n",
    "                break\n",
    "            candidate += 1\n",
    "        if candidate in mut_list:\n",
    "            continue\n",
    "        else:\n",
    "            mut_list.append(candidate)\n",
    "    print(\"to mutate: \", end='')\n",
    "    print(mut_list)\n",
    "    for idx in mut_list:\n",
    "        if idx < n_save:\n",
    "            copy = pop[idx].copy()\n",
    "            mutate(copy)\n",
    "            pop[-idx-1] = copy\n",
    "            pop[-idx-1]['fitness'] = None\n",
    "            pop[-idx-1]['n_evals'] = 0\n",
    "        else:\n",
    "            mutate(pop[idx])\n",
    "            pop[idx]['fitness'] = None\n",
    "            pop[idx]['n_evals'] = 0\n",
    "            \n",
    "    print('generation %d finished in %s seconds' % (gen, time.time() - start_time))\n",
    "#     while len(mut_list) < n_mut:\n",
    "#         min_r = cumsum_sq_fits[n_save] # don't mutate the first n_save individuals\n",
    "#         r = min_r + (1.-min_r) * np.random.random()\n",
    "#         candidate = n_save\n",
    "#         for i in range(n_save, len(fits)):\n",
    "#             if cumsum_sq_fits[i] > r:\n",
    "#                 break\n",
    "#             candidate += 1\n",
    "#         if candidate in mut_list:\n",
    "#             continue\n",
    "#         else:\n",
    "#             mut_list.append(candidate)\n",
    "#     print(\"to mutate: \", end='')\n",
    "#     print(mut_list)\n",
    "#     for _ in range(n_mut):\n",
    "#         idx = np.random.randint(len(pop))\n",
    "#         mutate(pop[idx])\n",
    "#         pop[idx]['fitness'] = None\n",
    "#         pop[idx]['n_evals'] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print final population\n",
    "for dic in pop[:4]:\n",
    "    print('{',end='')\n",
    "    for name in dic.keys():\n",
    "        if name != 'fitness' or dic['fitness'] != None:\n",
    "            print(\"\\'%s\\':%.2f, \" % (name, dic[name]), end='')\n",
    "    print('}\\n')\n",
    "\n",
    "pop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final population\n",
    "fname = \"v3_nst_afx_pop\"\n",
    "fname += \"_\" + datetime.now().strftime('%Y-%m-%d__%H_%M')\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(pop, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, pops_dict = rl5E_net({}, pres_interv=5, rand_w=False, par_heter=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_dict['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a static value for X\n",
    "net.units[X[0]].thresh = 10. # high threshold makes output zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sim_time = 20.\n",
    "#ratio = 15.1 # cns-amd\n",
    "ratio = 20. # breaker\n",
    "#ratio = 1.6 # breaker, no L,V\n",
    "secs2finish = sim_time * ratio\n",
    "lt1 = time.localtime()\n",
    "hrs, hrs_rem = divmod(secs2finish, 3600)\n",
    "mins, mns_rem = divmod(hrs_rem, 60)\n",
    "xtra_hrs, new_mins = divmod(lt1.tm_min+mins, 60)\n",
    "print(\"Expecting to finish at: %d:%d (%d seconds)\" % \n",
    "      (lt1.tm_hour+hrs+xtra_hrs, new_mins, secs2finish))\n",
    "start_time = time.time()\n",
    "\n",
    "times, data, plant_data  = net.run(sim_time)\n",
    "\n",
    "print('Execution time is %s seconds' % (time.time() - start_time))\n",
    "lt2 = time.localtime\n",
    "print(\"Finished at \" + time.strftime('%H:%M'))\n",
    "data = np.array(data)\n",
    "\n",
    "# import cProfile\n",
    "# import pstats\n",
    "# cProfile.run('times, data, plant_data = net.run(2.)', 'restats')\n",
    "# prof = pstats.Stats('restats')\n",
    "# prof.sort_stats('cumulative').print_stats(30)\n",
    "# data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting, fixing controller weights\n",
    "# standard values:\n",
    "# A__M_mat = np.rray([[0.27141863, 0.29511766, 0.23279135, 0.20067437],\n",
    "#                     [0.23307357, 0.1957229 , 0.28739239, 0.28380952]])\n",
    "\n",
    "# M__C_mat = np.array([[0.0295056,  2.05108517],\n",
    "#                      [2.05111951, 0.02950648]])\n",
    "# limit values:\n",
    "A__M_mat = np.array([[0.4, .5, 0.08, 0.018],\n",
    "                    [0.05, 0. , 0.4, 0.5]])\n",
    "\n",
    "M__C_mat = np.array([[0.,  2.15],\n",
    "                     [2.15, 0.]])\n",
    "\n",
    "\n",
    "for m_idx, m_id in enumerate(M):\n",
    "    for c_idx, c_id in enumerate(C):\n",
    "        syn_list = net.syns[c_id]\n",
    "        for syn in syn_list:\n",
    "            if syn.preID == m_id:\n",
    "                syn.w = M__C_mat[c_idx, m_idx]\n",
    "                syn.alpha = 1e-5 # slowing down learning\n",
    "                break\n",
    "\n",
    "for a_idx, a_id in enumerate(A):\n",
    "    for m_idx, m_id in enumerate(M):\n",
    "        syn_list = net.syns[m_id]\n",
    "        for syn in syn_list:\n",
    "            if syn.preID == a_id:\n",
    "                syn.w = A__M_mat[m_idx, a_idx]\n",
    "                syn.alpha = 1e-5 # slowing down learning\n",
    "                break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running in two stages. Initial high learning rate and viscosity.\n",
    "sim_time = 150.\n",
    "#ratio = 15.1 # cns-amd\n",
    "#ratio = 20. # breaker\n",
    "ratio = 1.6 # breaker, no L,V\n",
    "secs2finish = sim_time * ratio\n",
    "lt1 = time.localtime()\n",
    "hrs, hrs_rem = divmod(secs2finish, 3600)\n",
    "mins, mns_rem = divmod(hrs_rem, 60)\n",
    "xtra_hrs, new_mins = divmod(lt1.tm_min+mins, 60)\n",
    "print(\"Expecting to finish firstst simulation at %d:%d (%d seconds)\" % \n",
    "      (lt1.tm_hour+hrs+xtra_hrs, new_mins, secs2finish))\n",
    "start_time = time.time()\n",
    "\n",
    "times, data, plant_data  = net.run(sim_time)\n",
    "\n",
    "print('Initial execution time is %s seconds' % (time.time() - start_time))\n",
    "lt2 = time.localtime\n",
    "print(\"Finished at \" + time.strftime('%H:%M'))\n",
    "data = np.array(data)\n",
    "\n",
    "sim_time = 100.\n",
    "net.plants[0].mu = 0.5\n",
    "for i in [0,1]:\n",
    "    for syn in net.syns[C[i]]:\n",
    "        if syn.type == 'rga_21':\n",
    "            syn.lrate = 100.\n",
    "            syn.alpha = syn.lrate * net.min_delay\n",
    "\n",
    "secs2finish = sim_time * ratio\n",
    "lt1 = time.localtime()\n",
    "hrs, hrs_rem = divmod(secs2finish, 3600)\n",
    "mins, mns_rem = divmod(hrs_rem, 60)\n",
    "xtra_hrs, new_mins = divmod(lt1.tm_min+mins, 60)\n",
    "print(\"Expecting to finish at: %d:%d (%d seconds)\" % \n",
    "      (lt1.tm_hour+hrs+xtra_hrs, new_mins, secs2finish))\n",
    "start_time = time.time()\n",
    "\n",
    "times, data, plant_data  = net.run(sim_time)\n",
    "\n",
    "print('Second execution time is %s seconds' % (time.time() - start_time))\n",
    "lt2 = time.localtime\n",
    "print(\"Finished at \" + time.strftime('%H:%M'))\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.units[SP[0]].set_function(lambda t: des_sf[int(round(t/15.))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing the scope of the plots\n",
    "data_back = data\n",
    "times_back = times\n",
    "plant_data_back = [np.array([])]\n",
    "plant_data_back[0] = plant_data[0]\n",
    "\n",
    "first_idx=0*200\n",
    "second_idx=1*200\n",
    "times = times[first_idx:second_idx]\n",
    "data = data[:, first_idx:second_idx]\n",
    "plant_data[0] = plant_data[0][first_idx:second_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover the data\n",
    "data = data_back\n",
    "plant_data[0] = plant_data_back[0]\n",
    "times = times_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = (20,6)\n",
    "\n",
    "# M\n",
    "M_fig = plt.figure(figsize=fs)\n",
    "M_data = np.array(data[M])\n",
    "plt.plot(times, M_data.transpose())\n",
    "plt.legend(['M0', 'M1'])\n",
    "plt.title('M0, M1')\n",
    "#print(M_data[:,-1])\n",
    "\n",
    "# SF, SP\n",
    "SF_fig = plt.figure(figsize=fs)\n",
    "SF_data = np.array(data[SF])\n",
    "SP_data = np.array(data[SP])\n",
    "plt.plot(times, SF_data.transpose(), label='SF')\n",
    "plt.plot(times, SP_data.transpose(), label='SP', linewidth=4)\n",
    "plt.legend()\n",
    "plt.title('SF, SP')\n",
    "plt.show()\n",
    "#print('SF = [%f]' % (SF_data[0,-1]))\n",
    "#print('SP = [%f]' % (SP_data[0,-1]))\n",
    "\n",
    "# V, R\n",
    "V_fig = plt.figure(figsize=fs)\n",
    "V_data = np.array(data[V])\n",
    "plt.plot(times, V_data.transpose())\n",
    "plt.title('V, R')\n",
    "R_data = np.array(data[R])\n",
    "plt.plot(times, R_data.transpose(), linewidth=4)\n",
    "plt.legend(['V', 'R'])\n",
    "\n",
    "# M--C0 weights\n",
    "W_fig1 = plt.figure(figsize=fs)\n",
    "w_track_data = np.array(data[M_C0_track])\n",
    "plt.plot(times, w_track_data.transpose())\n",
    "plt.legend(['M0-C0', 'M1-C0'])\n",
    "plt.title('M--C0 weights')\n",
    "\n",
    "# A--M0 weights\n",
    "W_fig2 = plt.figure(figsize=fs)\n",
    "w_track_data2 = np.array(data[A_M0_track])\n",
    "plt.plot(times, w_track_data2.transpose())\n",
    "plt.legend(['A0-M0', 'A1-M0', 'A2-M0', 'A3-M0'])\n",
    "plt.title('A--M0 weights')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X\n",
    "X_fig = plt.figure(figsize=fs)\n",
    "X_data = np.array(data[X])\n",
    "plt.plot(times, X_data.transpose())\n",
    "plt.ylim([-0.05,1.05])\n",
    "#plt.legend(['X'])\n",
    "plt.title('X')\n",
    "\n",
    "fs = (20,12)\n",
    "# MPLEX\n",
    "MPLEX_fig = plt.figure(figsize=fs)\n",
    "MPLEX_data = np.array(data[MPLEX])\n",
    "plt.plot(times, MPLEX_data.transpose())\n",
    "plt.legend(['MPLEX0', 'MPLEX1'])\n",
    "plt.title('MPLEX0, MPLEX1')\n",
    "\n",
    "# SPF\n",
    "fs = (20,6)\n",
    "SPF_fig = plt.figure(figsize=fs)\n",
    "SPF_data = np.array(data[SPF])\n",
    "plt.plot(times, SPF_data.transpose())\n",
    "plt.legend(['SPF0', 'SPF1'])\n",
    "plt.title('SPF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# P\n",
    "P_fig = plt.figure(figsize=fs)\n",
    "P_data = plant_data[P]\n",
    "plt.plot(times, P_data[:,0], label='angle')\n",
    "plt.plot(times, P_data[:,1], label='ang vel')\n",
    "plt.legend()\n",
    "plt.title('pendulum')\n",
    "#print(\"angle: %f, vel: %f\" % (P_data[-1,0],P_data[-1,1]))\n",
    "\n",
    "# A\n",
    "A_fig = plt.figure(figsize=fs)\n",
    "A_data = np.array(data[A])\n",
    "plt.plot(times, A_data.transpose())\n",
    "plt.legend(['A0', 'A1', 'A2', 'A3'])\n",
    "plt.title('A')\n",
    "#print(A_data[:,-1])\n",
    "\n",
    "# L\n",
    "# L_fig = plt.figure(figsize=fs)\n",
    "# L_data = np.array(data[L])\n",
    "# plt.plot(times, L_data.transpose())\n",
    "# plt.title('L')\n",
    "\n",
    "# C0\n",
    "C0_fig = plt.figure(figsize=fs)\n",
    "C0_data = np.array(data[C[0]])\n",
    "plt.plot(times, C0_data.transpose())\n",
    "#plt.plot(times, data[dc_track[0]], linewidth=3)\n",
    "plt.title('C0')\n",
    "#print(C0_data[-1])\n",
    "\n",
    "# C1\n",
    "C1_fig = plt.figure(figsize=fs)\n",
    "C1_data = np.array(data[C[1]])\n",
    "plt.plot(times, C1_data.transpose())\n",
    "#plt.plot(times, data[dc_track[1]], linewidth=3)\n",
    "plt.title('C1')\n",
    "#print(C1_data[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the M__C and A__M connections\n",
    "M__C_mat = np.zeros((2,2)) # rows are target (C) neurons\n",
    "for m_idx, m_id in enumerate(M):\n",
    "    for c_idx, c_id in enumerate(C):\n",
    "        syn_list = net.syns[c_id]\n",
    "        for syn in syn_list:\n",
    "            if syn.preID == m_id:\n",
    "                M__C_mat[c_idx, m_idx] = syn.w\n",
    "                break\n",
    "                \n",
    "A__M_mat = np.zeros((2,4)) # rows are target (M) neurons\n",
    "for a_idx, a_id in enumerate(A):\n",
    "    for m_idx, m_id in enumerate(M):\n",
    "        syn_list = net.syns[m_id]\n",
    "        for syn in syn_list:\n",
    "            if syn.preID == a_id:\n",
    "                A__M_mat[m_idx, a_idx] = syn.w\n",
    "                break\n",
    "print(M__C_mat)\n",
    "print(A__M_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L__V connections\n",
    "L__V_w_mat = np.zeros((No2, No2))\n",
    "for i in range(No2):\n",
    "    for j in range(No2):\n",
    "        w = net.syns[V[0]][i*No2 + j].w\n",
    "        #print(\"%.2f\" % (w), end=' ')\n",
    "        L__V_w_mat[i,No2-j-1] = w\n",
    "    #print(\"\\n\")\n",
    "    \n",
    "L__V_w_mat_fig = plt.figure(figsize=(8,8))\n",
    "axs = plt.subplot(1,1,1)\n",
    "cs = axs.imshow(L__V_w_mat)\n",
    "L__V_w_mat_fig.colorbar(cs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L__X connections\n",
    "matty0 = np.zeros((No2, No2))\n",
    "matty1 = np.zeros((No2, No2))\n",
    "for i in range(No2):\n",
    "    for j in range(No2):\n",
    "        w0 = net.syns[X[0]][i*No2 + j].w\n",
    "        #w1 = net.syns[X[1]][i*No2 + j+4].w\n",
    "        #print(\"%.2f\" % (w), end=' ')\n",
    "        matty0[i,No2-j-1] = w0\n",
    "        #matty1[i,No2-j-1] = w1\n",
    "    #print(\"\\n\")\n",
    "    \n",
    "matty_fig = plt.figure(figsize=(20,8))\n",
    "axs0 = plt.subplot(1,1,1)\n",
    "cs0 = axs0.imshow(matty0)\n",
    "plt.colorbar(cs0)\n",
    "# axs1 = plt.subplot(1,2,2)\n",
    "# cs1 = axs1.imshow(matty1)\n",
    "# plt.colorbar(cs1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotty = plotter(net, times, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotty.act_anim(S1+S2+L+R+V, 0.5, interv=10, slider=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotty.conn_anim(L, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A figure with more formatting\n",
    "SPF_fig = plt.figure(figsize=(20,10))\n",
    "SF_data = np.array(data[SF])\n",
    "SP_data = np.array(data[SP])\n",
    "plt.plot(times, SF_data.transpose(), label='$S_P$', linewidth=2)\n",
    "plt.plot(times, SP_data.transpose(), label='$S_D$', linewidth=4)\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "plt.legend(fontsize=25)\n",
    "plt.xlabel('time (s)', fontsize =25)\n",
    "plt.title('$S_D, S_P$', fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good initial weights\n",
    "\n",
    "# M__C\n",
    "# M[0] has the F-D error, so you want C[0] (which exerts positive torque)\n",
    "# to be driven by M[1] instead, and C[1] to be driven by M[0]\n",
    "shift = 0\n",
    "while not net.syns[C[0]][shift].type is synapse_types.rga:\n",
    "    shift += 1\n",
    "net.syns[C[0]][shift].w = 0.1\n",
    "net.syns[C[0]][shift+1].w = 0.8 # C[0] driven by M[1]\n",
    "net.syns[C[1]][shift].w = 0.8\n",
    "net.syns[C[1]][shift+1].w = 0.1\n",
    "\n",
    "# L__X, L__V\n",
    "scale = 1. # maximum weight value\n",
    "def dist(c1, c2):\n",
    "    \"\"\" Periodic distance between 2-dim coordinates c1 and c2. \n",
    "\n",
    "        Assumes c1 and c2 are inside the box with corners [-0.5, -0.5], [0.5, 0.5].\n",
    "    \"\"\"\n",
    "    x_dist = min(max(c1[0], c2[0]) - min(c1[0], c2[0]),  # \"inner\" distance\n",
    "                 0.5-max(c1[0], c2[0]) + (min(c1[0], c2[0])+0.5) ) # \"outer\" distance\n",
    "    y_dist = min(max(c1[1], c2[1]) - min(c1[1], c2[1]),  # \"inner\" distance\n",
    "                 0.5-max(c1[1], c2[1]) + (min(c1[1], c2[1])+0.5) ) # \"outer\" distance\n",
    "    return np.sqrt(x_dist*x_dist + y_dist*y_dist)\n",
    "\n",
    "#L__V_iw = np.zeros((No2, No2))\n",
    "j = 0\n",
    "for i in range(len(L)):  # Setting L__V weights\n",
    "    u = net.units[L[i]]\n",
    "    c = u.coordinates\n",
    "    d = dist(c, [c[1], c[1]])\n",
    "    Vsyn = net.syns[V[0]][i]\n",
    "    Xsyn = net.syns[X[0]][i+j]\n",
    "    while Xsyn.type != synapse_types.diff_rm_hebbian:\n",
    "        j +=1\n",
    "        Xsyn = net.syns[X[0]][i+j]\n",
    "    if Vsyn.preID == u.ID and Xsyn.preID == u.ID:\n",
    "        a, b = divmod(i, No2)\n",
    "        Vsyn.w = scale*(.5 - d)\n",
    "        Xsyn.w = 0.01 if abs(c[1]-c[0]) < 0.5-max(c[1],c[0]) + min(c[1],c[0])+0.5 else .8\n",
    "    else:\n",
    "        print(\"FAILED!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# plot all factors in the M--C0 synaptic plasticity\n",
    "fs = (20,6)\n",
    "plastic_fig = plt.figure(figsize=fs)\n",
    "xp_data = np.array(data[xp_track[0]])\n",
    "up_data = np.array(data[up_track[0]])\n",
    "sp_data = np.array(data[sp_track[0]])\n",
    "spj_data = np.array(data[spj_track[0]])\n",
    "plt.plot(times, xp_data)\n",
    "plt.plot(times, up_data)\n",
    "plt.plot(times, sp_data)\n",
    "plt.plot(times, spj_data)\n",
    "plt.legend(['xp', 'up', 'sp', 'spj'])\n",
    "\n",
    "plastic_fig2 = plt.figure(figsize=fs)\n",
    "f1 = up_data - xp_data\n",
    "f2 = sp_data - spj_data\n",
    "rule = 500. * f1 * f2\n",
    "plt.plot(times, f1)\n",
    "plt.plot(times, f2)\n",
    "plt.plot(times, rule)\n",
    "plt.plot(times, np.zeros(len(times)), 'k', linewidth=1)\n",
    "plt.legend(['up - xp', 'sp - spj', 'prod'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# checking some connections\n",
    "print(\"Connections to M0 unit\")\n",
    "for idx, syn in enumerate(net.syns[M[0]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_id == P and hasattr(syn, 'plant_out'):\n",
    "        pre_pop = 'P'\n",
    "    elif pre_id in A:\n",
    "        pre_pop = 'A'\n",
    "    #elif pre_id in L:\n",
    "    #    pre_pop = 'L'\n",
    "    elif pre_id in M:\n",
    "        pre_pop = 'M'\n",
    "    #elif pre_id in V:\n",
    "    #    pre_pop = 'V'\n",
    "    elif pre_id in SPF:\n",
    "        pre_pop = 'SPF'\n",
    "    else:\n",
    "        pre_pop = 'erroneous'\n",
    "    if pre_pop == 'P':\n",
    "        plant_out = str(syn.plant_out)\n",
    "    else:\n",
    "        plant_out = 'None'\n",
    "    print('%d) %s (%d) --> M0, w=%f, port=%d, plant_out=%s'%(idx, pre_pop, pre_id, syn.w, syn.port, plant_out))\n",
    "\n",
    "print(\"Connections to M1 unit\")\n",
    "for idx, syn in enumerate(net.syns[M[1]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_id == P and hasattr(syn, 'plant_out'):\n",
    "        pre_pop = 'P'\n",
    "    elif pre_id in A:\n",
    "        pre_pop = 'A'\n",
    "    #elif pre_id in L:\n",
    "    #    pre_pop = 'L'\n",
    "    elif pre_id in M:\n",
    "        pre_pop = 'M'\n",
    "    #elif pre_id in V:\n",
    "    #    pre_pop = 'V'\n",
    "    elif pre_id in SPF:\n",
    "        pre_pop = 'SPF'\n",
    "    else:\n",
    "        pre_pop = 'erroneous'\n",
    "    if pre_pop == 'P':\n",
    "        plant_out = str(syn.plant_out)\n",
    "    else:\n",
    "        plant_out = 'None'\n",
    "    print('%d) %s (%d) --> M1, w=%f, port=%d, plant_out=%s'%(idx, pre_pop, pre_id, syn.w, syn.port, plant_out))\n",
    "    \n",
    "print(\"Connections to C0 unit\")\n",
    "for idx, syn in enumerate(net.syns[C[0]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_id == P and hasattr(syn, 'plant_out'):\n",
    "        pre_pop = 'P'\n",
    "    elif pre_id in A:\n",
    "        pre_pop = 'A'\n",
    "    elif pre_id in M:\n",
    "        pre_pop = 'M'\n",
    "    elif pre_id in C:\n",
    "        pre_pop = 'C'\n",
    "    else:\n",
    "        pre_pop = 'erroneous'\n",
    "    if pre_pop == 'P':\n",
    "        plant_out = str(syn.plant_out)\n",
    "    else:\n",
    "        plant_out = 'None'\n",
    "    print('%d) %s (%d) --> C0, w=%f, port=%d, plant_out=%s'%(idx, pre_pop, pre_id, syn.w, syn.port, plant_out))  \n",
    "\n",
    "print(\"Connections to C1 unit\")\n",
    "for idx, syn in enumerate(net.syns[C[1]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_id == P and hasattr(syn, 'plant_out'):\n",
    "        pre_pop = 'P'\n",
    "    elif pre_id in A:\n",
    "        pre_pop = 'A'\n",
    "    elif pre_id in M:\n",
    "        pre_pop = 'M'\n",
    "    elif pre_id in C:\n",
    "        pre_pop = 'C'\n",
    "    else:\n",
    "        pre_pop = 'erroneous'\n",
    "    if pre_pop == 'P':\n",
    "        plant_out = str(syn.plant_out)\n",
    "    else:\n",
    "        plant_out = 'None'\n",
    "    print('%d) %s (%d) --> C1, w=%f, port=%d, plant_out=%s'%(idx, pre_pop, pre_id, syn.w, syn.port, plant_out))  \n",
    "\n",
    "    \n",
    "print(\"Connections to afferent units\")\n",
    "for idx, syn in enumerate(net.syns[A[2]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_id == P and hasattr(syn, 'plant_out'):\n",
    "        pre_pop = 'P'\n",
    "    elif pre_id in A:\n",
    "        pre_pop = 'A'\n",
    "    else:\n",
    "        pre_pop = 'erroneous'\n",
    "    if pre_pop == 'P':\n",
    "        plant_out = str(syn.plant_out)\n",
    "    else:\n",
    "        plant_out = 'None'\n",
    "    print('%d) %s (%d) --> A, w=%f, port=%d, plant_out=%s'%(idx, pre_pop, pre_id, syn.w, syn.port, plant_out))\n",
    "\n",
    "print(\"Connections to plant\")\n",
    "for idx, syn in enumerate(net.plants[P].inp_syns[0]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_id in C:\n",
    "        pre_pop = 'C'\n",
    "    else:\n",
    "        pre_pop = 'erroneous'\n",
    "    print('%d) %s (%d, %s) --> P, w=%f'%(idx, pre_pop, pre_id, pre_type, syn.w))\n",
    "    \n",
    "print(\"Connections to MPLEX units\")\n",
    "for idx, syn in enumerate(net.syns[MPLEX[0]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_id in X:\n",
    "        pre_pop = 'X'\n",
    "    elif pre_id in SF:\n",
    "        pre_pop = 'SF'\n",
    "    elif pre_id in SP:\n",
    "        pre_pop = 'SP'\n",
    "    else:\n",
    "        pre_pop = 'erroneous'\n",
    "    print('%d) %s (%d) --> MPLEX, w=%f, port=%d'%(idx, pre_pop, pre_id, syn.w, syn.port))  \n",
    "\n",
    "print(\"Connections to SF units\")\n",
    "for idx, syn in enumerate(net.syns[SF[1]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_id == P and hasattr(syn, 'plant_out'):\n",
    "        pre_pop = 'P'\n",
    "    elif pre_id in T:\n",
    "        pre_pop = 'T'\n",
    "    else:\n",
    "        pre_pop = 'erroneous'\n",
    "    print('%d) %s (%d) --> SF, w=%f, port=%d, plant_out=%s'%\n",
    "          (idx, pre_pop, pre_id, syn.w, syn.port, plant_out))\n",
    "\n",
    "print(\"Connections to X unit\")\n",
    "for idx, syn in enumerate(net.syns[X[0]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_id in L:\n",
    "        pre_pop = 'L'\n",
    "    elif pre_id in V:\n",
    "        pre_pop = 'V'\n",
    "    else:\n",
    "        pre_pop = 'erroneous'\n",
    "    print('%d) %s (%d) --> X, w=%f, port=%d'%(idx, pre_pop, pre_id, syn.w, syn.port))  \n",
    "    \n",
    "print(\"Connections to V unit\")\n",
    "for idx, syn in enumerate(net.syns[V[0]]):\n",
    "    pre_id = syn.preID\n",
    "    pre_type = net.units[pre_id].type\n",
    "    if pre_id in L:\n",
    "        pre_pop = 'L'\n",
    "    elif pre_id in R:\n",
    "        pre_pop = 'R'\n",
    "    else:\n",
    "        pre_pop = 'erroneous'\n",
    "    print('%d) %s (%d) --> V, w=%f, port=%d'%(idx, pre_pop, pre_id, syn.w, syn.port))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "def eval_config(cfg):\n",
    "    \"\"\" Returns the error for a network with a given configuration.\n",
    "\n",
    "        Args:\n",
    "            cfg : a configuration dictionary.\n",
    "        Returns:\n",
    "            error : A float calculated from the sum of activities in the SPF layer.\n",
    "    \"\"\"\n",
    "    if cfg['n_evals'] > 8: # if the fitness has been evaluated \"enough\" times. See cell below...\n",
    "        return cfg['fitness']\n",
    "    \n",
    "    # obtain a network with the given configuration\n",
    "    net, pops_dict = rl5E_net(cfg, \n",
    "                          pres_interv=5.,\n",
    "                          rand_w=False,\n",
    "                          par_heter=0.1,\n",
    "                          x_switch=True,\n",
    "                          V_normalize=True,\n",
    "                          X_normalize=True)\n",
    "\n",
    "#     for name in pops_dict:\n",
    "#         exec(name + '=' + str(pops_dict[name]))\n",
    "    #des_angs = np.array(des_angs)\n",
    "    \n",
    "    # run the network to learn the value (X switching)\n",
    "    run_time = 4000.\n",
    "    #start_time = time.time()\n",
    "    times, data, plant_data  = net.run(run_time)\n",
    "    #print('Execution time is %s seconds' % (time.time() - start_time))\n",
    "    \n",
    "    # run the network to learn to change afferent representations\n",
    "    net.units[pops_dict['X'][0]].switch = False # stop swtiching\n",
    "    run_time = 1000.\n",
    "    times, data, plant_data  = net.run(run_time)\n",
    "    \n",
    "    # One last run for testing\n",
    "    run_time = 500.\n",
    "    times, data, plant_data  = net.run(run_time)\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # calculate average reward in last 500 seconds of reaching\n",
    "    R = pops_dict['R']\n",
    "    R_data = np.array(data[R])\n",
    "    mean_R = np.mean(R_data)\n",
    "    \n",
    "    # extract L__V and L__X weigths\n",
    "#     LVw = net.units[V[0]].buffer[1:,-1]\n",
    "#     LXw = net.units[X[0]].buffer[1:,-1]\n",
    "\n",
    "    return 1. - mean_R #, LVw, LXw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
