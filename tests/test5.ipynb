{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is used for testing learning using the draculab module.\n",
    "\n",
    "# In particular, extracting the eigenvectors of the input correlation matrix.\n",
    "# The algorithm used is based on Foldiak (1989) \"Adaptive network for optimal linear feature extraction\"\n",
    "# Proc IEEE/INNS IJCNN 1:401-405\n",
    "# But other variations are possible (e.g. BCM rule, Hebbian with substractive normalization)\n",
    "\n",
    "# By Sergio Verduzco Flores        June 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is supposed to be in .../draculab/tests/ , so cd before importing:\n",
    "%cd ..\n",
    "from draculab import *\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conn_mat(net):\n",
    "    # Get the connection matrix of a network in a Numpy array\n",
    "    conns = np.zeros((net.n_units,net.n_units))\n",
    "    for syn_list in net.syns:\n",
    "        for syn in syn_list:\n",
    "            conns[syn.postID,syn.preID] = syn.w\n",
    "    return conns\n",
    "\n",
    "def plot_stuff(data):\n",
    "    #fig.clf()\n",
    "    #plt.close()\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    for i in range(9):\n",
    "        ax = fig.add_subplot(3,3,i+1)\n",
    "        ax.clear()\n",
    "        plt.ylim(-0.01,0.5)\n",
    "        ax.plot(data[0], data[1][i], 'r', figure=fig)\n",
    "    new_fig = plt.figure(figsize=(5,3))\n",
    "    plt.plot(sim_dat[0], sim_dat[1][9], 'b', sim_dat[0], sim_dat[1][10], 'k', figure=new_fig)\n",
    "    plt.plot(sim_dat[0], sim_dat[1][11], 'g', sim_dat[0], sim_dat[1][12], 'r', figure=new_fig)\n",
    "    fig.canvas.draw()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################# TEST 1 ####################\n",
    "######### 1) Create a network\n",
    "net_params = {'min_delay' : 0.1, 'min_buff_size' : 10, 'rtol':1e-5, 'atol':1e-5 } # parameter dictionary for the network\n",
    "n1 = network(net_params)\n",
    "\n",
    "######### 2) Put some units in the network\n",
    "# parameters for the units\n",
    "n_units = 8\n",
    "init_val_list = np.random.uniform(0.2, 0.6, n_units) # initial values for the non-source units\n",
    "slope_list = np.random.uniform(5.0, 7.0 ,n_units) # slopes for sigmoidal units\n",
    "thresh_list = np.random.uniform(0.0, 0.2, n_units)  #thresholds for sigmoidal units\n",
    "tau_list = np.random.uniform(2.0, 3.5, n_units)\n",
    "pars = { 'init_val' : 0.5, 'tau_fast' : 1., 'function' : lambda x:None,\n",
    "         'type' : unit_types.source }  \n",
    "inputs = n1.create(9,pars) # creating nine input sources\n",
    "pars = { 'coordinates' : [np.zeros(2)]*n_units, \n",
    "         'init_val' : init_val_list, 'tau_fast' : 3., 'tau_slow' : 30.,\n",
    "         'slope' : slope_list, 'thresh' : thresh_list, 'tau' : tau_list,\n",
    "         'type' : unit_types.sigmoidal } \n",
    "units = n1.create(n_units,pars) # creating sigmoidal units\n",
    "\n",
    "######### 3) Connect the units in the network\n",
    "conn_spec = {'rule' : 'all_to_all', \n",
    "             'delay' : {'distribution' : 'uniform', 'low' : 0.1, 'high' : 0.3},\n",
    "             'allow_autapses' : False} # connection specification dictionary\n",
    "syn_pars = {'init_w' : {'distribution':'uniform', 'low':0.3, 'high':0.9}, 'omega' : 6., \n",
    "            'lrate' : 0.02, 'type' : synapse_types.hebbsnorm } # synapse parameters dictionary\n",
    "# Synapses tested here: oja, bcm, hebbsnorm, sq_hebbsnorm\n",
    "n1.connect(inputs, units, conn_spec, syn_pars)\n",
    "\n",
    "# We put competitive learning in the units to see if they can learn to extract different features\n",
    "syn_pars['init_w'] = 0.\n",
    "syn_pars['lrate'] = 0.015\n",
    "syn_pars['type'] = synapse_types.anticov   # antihebb, anticov\n",
    "n1.connect(units, units, conn_spec, syn_pars)\n",
    "\n",
    "# For hebbsnorm synapses, the sum of synaptic weights shouldn't change\n",
    "# For sq_hebbsnorm synapses, the sum of squared weights should approach omega\n",
    "w_sums = [sum([syn.w for syn in n1.syns[idx][0:9]]) for idx in range(9,9+n_units)]\n",
    "sq_w_sums = [sum([syn.w*syn.w for syn in n1.syns[idx][0:9]]) for idx in range(9,9+n_units)]\n",
    "print(\"Before sim, weight sums and squared weight sums are:\")\n",
    "print(w_sums)\n",
    "print(sq_w_sums)\n",
    "\n",
    "######### 4) Running and visualizing \n",
    "\n",
    "####### SETTING THE INPUT FUNCTIONS\n",
    "### You are going to present 4 input patterns that randomly switch over time.\n",
    "### Imagine the 9 inputs arranged in a grid, like a tic-tac-toe board, numbered\n",
    "### from left to right and from top to bottom:\n",
    "### 1 2 3\n",
    "### 4 5 6\n",
    "### 7 8 9\n",
    "### You'll have input patterns\n",
    "### 0 X 0   0 0 0   X 0 X   0 X 0\n",
    "### 0 X 0   X X X   0 0 0   X 0 X\n",
    "### 0 X 0   0 0 0   X 0 X   0 X 0\n",
    "### The input is always a normalized linear combination of one or two of these patterns.\n",
    "### Pattern pat1 is presented alone for t_pat time units, and then there is a transition period\n",
    "### during which pat1 becomes pat2 by presenting at time t an input \n",
    "### c*(t_pat+t_trans - t)*pat1 + c*(t - tpat)*pat2\n",
    "### where c = 1/t_trans, and t_trans is the duration of the transition period. \n",
    "### At time t_pat+t_trans, pat2 is presented by itself for t_pat time units.\n",
    "### \n",
    "# here are the patterns as arrays\n",
    "patterns = [np.zeros(9) for i in range(4)]\n",
    "patterns[0] = np.array([0., 1., 0., 0., 1., 0., 0., 1., 0.])/3.\n",
    "patterns[1] = np.array([0., 0., 0., 1., 1., 1., 0., 0., 0.])/3.\n",
    "patterns[2] = np.array([1., 0., 1., 0., 0., 0., 1., 0., 1.])/4.\n",
    "patterns[3] = np.array([0., 1., 0., 1., 0., 1., 0., 1., 0.])/4.\n",
    "\n",
    "n_pres = 50\n",
    "# number of times some pattern will be presented\n",
    "t_pat = 12. # as above\n",
    "t_trans = 4.\n",
    "c = 1/t_trans # auxiliary variable\n",
    "pats = range(4) # auxiliary variable\n",
    "cur_pat = np.random.choice(pats)  # pattern currently presented\n",
    "next_pat = np.random.choice(pats) # next pattern to be presented\n",
    "last_t = 0.\n",
    "start_time = time.time()\n",
    "\n",
    "def make_fun1(idx):  \n",
    "    # This creates a constant function with value: patterns[cur_pat][idx]\n",
    "    # thus avoiding a scoping problem that is sometimes hard to see:\n",
    "    # https://eev.ee/blog/2011/04/24/gotcha-python-scoping-closures/\n",
    "    fun = lambda t : patterns[cur_pat][idx]\n",
    "    return fun\n",
    "\n",
    "def make_fun2(idx, last_t):\n",
    "    # Creates a function for the pattern transition\n",
    "    fun = lambda t : c * ( (t_trans - (t-last_t))*patterns[cur_pat][idx] +\n",
    "                           (t-last_t)*patterns[next_pat][idx] )\n",
    "    return fun\n",
    "\n",
    "for pres in range(n_pres):\n",
    "# For each cycle you'll set the input functions and simulate, once with a single pattern,\n",
    "# once with a mix of patterns, as described above\n",
    "    \n",
    "    # first, we present a single pattern\n",
    "    for u in range(9):\n",
    "        n1.units[inputs[u]].set_function( make_fun1(u) )\n",
    "        \n",
    "    #sim_dat = n1.run(t_pat)  # simulating\n",
    "    sim_dat = n1.flat_run(t_pat)  # simulating\n",
    "    last_t = n1.sim_time # simulation time after last pattern presentation\n",
    "    \n",
    "    #plot_stuff(sim_dat)\n",
    "    #input('Fixed pattern presented: ' + str(cur_pat))\n",
    "    \n",
    "    # now one pattern turns into the next\n",
    "    for u in range(9):\n",
    "        n1.units[inputs[u]].set_function(make_fun2(u, last_t))\n",
    "    \n",
    "    #sim_dat = n1.run(t_trans) # simulating\n",
    "    sim_dat = n1.flat_run(t_trans)  # simulating\n",
    "    \n",
    "    #plot_stuff(sim_dat)\n",
    "    #input('Transitioned to pattern: ' + str(next_pat))\n",
    "\n",
    "    # choose the pattern you'll present next\n",
    "    cur_pat = next_pat\n",
    "    next_pat = np.random.choice(pats)\n",
    "    \n",
    "    if pres%10 == 0:\n",
    "        print('Presentation ' + str(pres+1))\n",
    "\n",
    "print('Execution time: %s seconds' % (time.time() - start_time))  # around 11.7 seconds\n",
    "\n",
    "# For hebbsnorm synapses, the sum of synaptic weights shouldn't change\n",
    "# For sq_hebbsnorm synapses, the sum of squared weights should approach omega\n",
    "w_sums = [sum([syn.w for syn in n1.syns[idx][0:9]]) for idx in range(9,9+n_units)]\n",
    "sq_w_sums = [sum([syn.w*syn.w for syn in n1.syns[idx][0:9]]) for idx in range(9,9+n_units)]\n",
    "print(\"After sim, weight sums and squared weight sums are:\")\n",
    "print(w_sums)\n",
    "print(sq_w_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Checking whether the units have preferred patterns\n",
    "\n",
    "n_pres = 4\n",
    "cur_pat = 0\n",
    "next_pat = 1\n",
    "for pres in range(n_pres):\n",
    "# For each cycle you'll set the input functions and simulate, once with a single pattern,\n",
    "# once with a mix of patterns, as described above\n",
    "    \n",
    "    # first, we present a single pattern\n",
    "    \n",
    "    for u in range(9):\n",
    "        n1.units[inputs[u]].set_function( make_fun1(u) )\n",
    "        \n",
    "    #sim_dat = n1.run(t_pat)  # simulating\n",
    "    sim_dat = n1.flat_run(t_pat) # simulating\n",
    "    last_t = n1.sim_time # simulation time after last pattern presentation\n",
    "    \n",
    "    plot_stuff(sim_dat)\n",
    "    #input('Fixed pattern presented: ' + str(cur_pat))\n",
    "    \n",
    "    # now one pattern turns into the next\n",
    "    for u in range(9):\n",
    "        n1.units[inputs[u]].set_function(make_fun2(u, last_t))\n",
    "    \n",
    "    #sim_dat = n1.run(t_trans) # simulating\n",
    "    sim_dat = n1.flat_run(t_trans) # simulating\n",
    "    \n",
    "    plot_stuff(sim_dat)\n",
    "    #input('Transitioned to pattern: ' + str(next_pat))\n",
    "\n",
    "    # choose the pattern you'll present next\n",
    "    cur_pat = next_pat\n",
    "    next_pat = (next_pat+1)%4\n",
    "    \n",
    "    if pres%10 == 0:\n",
    "        print('Presentation ' + str(pres+1))\n",
    "        \n",
    "        \n",
    "weights = [ (np.array(n1.units[9+i].get_weights(n1.sim_time)))[0:9] for i in range(n_units)]\n",
    "proj = [[] for i in range(n_units)]\n",
    "for i in range(n_units):\n",
    "    proj[i] = [sum(weights[i]*patterns[j]) for j in range(4)]\n",
    "    print([\"%.2f\" % v for v in proj[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Comparing the weight vectors with the leading eigenvector of the correlation matrix\n",
    "#######################################################################################\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Obtaining eigenvectors of the correlation matrix\n",
    "pat_mat = np.matrix(patterns)\n",
    "corr = (pat_mat.T)*pat_mat # input correlation matrix\n",
    "eigs = np.linalg.eig(corr) # extracting eigenvalues and eigenvectors\n",
    "evals = eigs[0] # eigenvalues\n",
    "evecs = [eigs[1][:,i] for i in range(9)] # eigenvectors\n",
    "\n",
    "# obtaining the leading eigenvector\n",
    "max_index, max_value = max(enumerate(evals), key=lambda p:p[1])\n",
    "print('Max eigenvalue: ' + str(max_value) + ', index: ' + str(max_index))\n",
    "max_evector = evecs[max_index]\n",
    "    \n",
    "# plotting all eigenvectors in 3x3 format\n",
    "fig3 = plt.figure(figsize=(10,10))\n",
    "ev_grid = ImageGrid(fig3, 111, nrows_ncols=(3,3), axes_pad=0.05)\n",
    "for idx,vec in enumerate(evecs):\n",
    "    vec.shape = 3,3\n",
    "    ev_grid[idx].imshow(vec)\n",
    "\n",
    "# plotting leading eigenvector VS weight vectors in 3x3 format\n",
    "fig4 = plt.figure(figsize=(10,10))\n",
    "cols = int(round(np.sqrt(n_units)))\n",
    "if cols*cols < n_units:\n",
    "    rows = cols + 1\n",
    "else:\n",
    "    rows = cols\n",
    "sp_ev_grid = ImageGrid(fig4, 111, nrows_ncols=(rows,cols), axes_pad=0.05)\n",
    "for idx,vec in enumerate(weights):\n",
    "    vec.shape = 3,3\n",
    "    sp_ev_grid[idx].imshow(vec)\n",
    "    print([\"%.2f\" % float(v[0]) for v in vec.reshape(9,1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "C = conn_mat(n1)\n",
    "for row in C:\n",
    "    print([\"{0:0.1f}\".format(i) for i in row])\n",
    "\n",
    "fig5 = plt.figure(figsize=(14,14))\n",
    "conn_grid = ImageGrid(fig5, 111, nrows_ncols=(1,1), axes_pad=0.2)\n",
    "conn_grid[0].imshow(C)\n",
    "#print(n1.delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for unit in n1.units:\n",
    "    if unit.type == unit_types.sigmoidal:\n",
    "        print('delay: %f' % unit.delay)\n",
    "        print('init: %f' % unit.init_val)\n",
    "        print('tau: %f' % unit.tau)\n",
    "        print('thresh: %f' % unit.thresh)\n",
    "        print('slope: %f' % unit.slope)\n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
